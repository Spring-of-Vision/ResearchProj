{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc97bdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: furo in c:\\users\\mayan\\appdata\\roaming\\python\\python311\\site-packages (2022.12.7)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from furo) (4.12.2)\n",
      "Requirement already satisfied: sphinx<7.0,>=5.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from furo) (5.0.2)\n",
      "Requirement already satisfied: sphinx-basic-ng in c:\\users\\mayan\\appdata\\roaming\\python\\python311\\site-packages (from furo) (1.0.0b2)\n",
      "Requirement already satisfied: pygments>=2.7 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from furo) (2.15.1)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (1.1.5)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (1.0.3)\n",
      "Requirement already satisfied: Jinja2>=2.3 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (3.1.2)\n",
      "Requirement already satisfied: docutils<0.19,>=0.14 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (0.18.1)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (2.2.0)\n",
      "Requirement already satisfied: babel>=1.3 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (2.11.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (0.7.12)\n",
      "Requirement already satisfied: imagesize in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.5.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (2.31.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (23.1)\n",
      "Requirement already satisfied: colorama>=0.3.5 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx<7.0,>=5.0->furo) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from beautifulsoup4->furo) (2.4)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from babel>=1.3->sphinx<7.0,>=5.0->furo) (2023.3.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from Jinja2>=2.3->sphinx<7.0,>=5.0->furo) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx<7.0,>=5.0->furo) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx<7.0,>=5.0->furo) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx<7.0,>=5.0->furo) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx<7.0,>=5.0->furo) (2024.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mayan\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mayan\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\mayan\\appdata\\roaming\\python\\python311\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: prettytable in c:\\users\\mayan\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from prettytable) (0.2.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mayan\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\mayan\\anaconda3\\lib\\site-packages (1.11.1)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from scipy) (1.24.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mayan\\anaconda3\\lib\\site-packages (57.5.0)\n",
      "Requirement already satisfied: sphinx-gallery in c:\\users\\mayan\\appdata\\roaming\\python\\python311\\site-packages (0.11.1)\n",
      "Requirement already satisfied: sphinx>=3 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx-gallery) (5.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (1.1.5)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (1.0.3)\n",
      "Requirement already satisfied: Jinja2>=2.3 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (3.1.2)\n",
      "Requirement already satisfied: Pygments>=2.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (2.15.1)\n",
      "Requirement already satisfied: docutils<0.19,>=0.14 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (0.18.1)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (2.2.0)\n",
      "Requirement already satisfied: babel>=1.3 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (2.11.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (0.7.12)\n",
      "Requirement already satisfied: imagesize in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.5.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (2.31.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (23.1)\n",
      "Requirement already satisfied: colorama>=0.3.5 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=3->sphinx-gallery) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from babel>=1.3->sphinx>=3->sphinx-gallery) (2023.3.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from Jinja2>=2.3->sphinx>=3->sphinx-gallery) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=3->sphinx-gallery) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=3->sphinx-gallery) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=3->sphinx-gallery) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=3->sphinx-gallery) (2024.2.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sphinxemoji in c:\\users\\mayan\\appdata\\roaming\\python\\python311\\site-packages (0.2.0)\n",
      "Requirement already satisfied: sphinx>=1.8 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinxemoji) (5.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (1.1.5)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (1.0.3)\n",
      "Requirement already satisfied: Jinja2>=2.3 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (3.1.2)\n",
      "Requirement already satisfied: Pygments>=2.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (2.15.1)\n",
      "Requirement already satisfied: docutils<0.19,>=0.14 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (0.18.1)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (2.2.0)\n",
      "Requirement already satisfied: babel>=1.3 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (2.11.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (0.7.12)\n",
      "Requirement already satisfied: imagesize in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.5.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (2.31.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (23.1)\n",
      "Requirement already satisfied: colorama>=0.3.5 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from sphinx>=1.8->sphinxemoji) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from babel>=1.3->sphinx>=1.8->sphinxemoji) (2023.3.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from Jinja2>=2.3->sphinx>=1.8->sphinxemoji) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=1.8->sphinxemoji) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=1.8->sphinxemoji) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=1.8->sphinxemoji) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mayan\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=1.8->sphinxemoji) (2024.2.2)\n",
      "Requirement already satisfied: termcolor in c:\\users\\mayan\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "^C\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install furo\n",
    "#!pip install graphviz\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install prettytable\n",
    "!pip install scikit-learn\n",
    "!pip install scipy\n",
    "!pip install setuptools\n",
    "!pip install sphinx-gallery\n",
    "!pip install sphinxemoji\n",
    "!pip install termcolor\n",
    "!pip install pydotplus\n",
    "#!winget install -e --id Graphviz.Graphviz\n",
    "\n",
    "!pip install trustee --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cb41ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import joblib\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from trustee import ClassificationTrustee\n",
    "from trustee.utils.tree import get_dt_info, top_k_prune\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640acaff",
   "metadata": {},
   "source": [
    "# SVM & PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7872c2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.9783677482792527\n"
     ]
    }
   ],
   "source": [
    "## PCA SVM\n",
    "\n",
    "# Load the df\n",
    "df = pd.read_csv(\"df_pca.csv\")\n",
    "\n",
    "y = df['feature_0']\n",
    "X = df.drop(columns = ['feature_0'], inplace = False)\n",
    "\n",
    "# Split the data into 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the SVM classifier - pca\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Perform 3-fold cross-validation on the training data\n",
    "#kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "#cross_val_scores = cross_val_score(svm_classifier, X_train, y_train, cv=kfold)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the cross-validation set\n",
    "#cv_score = cross_val_scores.mean()\n",
    "\n",
    "#print(\"Mean cross-validation accuracy:\", cv_score)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "test_score = svm_classifier.score(X_test, y_test)\n",
    "print(\"Test set accuracy:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ea6dd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.9783677482792527\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Define a pipeline to handle feature extraction and classification\n",
    "svmPipeline = Pipeline([\n",
    "    ('classifier', svm_classifier)      # Apply SVM classifier\n",
    "])\n",
    "\n",
    "# Train the classifier on the training set\n",
    "svmPipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "test_score = svmPipeline.score(X_test, y_test)\n",
    "print(\"Test set accuracy:\", test_score)\n",
    "\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = svmPipeline.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "#print(classification_report(y_test, y_pred, labels=['white','black']))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2523fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quic_text_rf.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #joblib.dump(svm_classifier, 'quic_text_svm_pca.joblib') # put model here to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db5f5445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the confusion matrix\n",
    "category_labels = ['GoogleDoc', 'GoogleDrive', 'Youtube']\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=category_labels, yticklabels=category_labels)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d42918",
   "metadata": {},
   "source": [
    "# Trustee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c45f2189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing training dataset using Pipeline(steps=[('classifier', SVC(kernel='linear'))]) as expert model\n",
      "Expert model score: 0.9831467612040493\n",
      "Initializing Trustee outer-loop with 10 iterations\n",
      "########## Outer-loop Iteration 0/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (1660, 1660) entries\n",
      "Student model 0-0 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9816266329540665\n",
      "Student model 0-0 fidelity: 0.9816266329540665\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (1810, 1810) entries\n",
      "Student model 0-1 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9937924670749099\n",
      "Student model 0-1 fidelity: 0.9937924670749099\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (1960, 1960) entries\n",
      "Student model 0-2 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9707755926202529\n",
      "Student model 0-2 fidelity: 0.9707755926202529\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (2110, 2110) entries\n",
      "Student model 0-3 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9659226242390786\n",
      "Student model 0-3 fidelity: 0.9659226242390786\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (2260, 2260) entries\n",
      "Student model 0-4 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9540085540085541\n",
      "Student model 0-4 fidelity: 0.9540085540085541\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (2410, 2410) entries\n",
      "Student model 0-5 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.985951856419554\n",
      "Student model 0-5 fidelity: 0.985951856419554\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (2560, 2560) entries\n",
      "Student model 0-6 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9873015873015873\n",
      "Student model 0-6 fidelity: 0.9873015873015873\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (2710, 2710) entries\n",
      "Student model 0-7 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.986532684645892\n",
      "Student model 0-7 fidelity: 0.986532684645892\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (2860, 2860) entries\n",
      "Student model 0-8 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9598080603399751\n",
      "Student model 0-8 fidelity: 0.9598080603399751\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (3010, 3010) entries\n",
      "Student model 0-9 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9656914832726621\n",
      "Student model 0-9 fidelity: 0.9656914832726621\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (3160, 3160) entries\n",
      "Student model 0-10 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9850447179360274\n",
      "Student model 0-10 fidelity: 0.9850447179360274\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (3310, 3310) entries\n",
      "Student model 0-11 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9606553472575007\n",
      "Student model 0-11 fidelity: 0.9606553472575007\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (3460, 3460) entries\n",
      "Student model 0-12 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9594574507617986\n",
      "Student model 0-12 fidelity: 0.9594574507617986\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (3610, 3610) entries\n",
      "Student model 0-13 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9627602584250043\n",
      "Student model 0-13 fidelity: 0.9627602584250043\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (3760, 3760) entries\n",
      "Student model 0-14 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9685678639927006\n",
      "Student model 0-14 fidelity: 0.9685678639927006\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (3910, 3910) entries\n",
      "Student model 0-15 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9467074361551235\n",
      "Student model 0-15 fidelity: 0.9467074361551235\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (4060, 4060) entries\n",
      "Student model 0-16 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9676318193617114\n",
      "Student model 0-16 fidelity: 0.9676318193617114\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (4210, 4210) entries\n",
      "Student model 0-17 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9502434582648486\n",
      "Student model 0-17 fidelity: 0.9502434582648486\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (4360, 4360) entries\n",
      "Student model 0-18 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9701104613385314\n",
      "Student model 0-18 fidelity: 0.9701104613385314\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (4510, 4510) entries\n",
      "Student model 0-19 trained with depth 5 and 15 leaves:\n",
      "Student model score: 0.9701937984496123\n",
      "Student model 0-19 fidelity: 0.9701937984496123\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (4660, 4660) entries\n",
      "Student model 0-20 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9503091403414344\n",
      "Student model 0-20 fidelity: 0.9503091403414344\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (4810, 4810) entries\n",
      "Student model 0-21 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9672165691252541\n",
      "Student model 0-21 fidelity: 0.9672165691252541\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (4960, 4960) entries\n",
      "Student model 0-22 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9676144434372796\n",
      "Student model 0-22 fidelity: 0.9676144434372796\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (5110, 5110) entries\n",
      "Student model 0-23 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9860924533038936\n",
      "Student model 0-23 fidelity: 0.9860924533038936\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (5260, 5260) entries\n",
      "Student model 0-24 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9628482972136223\n",
      "Student model 0-24 fidelity: 0.9628482972136223\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (5410, 5410) entries\n",
      "Student model 0-25 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9842592592592593\n",
      "Student model 0-25 fidelity: 0.9842592592592593\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (5560, 5560) entries\n",
      "Student model 0-26 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9489495732724712\n",
      "Student model 0-26 fidelity: 0.9489495732724712\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (5710, 5710) entries\n",
      "Student model 0-27 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9846873755475906\n",
      "Student model 0-27 fidelity: 0.9846873755475906\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (5860, 5860) entries\n",
      "Student model 0-28 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9775167361374258\n",
      "Student model 0-28 fidelity: 0.9775167361374258\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (6010, 6010) entries\n",
      "Student model 0-29 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9664861306239353\n",
      "Student model 0-29 fidelity: 0.9664861306239353\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (6160, 6160) entries\n",
      "Student model 0-30 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.993004329004329\n",
      "Student model 0-30 fidelity: 0.993004329004329\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (6310, 6310) entries\n",
      "Student model 0-31 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9858286540478055\n",
      "Student model 0-31 fidelity: 0.9858286540478055\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (6460, 6460) entries\n",
      "Student model 0-32 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9853289833779851\n",
      "Student model 0-32 fidelity: 0.9853289833779851\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (6610, 6610) entries\n",
      "Student model 0-33 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9756418696510862\n",
      "Student model 0-33 fidelity: 0.9756418696510862\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (6760, 6760) entries\n",
      "Student model 0-34 trained with depth 4 and 10 leaves:\n",
      "Student model score: 0.971179183135705\n",
      "Student model 0-34 fidelity: 0.971179183135705\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (6910, 6910) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 0-35 trained with depth 4 and 11 leaves:\n",
      "Student model score: 0.9863247863247864\n",
      "Student model 0-35 fidelity: 0.9863247863247864\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (7060, 7060) entries\n",
      "Student model 0-36 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.97410359386263\n",
      "Student model 0-36 fidelity: 0.97410359386263\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (7210, 7210) entries\n",
      "Student model 0-37 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9805868431084019\n",
      "Student model 0-37 fidelity: 0.9805868431084019\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (7360, 7360) entries\n",
      "Student model 0-38 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9791687248101139\n",
      "Student model 0-38 fidelity: 0.9791687248101139\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (7510, 7510) entries\n",
      "Student model 0-39 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9794653803637825\n",
      "Student model 0-39 fidelity: 0.9794653803637825\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (7660, 7660) entries\n",
      "Student model 0-40 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9633374626111708\n",
      "Student model 0-40 fidelity: 0.9633374626111708\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (7810, 7810) entries\n",
      "Student model 0-41 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.971322849213691\n",
      "Student model 0-41 fidelity: 0.971322849213691\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (7960, 7960) entries\n",
      "Student model 0-42 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9688897591893602\n",
      "Student model 0-42 fidelity: 0.9688897591893602\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (8110, 8110) entries\n",
      "Student model 0-43 trained with depth 4 and 9 leaves:\n",
      "Student model score: 1.0\n",
      "Student model 0-43 fidelity: 1.0\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (8260, 8260) entries\n",
      "Student model 0-44 trained with depth 4 and 10 leaves:\n",
      "Student model score: 0.9791865838526491\n",
      "Student model 0-44 fidelity: 0.9791865838526491\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (8410, 8410) entries\n",
      "Student model 0-45 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9308422708422709\n",
      "Student model 0-45 fidelity: 0.9308422708422709\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (8560, 8560) entries\n",
      "Student model 0-46 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9747724178249734\n",
      "Student model 0-46 fidelity: 0.9747724178249734\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (8710, 8710) entries\n",
      "Student model 0-47 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9921644654469081\n",
      "Student model 0-47 fidelity: 0.9921644654469081\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (8860, 8860) entries\n",
      "Student model 0-48 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9588879326831133\n",
      "Student model 0-48 fidelity: 0.9588879326831133\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (9010, 9010) entries\n",
      "Student model 0-49 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9807536170810507\n",
      "Student model 0-49 fidelity: 0.9807536170810507\n",
      "########## Outer-loop Iteration 1/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (9160, 9160) entries\n",
      "Student model 1-0 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9763527611628877\n",
      "Student model 1-0 fidelity: 0.9763527611628877\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (9310, 9310) entries\n",
      "Student model 1-1 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9869597615499255\n",
      "Student model 1-1 fidelity: 0.9869597615499255\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (9460, 9460) entries\n",
      "Student model 1-2 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9535522714833059\n",
      "Student model 1-2 fidelity: 0.9535522714833059\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (9610, 9610) entries\n",
      "Student model 1-3 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9707114005950502\n",
      "Student model 1-3 fidelity: 0.9707114005950502\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (9760, 9760) entries\n",
      "Student model 1-4 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9865983445013796\n",
      "Student model 1-4 fidelity: 0.9865983445013796\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (9910, 9910) entries\n",
      "Student model 1-5 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9656236700835684\n",
      "Student model 1-5 fidelity: 0.9656236700835684\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (10060, 10060) entries\n",
      "Student model 1-6 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9840659340659341\n",
      "Student model 1-6 fidelity: 0.9840659340659341\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (10210, 10210) entries\n",
      "Student model 1-7 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9662482901277817\n",
      "Student model 1-7 fidelity: 0.9662482901277817\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (10360, 10360) entries\n",
      "Student model 1-8 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9929323364207864\n",
      "Student model 1-8 fidelity: 0.9929323364207864\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (10510, 10510) entries\n",
      "Student model 1-9 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9799708313077297\n",
      "Student model 1-9 fidelity: 0.9799708313077297\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (10660, 10660) entries\n",
      "Student model 1-10 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9799935677099035\n",
      "Student model 1-10 fidelity: 0.9799935677099035\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (10810, 10810) entries\n",
      "Student model 1-11 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9846723044397464\n",
      "Student model 1-11 fidelity: 0.9846723044397464\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (10960, 10960) entries\n",
      "Student model 1-12 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9653427156208023\n",
      "Student model 1-12 fidelity: 0.9653427156208023\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (11110, 11110) entries\n",
      "Student model 1-13 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.985397840483349\n",
      "Student model 1-13 fidelity: 0.985397840483349\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (11260, 11260) entries\n",
      "Student model 1-14 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9604794454606719\n",
      "Student model 1-14 fidelity: 0.9604794454606719\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (11410, 11410) entries\n",
      "Student model 1-15 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9878516624040921\n",
      "Student model 1-15 fidelity: 0.9878516624040921\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (11560, 11560) entries\n",
      "Student model 1-16 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9584070144414972\n",
      "Student model 1-16 fidelity: 0.9584070144414972\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (11710, 11710) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 1-17 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9737373737373737\n",
      "Student model 1-17 fidelity: 0.9737373737373737\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (11860, 11860) entries\n",
      "Student model 1-18 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9541908185975982\n",
      "Student model 1-18 fidelity: 0.9541908185975982\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (12010, 12010) entries\n",
      "Student model 1-19 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9627602584250043\n",
      "Student model 1-19 fidelity: 0.9627602584250043\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (12160, 12160) entries\n",
      "Student model 1-20 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9735228539576366\n",
      "Student model 1-20 fidelity: 0.9735228539576366\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (12310, 12310) entries\n",
      "Student model 1-21 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9856985674773816\n",
      "Student model 1-21 fidelity: 0.9856985674773816\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (12460, 12460) entries\n",
      "Student model 1-22 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9866184932423391\n",
      "Student model 1-22 fidelity: 0.9866184932423391\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (12610, 12610) entries\n",
      "Student model 1-23 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9522167266342462\n",
      "Student model 1-23 fidelity: 0.9522167266342462\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (12760, 12760) entries\n",
      "Student model 1-24 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9856050382366172\n",
      "Student model 1-24 fidelity: 0.9856050382366172\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (12910, 12910) entries\n",
      "Student model 1-25 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9765432098765432\n",
      "Student model 1-25 fidelity: 0.9765432098765432\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (13060, 13060) entries\n",
      "Student model 1-26 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.944295455654256\n",
      "Student model 1-26 fidelity: 0.944295455654256\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (13210, 13210) entries\n",
      "Student model 1-27 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9857121143030856\n",
      "Student model 1-27 fidelity: 0.9857121143030856\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (13360, 13360) entries\n",
      "Student model 1-28 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.972830392677721\n",
      "Student model 1-28 fidelity: 0.972830392677721\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (13510, 13510) entries\n",
      "Student model 1-29 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9381499726327313\n",
      "Student model 1-29 fidelity: 0.9381499726327313\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (13660, 13660) entries\n",
      "Student model 1-30 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9792862183687872\n",
      "Student model 1-30 fidelity: 0.9792862183687872\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (13810, 13810) entries\n",
      "Student model 1-31 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9805057471264368\n",
      "Student model 1-31 fidelity: 0.9805057471264368\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (13960, 13960) entries\n",
      "Student model 1-32 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9738362707073143\n",
      "Student model 1-32 fidelity: 0.9738362707073143\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (14110, 14110) entries\n",
      "Student model 1-33 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9931798806479112\n",
      "Student model 1-33 fidelity: 0.9931798806479112\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (14260, 14260) entries\n",
      "Student model 1-34 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.96735594154949\n",
      "Student model 1-34 fidelity: 0.96735594154949\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (14410, 14410) entries\n",
      "Student model 1-35 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9925055787124752\n",
      "Student model 1-35 fidelity: 0.9925055787124752\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (14560, 14560) entries\n",
      "Student model 1-36 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9714117300324198\n",
      "Student model 1-36 fidelity: 0.9714117300324198\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (14710, 14710) entries\n",
      "Student model 1-37 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9912725685921563\n",
      "Student model 1-37 fidelity: 0.9912725685921563\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (14860, 14860) entries\n",
      "Student model 1-38 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9757495590828924\n",
      "Student model 1-38 fidelity: 0.9757495590828924\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (15010, 15010) entries\n",
      "Student model 1-39 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9727743503077937\n",
      "Student model 1-39 fidelity: 0.9727743503077937\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (15160, 15160) entries\n",
      "Student model 1-40 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.987029721107551\n",
      "Student model 1-40 fidelity: 0.987029721107551\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (15310, 15310) entries\n",
      "Student model 1-41 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9480657749770899\n",
      "Student model 1-41 fidelity: 0.9480657749770899\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (15460, 15460) entries\n",
      "Student model 1-42 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9804289093616921\n",
      "Student model 1-42 fidelity: 0.9804289093616921\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (15610, 15610) entries\n",
      "Student model 1-43 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9415278138746909\n",
      "Student model 1-43 fidelity: 0.9415278138746909\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (15760, 15760) entries\n",
      "Student model 1-44 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9712468410142829\n",
      "Student model 1-44 fidelity: 0.9712468410142829\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (15910, 15910) entries\n",
      "Student model 1-45 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9702452355267889\n",
      "Student model 1-45 fidelity: 0.9702452355267889\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (16060, 16060) entries\n",
      "Student model 1-46 trained with depth 6 and 11 leaves:\n",
      "Student model score: 1.0\n",
      "Student model 1-46 fidelity: 1.0\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (16210, 16210) entries\n",
      "Student model 1-47 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9663437936633813\n",
      "Student model 1-47 fidelity: 0.9663437936633813\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (16360, 16360) entries\n",
      "Student model 1-48 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.95785169710929\n",
      "Student model 1-48 fidelity: 0.95785169710929\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (16510, 16510) entries\n",
      "Student model 1-49 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9732236862598511\n",
      "Student model 1-49 fidelity: 0.9732236862598511\n",
      "########## Outer-loop Iteration 2/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (16660, 16660) entries\n",
      "Student model 2-0 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9491634491634492\n",
      "Student model 2-0 fidelity: 0.9491634491634492\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (16810, 16810) entries\n",
      "Student model 2-1 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9732048647934355\n",
      "Student model 2-1 fidelity: 0.9732048647934355\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (16960, 16960) entries\n",
      "Student model 2-2 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9636396624348431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 2-2 fidelity: 0.9636396624348431\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (17110, 17110) entries\n",
      "Student model 2-3 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.97458535418283\n",
      "Student model 2-3 fidelity: 0.97458535418283\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (17260, 17260) entries\n",
      "Student model 2-4 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9803055246976689\n",
      "Student model 2-4 fidelity: 0.9803055246976689\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (17410, 17410) entries\n",
      "Student model 2-5 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9713915869378055\n",
      "Student model 2-5 fidelity: 0.9713915869378055\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (17560, 17560) entries\n",
      "Student model 2-6 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9706924315619968\n",
      "Student model 2-6 fidelity: 0.9706924315619968\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (17710, 17710) entries\n",
      "Student model 2-7 trained with depth 3 and 7 leaves:\n",
      "Student model score: 0.97215329473394\n",
      "Student model 2-7 fidelity: 0.97215329473394\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (17860, 17860) entries\n",
      "Student model 2-8 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9669150390370916\n",
      "Student model 2-8 fidelity: 0.9669150390370916\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (18010, 18010) entries\n",
      "Student model 2-9 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9641309693393025\n",
      "Student model 2-9 fidelity: 0.9641309693393025\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (18160, 18160) entries\n",
      "Student model 2-10 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9851190476190476\n",
      "Student model 2-10 fidelity: 0.9851190476190476\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (18310, 18310) entries\n",
      "Student model 2-11 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9823529411764707\n",
      "Student model 2-11 fidelity: 0.9823529411764707\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (18460, 18460) entries\n",
      "Student model 2-12 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9932411674347158\n",
      "Student model 2-12 fidelity: 0.9932411674347158\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (18610, 18610) entries\n",
      "Student model 2-13 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9784736842105263\n",
      "Student model 2-13 fidelity: 0.9784736842105263\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (18760, 18760) entries\n",
      "Student model 2-14 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9656333116213428\n",
      "Student model 2-14 fidelity: 0.9656333116213428\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (18910, 18910) entries\n",
      "Student model 2-15 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.992271818787475\n",
      "Student model 2-15 fidelity: 0.992271818787475\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (19060, 19060) entries\n",
      "Student model 2-16 trained with depth 4 and 10 leaves:\n",
      "Student model score: 0.9857898715041573\n",
      "Student model 2-16 fidelity: 0.9857898715041573\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (19210, 19210) entries\n",
      "Student model 2-17 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9797523623330076\n",
      "Student model 2-17 fidelity: 0.9797523623330076\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (19360, 19360) entries\n",
      "Student model 2-18 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9863756613756612\n",
      "Student model 2-18 fidelity: 0.9863756613756612\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (19510, 19510) entries\n",
      "Student model 2-19 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9862514029180697\n",
      "Student model 2-19 fidelity: 0.9862514029180697\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (19660, 19660) entries\n",
      "Student model 2-20 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9926739926739927\n",
      "Student model 2-20 fidelity: 0.9926739926739927\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (19810, 19810) entries\n",
      "Student model 2-21 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9713311548927988\n",
      "Student model 2-21 fidelity: 0.9713311548927988\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (19960, 19960) entries\n",
      "Student model 2-22 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9938906154540866\n",
      "Student model 2-22 fidelity: 0.9938906154540866\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (20110, 20110) entries\n",
      "Student model 2-23 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9730996707247769\n",
      "Student model 2-23 fidelity: 0.9730996707247769\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (20260, 20260) entries\n",
      "Student model 2-24 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9791687248101139\n",
      "Student model 2-24 fidelity: 0.9791687248101139\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (20410, 20410) entries\n",
      "Student model 2-25 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9828067913174298\n",
      "Student model 2-25 fidelity: 0.9828067913174298\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (20560, 20560) entries\n",
      "Student model 2-26 trained with depth 4 and 6 leaves:\n",
      "Student model score: 0.9328924162257497\n",
      "Student model 2-26 fidelity: 0.9328924162257497\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (20710, 20710) entries\n",
      "Student model 2-27 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9717678553885452\n",
      "Student model 2-27 fidelity: 0.9717678553885452\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (20860, 20860) entries\n",
      "Student model 2-28 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9718013468013468\n",
      "Student model 2-28 fidelity: 0.9718013468013468\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (21010, 21010) entries\n",
      "Student model 2-29 trained with depth 3 and 6 leaves:\n",
      "Student model score: 0.9789667964110155\n",
      "Student model 2-29 fidelity: 0.9789667964110155\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (21160, 21160) entries\n",
      "Student model 2-30 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9780086580086581\n",
      "Student model 2-30 fidelity: 0.9780086580086581\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (21310, 21310) entries\n",
      "Student model 2-31 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9724501214552799\n",
      "Student model 2-31 fidelity: 0.9724501214552799\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (21460, 21460) entries\n",
      "Student model 2-32 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.970959595959596\n",
      "Student model 2-32 fidelity: 0.970959595959596\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (21610, 21610) entries\n",
      "Student model 2-33 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9701312103788884\n",
      "Student model 2-33 fidelity: 0.9701312103788884\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (21760, 21760) entries\n",
      "Student model 2-34 trained with depth 4 and 6 leaves:\n",
      "Student model score: 0.9786335758094422\n",
      "Student model 2-34 fidelity: 0.9786335758094422\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (21910, 21910) entries\n",
      "Student model 2-35 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9716745455244243\n",
      "Student model 2-35 fidelity: 0.9716745455244243\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (22060, 22060) entries\n",
      "Student model 2-36 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9716269841269841\n",
      "Student model 2-36 fidelity: 0.9716269841269841\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (22210, 22210) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 2-37 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9788939624556062\n",
      "Student model 2-37 fidelity: 0.9788939624556062\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (22360, 22360) entries\n",
      "Student model 2-38 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9604407219433427\n",
      "Student model 2-38 fidelity: 0.9604407219433427\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (22510, 22510) entries\n",
      "Student model 2-39 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9859978794751258\n",
      "Student model 2-39 fidelity: 0.9859978794751258\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (22660, 22660) entries\n",
      "Student model 2-40 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9784078144078143\n",
      "Student model 2-40 fidelity: 0.9784078144078143\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (22810, 22810) entries\n",
      "Student model 2-41 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9871615312791784\n",
      "Student model 2-41 fidelity: 0.9871615312791784\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (22960, 22960) entries\n",
      "Student model 2-42 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.986120909388236\n",
      "Student model 2-42 fidelity: 0.986120909388236\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (23110, 23110) entries\n",
      "Student model 2-43 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9795211213036605\n",
      "Student model 2-43 fidelity: 0.9795211213036605\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (23260, 23260) entries\n",
      "Student model 2-44 trained with depth 7 and 11 leaves:\n",
      "Student model score: 1.0\n",
      "Student model 2-44 fidelity: 1.0\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (23410, 23410) entries\n",
      "Student model 2-45 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9878516624040921\n",
      "Student model 2-45 fidelity: 0.9878516624040921\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (23560, 23560) entries\n",
      "Student model 2-46 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9439859703913522\n",
      "Student model 2-46 fidelity: 0.9439859703913522\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (23710, 23710) entries\n",
      "Student model 2-47 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9913419913419914\n",
      "Student model 2-47 fidelity: 0.9913419913419914\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (23860, 23860) entries\n",
      "Student model 2-48 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.965263748597082\n",
      "Student model 2-48 fidelity: 0.965263748597082\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (24010, 24010) entries\n",
      "Student model 2-49 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9663373839798273\n",
      "Student model 2-49 fidelity: 0.9663373839798273\n",
      "########## Outer-loop Iteration 3/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (24160, 24160) entries\n",
      "Student model 3-0 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9386116129887783\n",
      "Student model 3-0 fidelity: 0.9386116129887783\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (24310, 24310) entries\n",
      "Student model 3-1 trained with depth 4 and 11 leaves:\n",
      "Student model score: 0.9693005407291122\n",
      "Student model 3-1 fidelity: 0.9693005407291122\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (24460, 24460) entries\n",
      "Student model 3-2 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9790943752741507\n",
      "Student model 3-2 fidelity: 0.9790943752741507\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (24610, 24610) entries\n",
      "Student model 3-3 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9934483090856538\n",
      "Student model 3-3 fidelity: 0.9934483090856538\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (24760, 24760) entries\n",
      "Student model 3-4 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9640078950423777\n",
      "Student model 3-4 fidelity: 0.9640078950423777\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (24910, 24910) entries\n",
      "Student model 3-5 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9609777015437393\n",
      "Student model 3-5 fidelity: 0.9609777015437393\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (25060, 25060) entries\n",
      "Student model 3-6 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9858474858474859\n",
      "Student model 3-6 fidelity: 0.9858474858474859\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (25210, 25210) entries\n",
      "Student model 3-7 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.956935316499481\n",
      "Student model 3-7 fidelity: 0.956935316499481\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (25360, 25360) entries\n",
      "Student model 3-8 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9873004354136429\n",
      "Student model 3-8 fidelity: 0.9873004354136429\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (25510, 25510) entries\n",
      "Student model 3-9 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9733986732006534\n",
      "Student model 3-9 fidelity: 0.9733986732006534\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (25660, 25660) entries\n",
      "Student model 3-10 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9927775877142965\n",
      "Student model 3-10 fidelity: 0.9927775877142965\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (25810, 25810) entries\n",
      "Student model 3-11 trained with depth 5 and 7 leaves:\n",
      "Student model score: 0.9605922096087322\n",
      "Student model 3-11 fidelity: 0.9605922096087322\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (25960, 25960) entries\n",
      "Student model 3-12 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.8881762492699292\n",
      "Student model 3-12 fidelity: 0.8881762492699292\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (26110, 26110) entries\n",
      "Student model 3-13 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9865732421842323\n",
      "Student model 3-13 fidelity: 0.9865732421842323\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (26260, 26260) entries\n",
      "Student model 3-14 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9720389484716181\n",
      "Student model 3-14 fidelity: 0.9720389484716181\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (26410, 26410) entries\n",
      "Student model 3-15 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9938712413472325\n",
      "Student model 3-15 fidelity: 0.9938712413472325\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (26560, 26560) entries\n",
      "Student model 3-16 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9704713064713064\n",
      "Student model 3-16 fidelity: 0.9704713064713064\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (26710, 26710) entries\n",
      "Student model 3-17 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.992007992007992\n",
      "Student model 3-17 fidelity: 0.992007992007992\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (26860, 26860) entries\n",
      "Student model 3-18 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9782653089739703\n",
      "Student model 3-18 fidelity: 0.9782653089739703\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (27010, 27010) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 3-19 trained with depth 6 and 10 leaves:\n",
      "Student model score: 1.0\n",
      "Student model 3-19 fidelity: 1.0\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (27160, 27160) entries\n",
      "Student model 3-20 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9670327047679054\n",
      "Student model 3-20 fidelity: 0.9670327047679054\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (27310, 27310) entries\n",
      "Student model 3-21 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.937206548241031\n",
      "Student model 3-21 fidelity: 0.937206548241031\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (27460, 27460) entries\n",
      "Student model 3-22 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9736701405851381\n",
      "Student model 3-22 fidelity: 0.9736701405851381\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (27610, 27610) entries\n",
      "Student model 3-23 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9934127676063159\n",
      "Student model 3-23 fidelity: 0.9934127676063159\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (27760, 27760) entries\n",
      "Student model 3-24 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9802352941176471\n",
      "Student model 3-24 fidelity: 0.9802352941176471\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (27910, 27910) entries\n",
      "Student model 3-25 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9724308486985972\n",
      "Student model 3-25 fidelity: 0.9724308486985972\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (28060, 28060) entries\n",
      "Student model 3-26 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9854939718125794\n",
      "Student model 3-26 fidelity: 0.9854939718125794\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (28210, 28210) entries\n",
      "Student model 3-27 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.960421613964921\n",
      "Student model 3-27 fidelity: 0.960421613964921\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (28360, 28360) entries\n",
      "Student model 3-28 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9864197530864197\n",
      "Student model 3-28 fidelity: 0.9864197530864197\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (28510, 28510) entries\n",
      "Student model 3-29 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9687750881437825\n",
      "Student model 3-29 fidelity: 0.9687750881437825\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (28660, 28660) entries\n",
      "Student model 3-30 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9529477046222142\n",
      "Student model 3-30 fidelity: 0.9529477046222142\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (28810, 28810) entries\n",
      "Student model 3-31 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9555866079494129\n",
      "Student model 3-31 fidelity: 0.9555866079494129\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (28960, 28960) entries\n",
      "Student model 3-32 trained with depth 4 and 11 leaves:\n",
      "Student model score: 0.9711759504862952\n",
      "Student model 3-32 fidelity: 0.9711759504862952\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (29110, 29110) entries\n",
      "Student model 3-33 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9244825170826543\n",
      "Student model 3-33 fidelity: 0.9244825170826543\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (29260, 29260) entries\n",
      "Student model 3-34 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.986231175575253\n",
      "Student model 3-34 fidelity: 0.986231175575253\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (29410, 29410) entries\n",
      "Student model 3-35 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9464194019828573\n",
      "Student model 3-35 fidelity: 0.9464194019828573\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (29560, 29560) entries\n",
      "Student model 3-36 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9395180482521767\n",
      "Student model 3-36 fidelity: 0.9395180482521767\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (29710, 29710) entries\n",
      "Student model 3-37 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9667260843731432\n",
      "Student model 3-37 fidelity: 0.9667260843731432\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (29860, 29860) entries\n",
      "Student model 3-38 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9645069072117707\n",
      "Student model 3-38 fidelity: 0.9645069072117707\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (30010, 30010) entries\n",
      "Student model 3-39 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9928182555311015\n",
      "Student model 3-39 fidelity: 0.9928182555311015\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (30160, 30160) entries\n",
      "Student model 3-40 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9737225451511167\n",
      "Student model 3-40 fidelity: 0.9737225451511167\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (30310, 30310) entries\n",
      "Student model 3-41 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9746986513903807\n",
      "Student model 3-41 fidelity: 0.9746986513903807\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (30460, 30460) entries\n",
      "Student model 3-42 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9546445489510789\n",
      "Student model 3-42 fidelity: 0.9546445489510789\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (30610, 30610) entries\n",
      "Student model 3-43 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9781674602252933\n",
      "Student model 3-43 fidelity: 0.9781674602252933\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (30760, 30760) entries\n",
      "Student model 3-44 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9845464892656697\n",
      "Student model 3-44 fidelity: 0.9845464892656697\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (30910, 30910) entries\n",
      "Student model 3-45 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9734242696506848\n",
      "Student model 3-45 fidelity: 0.9734242696506848\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (31060, 31060) entries\n",
      "Student model 3-46 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9543937602761132\n",
      "Student model 3-46 fidelity: 0.9543937602761132\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (31210, 31210) entries\n",
      "Student model 3-47 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9473925604911521\n",
      "Student model 3-47 fidelity: 0.9473925604911521\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (31360, 31360) entries\n",
      "Student model 3-48 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9707818184720027\n",
      "Student model 3-48 fidelity: 0.9707818184720027\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (31510, 31510) entries\n",
      "Student model 3-49 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9859261581330546\n",
      "Student model 3-49 fidelity: 0.9859261581330546\n",
      "########## Outer-loop Iteration 4/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (31660, 31660) entries\n",
      "Student model 4-0 trained with depth 4 and 7 leaves:\n",
      "Student model score: 1.0\n",
      "Student model 4-0 fidelity: 1.0\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (31810, 31810) entries\n",
      "Student model 4-1 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.978134284016637\n",
      "Student model 4-1 fidelity: 0.978134284016637\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (31960, 31960) entries\n",
      "Student model 4-2 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9870440251572328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 4-2 fidelity: 0.9870440251572328\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (32110, 32110) entries\n",
      "Student model 4-3 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9509971857728953\n",
      "Student model 4-3 fidelity: 0.9509971857728953\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (32260, 32260) entries\n",
      "Student model 4-4 trained with depth 4 and 11 leaves:\n",
      "Student model score: 0.9483418310871334\n",
      "Student model 4-4 fidelity: 0.9483418310871334\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (32410, 32410) entries\n",
      "Student model 4-5 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9654406251650034\n",
      "Student model 4-5 fidelity: 0.9654406251650034\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (32560, 32560) entries\n",
      "Student model 4-6 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9671363243109629\n",
      "Student model 4-6 fidelity: 0.9671363243109629\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (32710, 32710) entries\n",
      "Student model 4-7 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9776629342520815\n",
      "Student model 4-7 fidelity: 0.9776629342520815\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (32860, 32860) entries\n",
      "Student model 4-8 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9650290446174762\n",
      "Student model 4-8 fidelity: 0.9650290446174762\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (33010, 33010) entries\n",
      "Student model 4-9 trained with depth 5 and 10 leaves:\n",
      "Student model score: 1.0\n",
      "Student model 4-9 fidelity: 1.0\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (33160, 33160) entries\n",
      "Student model 4-10 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9610902347971314\n",
      "Student model 4-10 fidelity: 0.9610902347971314\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (33310, 33310) entries\n",
      "Student model 4-11 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9730573017674266\n",
      "Student model 4-11 fidelity: 0.9730573017674266\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (33460, 33460) entries\n",
      "Student model 4-12 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.992772444946358\n",
      "Student model 4-12 fidelity: 0.992772444946358\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (33610, 33610) entries\n",
      "Student model 4-13 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9850983328012096\n",
      "Student model 4-13 fidelity: 0.9850983328012096\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (33760, 33760) entries\n",
      "Student model 4-14 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9612385665017245\n",
      "Student model 4-14 fidelity: 0.9612385665017245\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (33910, 33910) entries\n",
      "Student model 4-15 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9719444917464718\n",
      "Student model 4-15 fidelity: 0.9719444917464718\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (34060, 34060) entries\n",
      "Student model 4-16 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9937101320278892\n",
      "Student model 4-16 fidelity: 0.9937101320278892\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (34210, 34210) entries\n",
      "Student model 4-17 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9869554204660588\n",
      "Student model 4-17 fidelity: 0.9869554204660588\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (34360, 34360) entries\n",
      "Student model 4-18 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9654191039840917\n",
      "Student model 4-18 fidelity: 0.9654191039840917\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (34510, 34510) entries\n",
      "Student model 4-19 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9673816161271359\n",
      "Student model 4-19 fidelity: 0.9673816161271359\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (34660, 34660) entries\n",
      "Student model 4-20 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9800091102134871\n",
      "Student model 4-20 fidelity: 0.9800091102134871\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (34810, 34810) entries\n",
      "Student model 4-21 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9802902573237501\n",
      "Student model 4-21 fidelity: 0.9802902573237501\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (34960, 34960) entries\n",
      "Student model 4-22 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9713378428314895\n",
      "Student model 4-22 fidelity: 0.9713378428314895\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (35110, 35110) entries\n",
      "Student model 4-23 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9858465608465609\n",
      "Student model 4-23 fidelity: 0.9858465608465609\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (35260, 35260) entries\n",
      "Student model 4-24 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9661368240610876\n",
      "Student model 4-24 fidelity: 0.9661368240610876\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (35410, 35410) entries\n",
      "Student model 4-25 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9543716082349901\n",
      "Student model 4-25 fidelity: 0.9543716082349901\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (35560, 35560) entries\n",
      "Student model 4-26 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.979080179080179\n",
      "Student model 4-26 fidelity: 0.979080179080179\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (35710, 35710) entries\n",
      "Student model 4-27 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9871794871794872\n",
      "Student model 4-27 fidelity: 0.9871794871794872\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (35860, 35860) entries\n",
      "Student model 4-28 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9711612210461728\n",
      "Student model 4-28 fidelity: 0.9711612210461728\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (36010, 36010) entries\n",
      "Student model 4-29 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9474331869680707\n",
      "Student model 4-29 fidelity: 0.9474331869680707\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (36160, 36160) entries\n",
      "Student model 4-30 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9653918308694499\n",
      "Student model 4-30 fidelity: 0.9653918308694499\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (36310, 36310) entries\n",
      "Student model 4-31 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9923021613162457\n",
      "Student model 4-31 fidelity: 0.9923021613162457\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (36460, 36460) entries\n",
      "Student model 4-32 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9863888888888889\n",
      "Student model 4-32 fidelity: 0.9863888888888889\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (36610, 36610) entries\n",
      "Student model 4-33 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9929258317674367\n",
      "Student model 4-33 fidelity: 0.9929258317674367\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (36760, 36760) entries\n",
      "Student model 4-34 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.980584014038617\n",
      "Student model 4-34 fidelity: 0.980584014038617\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (36910, 36910) entries\n",
      "Student model 4-35 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9675061132884467\n",
      "Student model 4-35 fidelity: 0.9675061132884467\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (37060, 37060) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 4-36 trained with depth 4 and 6 leaves:\n",
      "Student model score: 0.9502788955665883\n",
      "Student model 4-36 fidelity: 0.9502788955665883\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (37210, 37210) entries\n",
      "Student model 4-37 trained with depth 4 and 10 leaves:\n",
      "Student model score: 0.9725266913461023\n",
      "Student model 4-37 fidelity: 0.9725266913461023\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (37360, 37360) entries\n",
      "Student model 4-38 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.973180722590636\n",
      "Student model 4-38 fidelity: 0.973180722590636\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (37510, 37510) entries\n",
      "Student model 4-39 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9925844436295481\n",
      "Student model 4-39 fidelity: 0.9925844436295481\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (37660, 37660) entries\n",
      "Student model 4-40 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9861281625511097\n",
      "Student model 4-40 fidelity: 0.9861281625511097\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (37810, 37810) entries\n",
      "Student model 4-41 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9732048647934355\n",
      "Student model 4-41 fidelity: 0.9732048647934355\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (37960, 37960) entries\n",
      "Student model 4-42 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9866081853750925\n",
      "Student model 4-42 fidelity: 0.9866081853750925\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (38110, 38110) entries\n",
      "Student model 4-43 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9794677564038672\n",
      "Student model 4-43 fidelity: 0.9794677564038672\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (38260, 38260) entries\n",
      "Student model 4-44 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9468773382732193\n",
      "Student model 4-44 fidelity: 0.9468773382732193\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (38410, 38410) entries\n",
      "Student model 4-45 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9934117647058823\n",
      "Student model 4-45 fidelity: 0.9934117647058823\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (38560, 38560) entries\n",
      "Student model 4-46 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.971471984805318\n",
      "Student model 4-46 fidelity: 0.971471984805318\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (38710, 38710) entries\n",
      "Student model 4-47 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.985864611305851\n",
      "Student model 4-47 fidelity: 0.985864611305851\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (38860, 38860) entries\n",
      "Student model 4-48 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9581578947368422\n",
      "Student model 4-48 fidelity: 0.9581578947368422\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (39010, 39010) entries\n",
      "Student model 4-49 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9698713385974599\n",
      "Student model 4-49 fidelity: 0.9698713385974599\n",
      "########## Outer-loop Iteration 5/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (39160, 39160) entries\n",
      "Student model 5-0 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9540168187511182\n",
      "Student model 5-0 fidelity: 0.9540168187511182\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (39310, 39310) entries\n",
      "Student model 5-1 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9787209960384833\n",
      "Student model 5-1 fidelity: 0.9787209960384833\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (39460, 39460) entries\n",
      "Student model 5-2 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9408217001914781\n",
      "Student model 5-2 fidelity: 0.9408217001914781\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (39610, 39610) entries\n",
      "Student model 5-3 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9603506443227697\n",
      "Student model 5-3 fidelity: 0.9603506443227697\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (39760, 39760) entries\n",
      "Student model 5-4 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9393869519768799\n",
      "Student model 5-4 fidelity: 0.9393869519768799\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (39910, 39910) entries\n",
      "Student model 5-5 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.987160674981658\n",
      "Student model 5-5 fidelity: 0.987160674981658\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (40060, 40060) entries\n",
      "Student model 5-6 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9558259971833672\n",
      "Student model 5-6 fidelity: 0.9558259971833672\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (40210, 40210) entries\n",
      "Student model 5-7 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9857425140598876\n",
      "Student model 5-7 fidelity: 0.9857425140598876\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (40360, 40360) entries\n",
      "Student model 5-8 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9642850026145325\n",
      "Student model 5-8 fidelity: 0.9642850026145325\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (40510, 40510) entries\n",
      "Student model 5-9 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9525593891402714\n",
      "Student model 5-9 fidelity: 0.9525593891402714\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (40660, 40660) entries\n",
      "Student model 5-10 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9397465689839698\n",
      "Student model 5-10 fidelity: 0.9397465689839698\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (40810, 40810) entries\n",
      "Student model 5-11 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9768136093163137\n",
      "Student model 5-11 fidelity: 0.9768136093163137\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (40960, 40960) entries\n",
      "Student model 5-12 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9727529772361478\n",
      "Student model 5-12 fidelity: 0.9727529772361478\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (41110, 41110) entries\n",
      "Student model 5-13 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9710913329095147\n",
      "Student model 5-13 fidelity: 0.9710913329095147\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (41260, 41260) entries\n",
      "Student model 5-14 trained with depth 4 and 9 leaves:\n",
      "Student model score: 1.0\n",
      "Student model 5-14 fidelity: 1.0\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (41410, 41410) entries\n",
      "Student model 5-15 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9503782746160795\n",
      "Student model 5-15 fidelity: 0.9503782746160795\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (41560, 41560) entries\n",
      "Student model 5-16 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9439531931335211\n",
      "Student model 5-16 fidelity: 0.9439531931335211\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (41710, 41710) entries\n",
      "Student model 5-17 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9688325630354616\n",
      "Student model 5-17 fidelity: 0.9688325630354616\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (41860, 41860) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 5-18 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9416051057842102\n",
      "Student model 5-18 fidelity: 0.9416051057842102\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (42010, 42010) entries\n",
      "Student model 5-19 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9646973988324862\n",
      "Student model 5-19 fidelity: 0.9646973988324862\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (42160, 42160) entries\n",
      "Student model 5-20 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9537756433450654\n",
      "Student model 5-20 fidelity: 0.9537756433450654\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (42310, 42310) entries\n",
      "Student model 5-21 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9514906477170628\n",
      "Student model 5-21 fidelity: 0.9514906477170628\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (42460, 42460) entries\n",
      "Student model 5-22 trained with depth 3 and 6 leaves:\n",
      "Student model score: 0.9742002647715168\n",
      "Student model 5-22 fidelity: 0.9742002647715168\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (42610, 42610) entries\n",
      "Student model 5-23 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9791023842917251\n",
      "Student model 5-23 fidelity: 0.9791023842917251\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (42760, 42760) entries\n",
      "Student model 5-24 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9722294372294372\n",
      "Student model 5-24 fidelity: 0.9722294372294372\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (42910, 42910) entries\n",
      "Student model 5-25 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9866122256947945\n",
      "Student model 5-25 fidelity: 0.9866122256947945\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (43060, 43060) entries\n",
      "Student model 5-26 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9921963613266186\n",
      "Student model 5-26 fidelity: 0.9921963613266186\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (43210, 43210) entries\n",
      "Student model 5-27 trained with depth 3 and 6 leaves:\n",
      "Student model score: 0.9594049694856146\n",
      "Student model 5-27 fidelity: 0.9594049694856146\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (43360, 43360) entries\n",
      "Student model 5-28 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9734965516532536\n",
      "Student model 5-28 fidelity: 0.9734965516532536\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (43510, 43510) entries\n",
      "Student model 5-29 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9912143806716375\n",
      "Student model 5-29 fidelity: 0.9912143806716375\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (43660, 43660) entries\n",
      "Student model 5-30 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9649642950813465\n",
      "Student model 5-30 fidelity: 0.9649642950813465\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (43810, 43810) entries\n",
      "Student model 5-31 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9862949987512066\n",
      "Student model 5-31 fidelity: 0.9862949987512066\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (43960, 43960) entries\n",
      "Student model 5-32 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9772462831286362\n",
      "Student model 5-32 fidelity: 0.9772462831286362\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (44110, 44110) entries\n",
      "Student model 5-33 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9867521367521368\n",
      "Student model 5-33 fidelity: 0.9867521367521368\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (44260, 44260) entries\n",
      "Student model 5-34 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9858241988390489\n",
      "Student model 5-34 fidelity: 0.9858241988390489\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (44410, 44410) entries\n",
      "Student model 5-35 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9669080442276318\n",
      "Student model 5-35 fidelity: 0.9669080442276318\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (44560, 44560) entries\n",
      "Student model 5-36 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9929005702201579\n",
      "Student model 5-36 fidelity: 0.9929005702201579\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (44710, 44710) entries\n",
      "Student model 5-37 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9798644185875149\n",
      "Student model 5-37 fidelity: 0.9798644185875149\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (44860, 44860) entries\n",
      "Student model 5-38 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9446183549000898\n",
      "Student model 5-38 fidelity: 0.9446183549000898\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (45010, 45010) entries\n",
      "Student model 5-39 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9720411806501676\n",
      "Student model 5-39 fidelity: 0.9720411806501676\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (45160, 45160) entries\n",
      "Student model 5-40 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9705327030727678\n",
      "Student model 5-40 fidelity: 0.9705327030727678\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (45310, 45310) entries\n",
      "Student model 5-41 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9798151292209017\n",
      "Student model 5-41 fidelity: 0.9798151292209017\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (45460, 45460) entries\n",
      "Student model 5-42 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9598579345701773\n",
      "Student model 5-42 fidelity: 0.9598579345701773\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (45610, 45610) entries\n",
      "Student model 5-43 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9862222222222222\n",
      "Student model 5-43 fidelity: 0.9862222222222222\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (45760, 45760) entries\n",
      "Student model 5-44 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.961594599525634\n",
      "Student model 5-44 fidelity: 0.961594599525634\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (45910, 45910) entries\n",
      "Student model 5-45 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9647288416951337\n",
      "Student model 5-45 fidelity: 0.9647288416951337\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (46060, 46060) entries\n",
      "Student model 5-46 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.979813384153761\n",
      "Student model 5-46 fidelity: 0.979813384153761\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (46210, 46210) entries\n",
      "Student model 5-47 trained with depth 4 and 10 leaves:\n",
      "Student model score: 0.9661375661375663\n",
      "Student model 5-47 fidelity: 0.9661375661375663\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (46360, 46360) entries\n",
      "Student model 5-48 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9658970999863983\n",
      "Student model 5-48 fidelity: 0.9658970999863983\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (46510, 46510) entries\n",
      "Student model 5-49 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9780047039913011\n",
      "Student model 5-49 fidelity: 0.9780047039913011\n",
      "########## Outer-loop Iteration 6/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (46660, 46660) entries\n",
      "Student model 6-0 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9864267074351107\n",
      "Student model 6-0 fidelity: 0.9864267074351107\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (46810, 46810) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 6-1 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9698509485094852\n",
      "Student model 6-1 fidelity: 0.9698509485094852\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (46960, 46960) entries\n",
      "Student model 6-2 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.986766247379455\n",
      "Student model 6-2 fidelity: 0.986766247379455\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (47110, 47110) entries\n",
      "Student model 6-3 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9927695088650438\n",
      "Student model 6-3 fidelity: 0.9927695088650438\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (47260, 47260) entries\n",
      "Student model 6-4 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9855973941739546\n",
      "Student model 6-4 fidelity: 0.9855973941739546\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (47410, 47410) entries\n",
      "Student model 6-5 trained with depth 5 and 9 leaves:\n",
      "Student model score: 1.0\n",
      "Student model 6-5 fidelity: 1.0\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (47560, 47560) entries\n",
      "Student model 6-6 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.9384022265622667\n",
      "Student model 6-6 fidelity: 0.9384022265622667\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (47710, 47710) entries\n",
      "Student model 6-7 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9853177857759884\n",
      "Student model 6-7 fidelity: 0.9853177857759884\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (47860, 47860) entries\n",
      "Student model 6-8 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9722908275179986\n",
      "Student model 6-8 fidelity: 0.9722908275179986\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (48010, 48010) entries\n",
      "Student model 6-9 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9470374940963177\n",
      "Student model 6-9 fidelity: 0.9470374940963177\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (48160, 48160) entries\n",
      "Student model 6-10 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9595540271295614\n",
      "Student model 6-10 fidelity: 0.9595540271295614\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (48310, 48310) entries\n",
      "Student model 6-11 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.980238302818948\n",
      "Student model 6-11 fidelity: 0.980238302818948\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (48460, 48460) entries\n",
      "Student model 6-12 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9776330342878211\n",
      "Student model 6-12 fidelity: 0.9776330342878211\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (48610, 48610) entries\n",
      "Student model 6-13 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9858646113058511\n",
      "Student model 6-13 fidelity: 0.9858646113058511\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (48760, 48760) entries\n",
      "Student model 6-14 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.972721272808911\n",
      "Student model 6-14 fidelity: 0.972721272808911\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (48910, 48910) entries\n",
      "Student model 6-15 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9667616551571124\n",
      "Student model 6-15 fidelity: 0.9667616551571124\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (49060, 49060) entries\n",
      "Student model 6-16 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9083726448809218\n",
      "Student model 6-16 fidelity: 0.9083726448809218\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (49210, 49210) entries\n",
      "Student model 6-17 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9729738750574085\n",
      "Student model 6-17 fidelity: 0.9729738750574085\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (49360, 49360) entries\n",
      "Student model 6-18 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9866606299599866\n",
      "Student model 6-18 fidelity: 0.9866606299599866\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (49510, 49510) entries\n",
      "Student model 6-19 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9594248477408839\n",
      "Student model 6-19 fidelity: 0.9594248477408839\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (49660, 49660) entries\n",
      "Student model 6-20 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9440476190476191\n",
      "Student model 6-20 fidelity: 0.9440476190476191\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (49810, 49810) entries\n",
      "Student model 6-21 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9865312722455579\n",
      "Student model 6-21 fidelity: 0.9865312722455579\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (49960, 49960) entries\n",
      "Student model 6-22 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9782525418478322\n",
      "Student model 6-22 fidelity: 0.9782525418478322\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (50110, 50110) entries\n",
      "Student model 6-23 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9743618945295013\n",
      "Student model 6-23 fidelity: 0.9743618945295013\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (50260, 50260) entries\n",
      "Student model 6-24 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9715901984194667\n",
      "Student model 6-24 fidelity: 0.9715901984194667\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (50410, 50410) entries\n",
      "Student model 6-25 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9922471229557844\n",
      "Student model 6-25 fidelity: 0.9922471229557844\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (50560, 50560) entries\n",
      "Student model 6-26 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9801799815609091\n",
      "Student model 6-26 fidelity: 0.9801799815609091\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (50710, 50710) entries\n",
      "Student model 6-27 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9367069883636843\n",
      "Student model 6-27 fidelity: 0.9367069883636843\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (50860, 50860) entries\n",
      "Student model 6-28 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9852014074367711\n",
      "Student model 6-28 fidelity: 0.9852014074367711\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (51010, 51010) entries\n",
      "Student model 6-29 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9734555964485475\n",
      "Student model 6-29 fidelity: 0.9734555964485475\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (51160, 51160) entries\n",
      "Student model 6-30 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9661264104035188\n",
      "Student model 6-30 fidelity: 0.9661264104035188\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (51310, 51310) entries\n",
      "Student model 6-31 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9712712947307921\n",
      "Student model 6-31 fidelity: 0.9712712947307921\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (51460, 51460) entries\n",
      "Student model 6-32 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9928892606922514\n",
      "Student model 6-32 fidelity: 0.9928892606922514\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (51610, 51610) entries\n",
      "Student model 6-33 trained with depth 4 and 9 leaves:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model score: 0.9452582086853186\n",
      "Student model 6-33 fidelity: 0.9452582086853186\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (51760, 51760) entries\n",
      "Student model 6-34 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9859633569739952\n",
      "Student model 6-34 fidelity: 0.9859633569739952\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (51910, 51910) entries\n",
      "Student model 6-35 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9864328682108332\n",
      "Student model 6-35 fidelity: 0.9864328682108332\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (52060, 52060) entries\n",
      "Student model 6-36 trained with depth 3 and 7 leaves:\n",
      "Student model score: 0.9938712413472325\n",
      "Student model 6-36 fidelity: 0.9938712413472325\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (52210, 52210) entries\n",
      "Student model 6-37 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9802282080059858\n",
      "Student model 6-37 fidelity: 0.9802282080059858\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (52360, 52360) entries\n",
      "Student model 6-38 trained with depth 4 and 10 leaves:\n",
      "Student model score: 0.9863636363636363\n",
      "Student model 6-38 fidelity: 0.9863636363636363\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (52510, 52510) entries\n",
      "Student model 6-39 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9731655428309972\n",
      "Student model 6-39 fidelity: 0.9731655428309972\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (52660, 52660) entries\n",
      "Student model 6-40 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9661460427758742\n",
      "Student model 6-40 fidelity: 0.9661460427758742\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (52810, 52810) entries\n",
      "Student model 6-41 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9933236104359099\n",
      "Student model 6-41 fidelity: 0.9933236104359099\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (52960, 52960) entries\n",
      "Student model 6-42 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9581821279495698\n",
      "Student model 6-42 fidelity: 0.9581821279495698\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (53110, 53110) entries\n",
      "Student model 6-43 trained with depth 4 and 10 leaves:\n",
      "Student model score: 0.9705331705331705\n",
      "Student model 6-43 fidelity: 0.9705331705331705\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (53260, 53260) entries\n",
      "Student model 6-44 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9720602609565376\n",
      "Student model 6-44 fidelity: 0.9720602609565376\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (53410, 53410) entries\n",
      "Student model 6-45 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9867052197222975\n",
      "Student model 6-45 fidelity: 0.9867052197222975\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (53560, 53560) entries\n",
      "Student model 6-46 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9787576279820939\n",
      "Student model 6-46 fidelity: 0.9787576279820939\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (53710, 53710) entries\n",
      "Student model 6-47 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9414916365452038\n",
      "Student model 6-47 fidelity: 0.9414916365452038\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (53860, 53860) entries\n",
      "Student model 6-48 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9793400157384832\n",
      "Student model 6-48 fidelity: 0.9793400157384832\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (54010, 54010) entries\n",
      "Student model 6-49 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.981247311827957\n",
      "Student model 6-49 fidelity: 0.981247311827957\n",
      "########## Outer-loop Iteration 7/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (54160, 54160) entries\n",
      "Student model 7-0 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9786162228847538\n",
      "Student model 7-0 fidelity: 0.9786162228847538\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (54310, 54310) entries\n",
      "Student model 7-1 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9418946843750325\n",
      "Student model 7-1 fidelity: 0.9418946843750325\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (54460, 54460) entries\n",
      "Student model 7-2 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9672407851570037\n",
      "Student model 7-2 fidelity: 0.9672407851570037\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (54610, 54610) entries\n",
      "Student model 7-3 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.968084203378321\n",
      "Student model 7-3 fidelity: 0.968084203378321\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (54760, 54760) entries\n",
      "Student model 7-4 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9639701511972495\n",
      "Student model 7-4 fidelity: 0.9639701511972495\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (54910, 54910) entries\n",
      "Student model 7-5 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9617025057140497\n",
      "Student model 7-5 fidelity: 0.9617025057140497\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (55060, 55060) entries\n",
      "Student model 7-6 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.985153358794446\n",
      "Student model 7-6 fidelity: 0.985153358794446\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (55210, 55210) entries\n",
      "Student model 7-7 trained with depth 5 and 9 leaves:\n",
      "Student model score: 1.0\n",
      "Student model 7-7 fidelity: 1.0\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (55360, 55360) entries\n",
      "Student model 7-8 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9584195997239475\n",
      "Student model 7-8 fidelity: 0.9584195997239475\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (55510, 55510) entries\n",
      "Student model 7-9 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.953162339760278\n",
      "Student model 7-9 fidelity: 0.953162339760278\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (55660, 55660) entries\n",
      "Student model 7-10 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9514398402763318\n",
      "Student model 7-10 fidelity: 0.9514398402763318\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (55810, 55810) entries\n",
      "Student model 7-11 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.956897557722764\n",
      "Student model 7-11 fidelity: 0.956897557722764\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (55960, 55960) entries\n",
      "Student model 7-12 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9872727272727273\n",
      "Student model 7-12 fidelity: 0.9872727272727273\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (56110, 56110) entries\n",
      "Student model 7-13 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9700854700854702\n",
      "Student model 7-13 fidelity: 0.9700854700854702\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (56260, 56260) entries\n",
      "Student model 7-14 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9486908367028146\n",
      "Student model 7-14 fidelity: 0.9486908367028146\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (56410, 56410) entries\n",
      "Student model 7-15 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9668406773160055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 7-15 fidelity: 0.9668406773160055\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (56560, 56560) entries\n",
      "Student model 7-16 trained with depth 6 and 8 leaves:\n",
      "Student model score: 0.9439883412015687\n",
      "Student model 7-16 fidelity: 0.9439883412015687\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (56710, 56710) entries\n",
      "Student model 7-17 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9861619861619862\n",
      "Student model 7-17 fidelity: 0.9861619861619862\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (56860, 56860) entries\n",
      "Student model 7-18 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9770114942528737\n",
      "Student model 7-18 fidelity: 0.9770114942528737\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (57010, 57010) entries\n",
      "Student model 7-19 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.954023741525149\n",
      "Student model 7-19 fidelity: 0.954023741525149\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (57160, 57160) entries\n",
      "Student model 7-20 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.993036666303993\n",
      "Student model 7-20 fidelity: 0.993036666303993\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (57310, 57310) entries\n",
      "Student model 7-21 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9433793158001533\n",
      "Student model 7-21 fidelity: 0.9433793158001533\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (57460, 57460) entries\n",
      "Student model 7-22 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9805491455815231\n",
      "Student model 7-22 fidelity: 0.9805491455815231\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (57610, 57610) entries\n",
      "Student model 7-23 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9922552255225522\n",
      "Student model 7-23 fidelity: 0.9922552255225522\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (57760, 57760) entries\n",
      "Student model 7-24 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.993785545845471\n",
      "Student model 7-24 fidelity: 0.993785545845471\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (57910, 57910) entries\n",
      "Student model 7-25 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.972652376075046\n",
      "Student model 7-25 fidelity: 0.972652376075046\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (58060, 58060) entries\n",
      "Student model 7-26 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9927321562586404\n",
      "Student model 7-26 fidelity: 0.9927321562586404\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (58210, 58210) entries\n",
      "Student model 7-27 trained with depth 6 and 11 leaves:\n",
      "Student model score: 1.0\n",
      "Student model 7-27 fidelity: 1.0\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (58360, 58360) entries\n",
      "Student model 7-28 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9806339636430073\n",
      "Student model 7-28 fidelity: 0.9806339636430073\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (58510, 58510) entries\n",
      "Student model 7-29 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9650566251334279\n",
      "Student model 7-29 fidelity: 0.9650566251334279\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (58660, 58660) entries\n",
      "Student model 7-30 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9711843711843712\n",
      "Student model 7-30 fidelity: 0.9711843711843712\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (58810, 58810) entries\n",
      "Student model 7-31 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9532652730513692\n",
      "Student model 7-31 fidelity: 0.9532652730513692\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (58960, 58960) entries\n",
      "Student model 7-32 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9538217195996426\n",
      "Student model 7-32 fidelity: 0.9538217195996426\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (59110, 59110) entries\n",
      "Student model 7-33 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9627143639923919\n",
      "Student model 7-33 fidelity: 0.9627143639923919\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (59260, 59260) entries\n",
      "Student model 7-34 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.950513724284216\n",
      "Student model 7-34 fidelity: 0.950513724284216\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (59410, 59410) entries\n",
      "Student model 7-35 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.953089133089133\n",
      "Student model 7-35 fidelity: 0.953089133089133\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (59560, 59560) entries\n",
      "Student model 7-36 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.956111111111111\n",
      "Student model 7-36 fidelity: 0.956111111111111\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (59710, 59710) entries\n",
      "Student model 7-37 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9582126767941331\n",
      "Student model 7-37 fidelity: 0.9582126767941331\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (59860, 59860) entries\n",
      "Student model 7-38 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9855003940110323\n",
      "Student model 7-38 fidelity: 0.9855003940110323\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (60010, 60010) entries\n",
      "Student model 7-39 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9873842592592593\n",
      "Student model 7-39 fidelity: 0.9873842592592593\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (60160, 60160) entries\n",
      "Student model 7-40 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9599686028257457\n",
      "Student model 7-40 fidelity: 0.9599686028257457\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (60310, 60310) entries\n",
      "Student model 7-41 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9802930854883242\n",
      "Student model 7-41 fidelity: 0.9802930854883242\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (60460, 60460) entries\n",
      "Student model 7-42 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9165587498920832\n",
      "Student model 7-42 fidelity: 0.9165587498920832\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (60610, 60610) entries\n",
      "Student model 7-43 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9693005407291122\n",
      "Student model 7-43 fidelity: 0.9693005407291122\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (60760, 60760) entries\n",
      "Student model 7-44 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9669215965100282\n",
      "Student model 7-44 fidelity: 0.9669215965100282\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (60910, 60910) entries\n",
      "Student model 7-45 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9783882745994475\n",
      "Student model 7-45 fidelity: 0.9783882745994475\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (61060, 61060) entries\n",
      "Student model 7-46 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9477821350762526\n",
      "Student model 7-46 fidelity: 0.9477821350762526\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (61210, 61210) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 7-47 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9934117647058823\n",
      "Student model 7-47 fidelity: 0.9934117647058823\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (61360, 61360) entries\n",
      "Student model 7-48 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9578119658119658\n",
      "Student model 7-48 fidelity: 0.9578119658119658\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (61510, 61510) entries\n",
      "Student model 7-49 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.987449118046133\n",
      "Student model 7-49 fidelity: 0.987449118046133\n",
      "########## Outer-loop Iteration 8/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (61660, 61660) entries\n",
      "Student model 8-0 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9912475134981529\n",
      "Student model 8-0 fidelity: 0.9912475134981529\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (61810, 61810) entries\n",
      "Student model 8-1 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9668463246826632\n",
      "Student model 8-1 fidelity: 0.9668463246826632\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (61960, 61960) entries\n",
      "Student model 8-2 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9518846019167286\n",
      "Student model 8-2 fidelity: 0.9518846019167286\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (62110, 62110) entries\n",
      "Student model 8-3 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9738337779933706\n",
      "Student model 8-3 fidelity: 0.9738337779933706\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (62260, 62260) entries\n",
      "Student model 8-4 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9663296709417777\n",
      "Student model 8-4 fidelity: 0.9663296709417777\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (62410, 62410) entries\n",
      "Student model 8-5 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.979540419092389\n",
      "Student model 8-5 fidelity: 0.979540419092389\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (62560, 62560) entries\n",
      "Student model 8-6 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9855935127674259\n",
      "Student model 8-6 fidelity: 0.9855935127674259\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (62710, 62710) entries\n",
      "Student model 8-7 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.950321206681099\n",
      "Student model 8-7 fidelity: 0.950321206681099\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (62860, 62860) entries\n",
      "Student model 8-8 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9558266411207588\n",
      "Student model 8-8 fidelity: 0.9558266411207588\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (63010, 63010) entries\n",
      "Student model 8-9 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9620329215584098\n",
      "Student model 8-9 fidelity: 0.9620329215584098\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (63160, 63160) entries\n",
      "Student model 8-10 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9647341172525099\n",
      "Student model 8-10 fidelity: 0.9647341172525099\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (63310, 63310) entries\n",
      "Student model 8-11 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.980161431488865\n",
      "Student model 8-11 fidelity: 0.980161431488865\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (63460, 63460) entries\n",
      "Student model 8-12 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9484477846546812\n",
      "Student model 8-12 fidelity: 0.9484477846546812\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (63610, 63610) entries\n",
      "Student model 8-13 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9718467705510389\n",
      "Student model 8-13 fidelity: 0.9718467705510389\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (63760, 63760) entries\n",
      "Student model 8-14 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9658444643593792\n",
      "Student model 8-14 fidelity: 0.9658444643593792\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (63910, 63910) entries\n",
      "Student model 8-15 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9807956303672859\n",
      "Student model 8-15 fidelity: 0.9807956303672859\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (64060, 64060) entries\n",
      "Student model 8-16 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9792402354200108\n",
      "Student model 8-16 fidelity: 0.9792402354200108\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (64210, 64210) entries\n",
      "Student model 8-17 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9864169865477055\n",
      "Student model 8-17 fidelity: 0.9864169865477055\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (64360, 64360) entries\n",
      "Student model 8-18 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9664884478450669\n",
      "Student model 8-18 fidelity: 0.9664884478450669\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (64510, 64510) entries\n",
      "Student model 8-19 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9799248204772916\n",
      "Student model 8-19 fidelity: 0.9799248204772916\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (64660, 64660) entries\n",
      "Student model 8-20 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9580901198842496\n",
      "Student model 8-20 fidelity: 0.9580901198842496\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (64810, 64810) entries\n",
      "Student model 8-21 trained with depth 4 and 10 leaves:\n",
      "Student model score: 0.9852175123853076\n",
      "Student model 8-21 fidelity: 0.9852175123853076\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (64960, 64960) entries\n",
      "Student model 8-22 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9860088130578082\n",
      "Student model 8-22 fidelity: 0.9860088130578082\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (65110, 65110) entries\n",
      "Student model 8-23 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9793758451656523\n",
      "Student model 8-23 fidelity: 0.9793758451656523\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (65260, 65260) entries\n",
      "Student model 8-24 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9790553070797426\n",
      "Student model 8-24 fidelity: 0.9790553070797426\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (65410, 65410) entries\n",
      "Student model 8-25 trained with depth 4 and 8 leaves:\n",
      "Student model score: 1.0\n",
      "Student model 8-25 fidelity: 1.0\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (65560, 65560) entries\n",
      "Student model 8-26 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9580409356725146\n",
      "Student model 8-26 fidelity: 0.9580409356725146\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (65710, 65710) entries\n",
      "Student model 8-27 trained with depth 4 and 6 leaves:\n",
      "Student model score: 0.9855813953488372\n",
      "Student model 8-27 fidelity: 0.9855813953488372\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (65860, 65860) entries\n",
      "Student model 8-28 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9852759622367465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 8-28 fidelity: 0.9852759622367465\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (66010, 66010) entries\n",
      "Student model 8-29 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9805130109223676\n",
      "Student model 8-29 fidelity: 0.9805130109223676\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (66160, 66160) entries\n",
      "Student model 8-30 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9938712413472325\n",
      "Student model 8-30 fidelity: 0.9938712413472325\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (66310, 66310) entries\n",
      "Student model 8-31 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.958888888888889\n",
      "Student model 8-31 fidelity: 0.958888888888889\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (66460, 66460) entries\n",
      "Student model 8-32 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9865189795678596\n",
      "Student model 8-32 fidelity: 0.9865189795678596\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (66610, 66610) entries\n",
      "Student model 8-33 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.967706877814004\n",
      "Student model 8-33 fidelity: 0.967706877814004\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (66760, 66760) entries\n",
      "Student model 8-34 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9482058682058683\n",
      "Student model 8-34 fidelity: 0.9482058682058683\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (66910, 66910) entries\n",
      "Student model 8-35 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9637048047676066\n",
      "Student model 8-35 fidelity: 0.9637048047676066\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (67060, 67060) entries\n",
      "Student model 8-36 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.978258300838946\n",
      "Student model 8-36 fidelity: 0.978258300838946\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (67210, 67210) entries\n",
      "Student model 8-37 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9399907815515801\n",
      "Student model 8-37 fidelity: 0.9399907815515801\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (67360, 67360) entries\n",
      "Student model 8-38 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9504124536804275\n",
      "Student model 8-38 fidelity: 0.9504124536804275\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (67510, 67510) entries\n",
      "Student model 8-39 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9603558937699375\n",
      "Student model 8-39 fidelity: 0.9603558937699375\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (67660, 67660) entries\n",
      "Student model 8-40 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9722519310754604\n",
      "Student model 8-40 fidelity: 0.9722519310754604\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (67810, 67810) entries\n",
      "Student model 8-41 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9866915422885572\n",
      "Student model 8-41 fidelity: 0.9866915422885572\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (67960, 67960) entries\n",
      "Student model 8-42 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9862176754759875\n",
      "Student model 8-42 fidelity: 0.9862176754759875\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (68110, 68110) entries\n",
      "Student model 8-43 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9571363429092568\n",
      "Student model 8-43 fidelity: 0.9571363429092568\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (68260, 68260) entries\n",
      "Student model 8-44 trained with depth 3 and 6 leaves:\n",
      "Student model score: 0.9734004828125168\n",
      "Student model 8-44 fidelity: 0.9734004828125168\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (68410, 68410) entries\n",
      "Student model 8-45 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9795300980390148\n",
      "Student model 8-45 fidelity: 0.9795300980390148\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (68560, 68560) entries\n",
      "Student model 8-46 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9634710786157185\n",
      "Student model 8-46 fidelity: 0.9634710786157185\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (68710, 68710) entries\n",
      "Student model 8-47 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9711525189786059\n",
      "Student model 8-47 fidelity: 0.9711525189786059\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (68860, 68860) entries\n",
      "Student model 8-48 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9519412845416144\n",
      "Student model 8-48 fidelity: 0.9519412845416144\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (69010, 69010) entries\n",
      "Student model 8-49 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.988583138173302\n",
      "Student model 8-49 fidelity: 0.988583138173302\n",
      "########## Outer-loop Iteration 9/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (69160, 69160) entries\n",
      "Student model 9-0 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9795744680851063\n",
      "Student model 9-0 fidelity: 0.9795744680851063\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (69310, 69310) entries\n",
      "Student model 9-1 trained with depth 4 and 10 leaves:\n",
      "Student model score: 0.9671810152915395\n",
      "Student model 9-1 fidelity: 0.9671810152915395\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (69460, 69460) entries\n",
      "Student model 9-2 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9935667677603162\n",
      "Student model 9-2 fidelity: 0.9935667677603162\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (69610, 69610) entries\n",
      "Student model 9-3 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9779659398376572\n",
      "Student model 9-3 fidelity: 0.9779659398376572\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (69760, 69760) entries\n",
      "Student model 9-4 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9930705636170285\n",
      "Student model 9-4 fidelity: 0.9930705636170285\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (69910, 69910) entries\n",
      "Student model 9-5 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9799965600275198\n",
      "Student model 9-5 fidelity: 0.9799965600275198\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (70060, 70060) entries\n",
      "Student model 9-6 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9925475096261334\n",
      "Student model 9-6 fidelity: 0.9925475096261334\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (70210, 70210) entries\n",
      "Student model 9-7 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9591374269005848\n",
      "Student model 9-7 fidelity: 0.9591374269005848\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (70360, 70360) entries\n",
      "Student model 9-8 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.959786064124868\n",
      "Student model 9-8 fidelity: 0.959786064124868\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (70510, 70510) entries\n",
      "Student model 9-9 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9470758738277919\n",
      "Student model 9-9 fidelity: 0.9470758738277919\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (70660, 70660) entries\n",
      "Student model 9-10 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9805752968370878\n",
      "Student model 9-10 fidelity: 0.9805752968370878\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (70810, 70810) entries\n",
      "Student model 9-11 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9682403837573452\n",
      "Student model 9-11 fidelity: 0.9682403837573452\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (70960, 70960) entries\n",
      "Student model 9-12 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9929794702691203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 9-12 fidelity: 0.9929794702691203\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (71110, 71110) entries\n",
      "Student model 9-13 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9935721657083886\n",
      "Student model 9-13 fidelity: 0.9935721657083886\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (71260, 71260) entries\n",
      "Student model 9-14 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9558333108891555\n",
      "Student model 9-14 fidelity: 0.9558333108891555\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (71410, 71410) entries\n",
      "Student model 9-15 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9669340016708438\n",
      "Student model 9-15 fidelity: 0.9669340016708438\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (71560, 71560) entries\n",
      "Student model 9-16 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9507333875149966\n",
      "Student model 9-16 fidelity: 0.9507333875149966\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (71710, 71710) entries\n",
      "Student model 9-17 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9728395061728395\n",
      "Student model 9-17 fidelity: 0.9728395061728395\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (71860, 71860) entries\n",
      "Student model 9-18 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9635591677408549\n",
      "Student model 9-18 fidelity: 0.9635591677408549\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (72010, 72010) entries\n",
      "Student model 9-19 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9719765965667605\n",
      "Student model 9-19 fidelity: 0.9719765965667605\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (72160, 72160) entries\n",
      "Student model 9-20 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.973713359748721\n",
      "Student model 9-20 fidelity: 0.973713359748721\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (72310, 72310) entries\n",
      "Student model 9-21 trained with depth 3 and 7 leaves:\n",
      "Student model score: 0.9642645229208536\n",
      "Student model 9-21 fidelity: 0.9642645229208536\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (72460, 72460) entries\n",
      "Student model 9-22 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9712468410142829\n",
      "Student model 9-22 fidelity: 0.9712468410142829\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (72610, 72610) entries\n",
      "Student model 9-23 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9583034764293314\n",
      "Student model 9-23 fidelity: 0.9583034764293314\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (72760, 72760) entries\n",
      "Student model 9-24 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9799812394216847\n",
      "Student model 9-24 fidelity: 0.9799812394216847\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (72910, 72910) entries\n",
      "Student model 9-25 trained with depth 9 and 15 leaves:\n",
      "Student model score: 0.9733333333333333\n",
      "Student model 9-25 fidelity: 0.9733333333333333\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (73060, 73060) entries\n",
      "Student model 9-26 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9796633746000835\n",
      "Student model 9-26 fidelity: 0.9796633746000835\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (73210, 73210) entries\n",
      "Student model 9-27 trained with depth 3 and 7 leaves:\n",
      "Student model score: 0.9682267067410906\n",
      "Student model 9-27 fidelity: 0.9682267067410906\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (73360, 73360) entries\n",
      "Student model 9-28 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9845679012345679\n",
      "Student model 9-28 fidelity: 0.9845679012345679\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (73510, 73510) entries\n",
      "Student model 9-29 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9726271303303888\n",
      "Student model 9-29 fidelity: 0.9726271303303888\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (73660, 73660) entries\n",
      "Student model 9-30 trained with depth 4 and 10 leaves:\n",
      "Student model score: 0.9859364893824273\n",
      "Student model 9-30 fidelity: 0.9859364893824273\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (73810, 73810) entries\n",
      "Student model 9-31 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.980161431488865\n",
      "Student model 9-31 fidelity: 0.980161431488865\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (73960, 73960) entries\n",
      "Student model 9-32 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9665513589076418\n",
      "Student model 9-32 fidelity: 0.9665513589076418\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (74110, 74110) entries\n",
      "Student model 9-33 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9858933869269787\n",
      "Student model 9-33 fidelity: 0.9858933869269787\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (74260, 74260) entries\n",
      "Student model 9-34 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.92665810868635\n",
      "Student model 9-34 fidelity: 0.92665810868635\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (74410, 74410) entries\n",
      "Student model 9-35 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9756776556776557\n",
      "Student model 9-35 fidelity: 0.9756776556776557\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (74560, 74560) entries\n",
      "Student model 9-36 trained with depth 4 and 10 leaves:\n",
      "Student model score: 0.9549222996171869\n",
      "Student model 9-36 fidelity: 0.9549222996171869\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (74710, 74710) entries\n",
      "Student model 9-37 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9859509020999705\n",
      "Student model 9-37 fidelity: 0.9859509020999705\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (74860, 74860) entries\n",
      "Student model 9-38 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9758453764273152\n",
      "Student model 9-38 fidelity: 0.9758453764273152\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (75010, 75010) entries\n",
      "Student model 9-39 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.959375\n",
      "Student model 9-39 fidelity: 0.959375\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (75160, 75160) entries\n",
      "Student model 9-40 trained with depth 3 and 6 leaves:\n",
      "Student model score: 0.9733917751179799\n",
      "Student model 9-40 fidelity: 0.9733917751179799\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (75310, 75310) entries\n",
      "Student model 9-41 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9460367391715426\n",
      "Student model 9-41 fidelity: 0.9460367391715426\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (75460, 75460) entries\n",
      "Student model 9-42 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9458247066942719\n",
      "Student model 9-42 fidelity: 0.9458247066942719\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (75610, 75610) entries\n",
      "Student model 9-43 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9880914407230197\n",
      "Student model 9-43 fidelity: 0.9880914407230197\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (75760, 75760) entries\n",
      "Student model 9-44 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9532974202830662\n",
      "Student model 9-44 fidelity: 0.9532974202830662\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (75910, 75910) entries\n",
      "Student model 9-45 trained with depth 4 and 7 leaves:\n",
      "Student model score: 0.9525863080924046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 9-45 fidelity: 0.9525863080924046\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (76060, 76060) entries\n",
      "Student model 9-46 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9347820111056132\n",
      "Student model 9-46 fidelity: 0.9347820111056132\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (76210, 76210) entries\n",
      "Student model 9-47 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9859090116881838\n",
      "Student model 9-47 fidelity: 0.9859090116881838\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (76360, 76360) entries\n",
      "Student model 9-48 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9723280872813583\n",
      "Student model 9-48 fidelity: 0.9723280872813583\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (76510, 76510) entries\n",
      "Student model 9-49 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9722222222222222\n",
      "Student model 9-49 fidelity: 0.9722222222222222\n",
      "Model explanation global fidelity report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   GoogleDoc       0.99      0.99      0.99       342\n",
      " GoogleDrive       0.95      0.98      0.96       331\n",
      "     Youtube       0.99      0.96      0.97       344\n",
      "\n",
      "    accuracy                           0.98      1017\n",
      "   macro avg       0.98      0.98      0.98      1017\n",
      "weighted avg       0.98      0.98      0.98      1017\n",
      "\n",
      "Model explanation score report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   GoogleDoc       0.99      0.98      0.99       346\n",
      " GoogleDrive       0.92      0.96      0.94       325\n",
      "     Youtube       0.98      0.94      0.96       346\n",
      "\n",
      "    accuracy                           0.96      1017\n",
      "   macro avg       0.96      0.96      0.96      1017\n",
      "weighted avg       0.96      0.96      0.96      1017\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "#svm_classifier = joblib.load('quic_text_svm_pca.joblib')\n",
    "\n",
    "trustee = ClassificationTrustee(expert=svm_classifier)\n",
    "trustee.fit(X_train, y_train, num_iter=50, num_stability_iter=10, samples_size=0.3, verbose=True)\n",
    "dt, pruned_dt, agreement, reward = trustee.explain()\n",
    "dt_y_pred = dt.predict(X_test)\n",
    "pruned_dt_y_pred = pruned_dt.predict(X_test)\n",
    "\n",
    "print(\"Model explanation global fidelity report:\")\n",
    "print(classification_report(y_pred, dt_y_pred))\n",
    "print(\"Model explanation score report:\")\n",
    "print(classification_report(y_test, dt_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39f2b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flowpic_svm_pruned_dt.pdf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output decision tree to pdf\n",
    "features = ['feature_{}'.format(i) for i in range(1, 101)]\n",
    "classes = ['GoogleDoc', 'GoogleDrive', 'Youtube']\n",
    "\n",
    "dot_data = tree.export_graphviz(\n",
    "    dt,\n",
    "    class_names=classes,\n",
    "    feature_names= features,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True,\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"flowpic_svm_dt\")\n",
    "\n",
    "# Output pruned decision tree to pdf\n",
    "dot_data = tree.export_graphviz(\n",
    "    pruned_dt,\n",
    "    class_names=classes,\n",
    "    feature_names=features,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True,\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"flowpic_svm_pruned_dt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc0596",
   "metadata": {},
   "source": [
    "# SVM & POOLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3587c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyFeature(feature_index):\n",
    "    \n",
    "    if feature_index==0:\n",
    "        return 0\n",
    "\n",
    "    pooled_array_size = 100  # cnn 1500  \n",
    "    \n",
    "    #   -x -y\n",
    "    y = feature_index // pooled_array_size\n",
    "    y = y*15 # cnn \n",
    "    x = feature_index-1\n",
    "    x = x % pooled_array_size\n",
    "    x = x*15 # cnn \n",
    "    \n",
    "    return f'{x}-{x+15},{y}-{y+15}'  # x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e7b32e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.9960668633235005\n"
     ]
    }
   ],
   "source": [
    "## POOLING SVM\n",
    "\n",
    "# Load the df\n",
    "df_pool = pd.read_csv(\"df_x,y_pooling.csv\") # df_pooling.csv\n",
    "\n",
    "y_pool = df_pool['feature_0']\n",
    "X_pool = df_pool.drop(columns = ['feature_0'], inplace = False)\n",
    "\n",
    "# Split the data into 70% training and 30% test\n",
    "X_pool_train, X_pool_test, y_pool_train, y_pool_test = train_test_split(X_pool, y_pool, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the SVM classifier - pca\n",
    "svm_pooling_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier on the training set\n",
    "svm_pooling_classifier.fit(X_pool_train, y_pool_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "test_score = svm_pooling_classifier.score(X_pool_test, y_pool_test)\n",
    "print(\"Test set accuracy:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ebb71",
   "metadata": {},
   "outputs": [],
   "source": [
    " #joblib.dump(svm_classifier, 'quic_text_svm_pca.joblib') # put model here to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "102ee15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pool_pred = svm_pooling_classifier.predict(X_pool_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47263080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the confusion matrix\n",
    "category_labels = ['GoogleDoc', 'GoogleDrive', 'Youtube']\n",
    "conf_matrix = confusion_matrix(y_pool_test, y_pool_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=category_labels, yticklabels=category_labels)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e5e1a",
   "metadata": {},
   "source": [
    "# Trustee Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5a1e090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing training dataset using SVC(kernel='linear') as expert model\n",
      "Expert model score: 0.9994231262232148\n",
      "Initializing Trustee outer-loop with 10 iterations\n",
      "########## Outer-loop Iteration 0/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (1660, 1660) entries\n",
      "Student model 0-0 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9595028067361667\n",
      "Student model 0-0 fidelity: 0.9595028067361667\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (1810, 1810) entries\n",
      "Student model 0-1 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9717770698902773\n",
      "Student model 0-1 fidelity: 0.9717770698902773\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (1960, 1960) entries\n",
      "Student model 0-2 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9393041482819978\n",
      "Student model 0-2 fidelity: 0.9393041482819978\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (2110, 2110) entries\n",
      "Student model 0-3 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9598765432098765\n",
      "Student model 0-3 fidelity: 0.9598765432098765\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (2260, 2260) entries\n",
      "Student model 0-4 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9866184932423391\n",
      "Student model 0-4 fidelity: 0.9866184932423391\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (2410, 2410) entries\n",
      "Student model 0-5 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9794854348801958\n",
      "Student model 0-5 fidelity: 0.9794854348801958\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (2560, 2560) entries\n",
      "Student model 0-6 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.9664421997755331\n",
      "Student model 0-6 fidelity: 0.9664421997755331\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (2710, 2710) entries\n",
      "Student model 0-7 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9543429207482959\n",
      "Student model 0-7 fidelity: 0.9543429207482959\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (2860, 2860) entries\n",
      "Student model 0-8 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9394453876627051\n",
      "Student model 0-8 fidelity: 0.9394453876627051\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (3010, 3010) entries\n",
      "Student model 0-9 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9790114713480103\n",
      "Student model 0-9 fidelity: 0.9790114713480103\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (3160, 3160) entries\n",
      "Student model 0-10 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9547407345527089\n",
      "Student model 0-10 fidelity: 0.9547407345527089\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (3310, 3310) entries\n",
      "Student model 0-11 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9596269427809426\n",
      "Student model 0-11 fidelity: 0.9596269427809426\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (3460, 3460) entries\n",
      "Student model 0-12 trained with depth 8 and 16 leaves:\n",
      "Student model score: 0.9604794454606719\n",
      "Student model 0-12 fidelity: 0.9604794454606719\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (3610, 3610) entries\n",
      "Student model 0-13 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9212829971166032\n",
      "Student model 0-13 fidelity: 0.9212829971166032\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (3760, 3760) entries\n",
      "Student model 0-14 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9733478576615832\n",
      "Student model 0-14 fidelity: 0.9733478576615832\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (3910, 3910) entries\n",
      "Student model 0-15 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9561186019739237\n",
      "Student model 0-15 fidelity: 0.9561186019739237\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (4060, 4060) entries\n",
      "Student model 0-16 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9664598917472481\n",
      "Student model 0-16 fidelity: 0.9664598917472481\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (4210, 4210) entries\n",
      "Student model 0-17 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9126694520424419\n",
      "Student model 0-17 fidelity: 0.9126694520424419\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (4360, 4360) entries\n",
      "Student model 0-18 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9465068757717856\n",
      "Student model 0-18 fidelity: 0.9465068757717856\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (4510, 4510) entries\n",
      "Student model 0-19 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9388701833146277\n",
      "Student model 0-19 fidelity: 0.9388701833146277\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (4660, 4660) entries\n",
      "Student model 0-20 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.95327203660537\n",
      "Student model 0-20 fidelity: 0.95327203660537\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (4810, 4810) entries\n",
      "Student model 0-21 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9395464454992224\n",
      "Student model 0-21 fidelity: 0.9395464454992224\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (4960, 4960) entries\n",
      "Student model 0-22 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9792052649195506\n",
      "Student model 0-22 fidelity: 0.9792052649195506\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (5110, 5110) entries\n",
      "Student model 0-23 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9276677320562018\n",
      "Student model 0-23 fidelity: 0.9276677320562018\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (5260, 5260) entries\n",
      "Student model 0-24 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9603132911177624\n",
      "Student model 0-24 fidelity: 0.9603132911177624\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (5410, 5410) entries\n",
      "Student model 0-25 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.950604984261746\n",
      "Student model 0-25 fidelity: 0.950604984261746\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (5560, 5560) entries\n",
      "Student model 0-26 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9150316771234411\n",
      "Student model 0-26 fidelity: 0.9150316771234411\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (5710, 5710) entries\n",
      "Student model 0-27 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9728557504873295\n",
      "Student model 0-27 fidelity: 0.9728557504873295\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (5860, 5860) entries\n",
      "Student model 0-28 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9549628539985885\n",
      "Student model 0-28 fidelity: 0.9549628539985885\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (6010, 6010) entries\n",
      "Student model 0-29 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9401923076923078\n",
      "Student model 0-29 fidelity: 0.9401923076923078\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (6160, 6160) entries\n",
      "Student model 0-30 trained with depth 6 and 8 leaves:\n",
      "Student model score: 0.9530600118835414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 0-30 fidelity: 0.9530600118835414\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (6310, 6310) entries\n",
      "Student model 0-31 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9936092955700798\n",
      "Student model 0-31 fidelity: 0.9936092955700798\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (6460, 6460) entries\n",
      "Student model 0-32 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9416332660267489\n",
      "Student model 0-32 fidelity: 0.9416332660267489\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (6610, 6610) entries\n",
      "Student model 0-33 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9035019700551615\n",
      "Student model 0-33 fidelity: 0.9035019700551615\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (6760, 6760) entries\n",
      "Student model 0-34 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9056817664709929\n",
      "Student model 0-34 fidelity: 0.9056817664709929\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (6910, 6910) entries\n",
      "Student model 0-35 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9526617526617526\n",
      "Student model 0-35 fidelity: 0.9526617526617526\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (7060, 7060) entries\n",
      "Student model 0-36 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9319004710317862\n",
      "Student model 0-36 fidelity: 0.9319004710317862\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (7210, 7210) entries\n",
      "Student model 0-37 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9324157947709665\n",
      "Student model 0-37 fidelity: 0.9324157947709665\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (7360, 7360) entries\n",
      "Student model 0-38 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9799649873565454\n",
      "Student model 0-38 fidelity: 0.9799649873565454\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (7510, 7510) entries\n",
      "Student model 0-39 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9934998607113009\n",
      "Student model 0-39 fidelity: 0.9934998607113009\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (7660, 7660) entries\n",
      "Student model 0-40 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9528334366177788\n",
      "Student model 0-40 fidelity: 0.9528334366177788\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (7810, 7810) entries\n",
      "Student model 0-41 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9596755070619629\n",
      "Student model 0-41 fidelity: 0.9596755070619629\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (7960, 7960) entries\n",
      "Student model 0-42 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9868114422062031\n",
      "Student model 0-42 fidelity: 0.9868114422062031\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (8110, 8110) entries\n",
      "Student model 0-43 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9797326715430162\n",
      "Student model 0-43 fidelity: 0.9797326715430162\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (8260, 8260) entries\n",
      "Student model 0-44 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9492856729712534\n",
      "Student model 0-44 fidelity: 0.9492856729712534\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (8410, 8410) entries\n",
      "Student model 0-45 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.958989898989899\n",
      "Student model 0-45 fidelity: 0.958989898989899\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (8560, 8560) entries\n",
      "Student model 0-46 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9728596279941121\n",
      "Student model 0-46 fidelity: 0.9728596279941121\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (8710, 8710) entries\n",
      "Student model 0-47 trained with depth 7 and 17 leaves:\n",
      "Student model score: 0.9207675041008373\n",
      "Student model 0-47 fidelity: 0.9207675041008373\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (8860, 8860) entries\n",
      "Student model 0-48 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9546008795152668\n",
      "Student model 0-48 fidelity: 0.9546008795152668\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (9010, 9010) entries\n",
      "Student model 0-49 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9610037716050871\n",
      "Student model 0-49 fidelity: 0.9610037716050871\n",
      "########## Outer-loop Iteration 1/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (9160, 9160) entries\n",
      "Student model 1-0 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9738200656606728\n",
      "Student model 1-0 fidelity: 0.9738200656606728\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (9310, 9310) entries\n",
      "Student model 1-1 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.9622257935736148\n",
      "Student model 1-1 fidelity: 0.9622257935736148\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (9460, 9460) entries\n",
      "Student model 1-2 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.940240172198935\n",
      "Student model 1-2 fidelity: 0.940240172198935\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (9610, 9610) entries\n",
      "Student model 1-3 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9798567977915805\n",
      "Student model 1-3 fidelity: 0.9798567977915805\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (9760, 9760) entries\n",
      "Student model 1-4 trained with depth 9 and 16 leaves:\n",
      "Student model score: 0.9152309847962021\n",
      "Student model 1-4 fidelity: 0.9152309847962021\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (9910, 9910) entries\n",
      "Student model 1-5 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9483891833740166\n",
      "Student model 1-5 fidelity: 0.9483891833740166\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (10060, 10060) entries\n",
      "Student model 1-6 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.8840354090976087\n",
      "Student model 1-6 fidelity: 0.8840354090976087\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (10210, 10210) entries\n",
      "Student model 1-7 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9396581196581196\n",
      "Student model 1-7 fidelity: 0.9396581196581196\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (10360, 10360) entries\n",
      "Student model 1-8 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9367243288654675\n",
      "Student model 1-8 fidelity: 0.9367243288654675\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (10510, 10510) entries\n",
      "Student model 1-9 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9596033463205381\n",
      "Student model 1-9 fidelity: 0.9596033463205381\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (10660, 10660) entries\n",
      "Student model 1-10 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9523953712227594\n",
      "Student model 1-10 fidelity: 0.9523953712227594\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (10810, 10810) entries\n",
      "Student model 1-11 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9669525537412723\n",
      "Student model 1-11 fidelity: 0.9669525537412723\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (10960, 10960) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 1-12 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9668733590302216\n",
      "Student model 1-12 fidelity: 0.9668733590302216\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (11110, 11110) entries\n",
      "Student model 1-13 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.924331987940846\n",
      "Student model 1-13 fidelity: 0.924331987940846\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (11260, 11260) entries\n",
      "Student model 1-14 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9535185604773234\n",
      "Student model 1-14 fidelity: 0.9535185604773234\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (11410, 11410) entries\n",
      "Student model 1-15 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9467947849861176\n",
      "Student model 1-15 fidelity: 0.9467947849861176\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (11560, 11560) entries\n",
      "Student model 1-16 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9735306735306736\n",
      "Student model 1-16 fidelity: 0.9735306735306736\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (11710, 11710) entries\n",
      "Student model 1-17 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9537564845895635\n",
      "Student model 1-17 fidelity: 0.9537564845895635\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (11860, 11860) entries\n",
      "Student model 1-18 trained with depth 7 and 17 leaves:\n",
      "Student model score: 0.9594736842105264\n",
      "Student model 1-18 fidelity: 0.9594736842105264\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (12010, 12010) entries\n",
      "Student model 1-19 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9795378194718128\n",
      "Student model 1-19 fidelity: 0.9795378194718128\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (12160, 12160) entries\n",
      "Student model 1-20 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.946896461934056\n",
      "Student model 1-20 fidelity: 0.946896461934056\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (12310, 12310) entries\n",
      "Student model 1-21 trained with depth 7 and 17 leaves:\n",
      "Student model score: 0.9573842087116423\n",
      "Student model 1-21 fidelity: 0.9573842087116423\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (12460, 12460) entries\n",
      "Student model 1-22 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.9665977377307841\n",
      "Student model 1-22 fidelity: 0.9665977377307841\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (12610, 12610) entries\n",
      "Student model 1-23 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9469001828741384\n",
      "Student model 1-23 fidelity: 0.9469001828741384\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (12760, 12760) entries\n",
      "Student model 1-24 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9725806451612904\n",
      "Student model 1-24 fidelity: 0.9725806451612904\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (12910, 12910) entries\n",
      "Student model 1-25 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9671957671957672\n",
      "Student model 1-25 fidelity: 0.9671957671957672\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (13060, 13060) entries\n",
      "Student model 1-26 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9685568947734771\n",
      "Student model 1-26 fidelity: 0.9685568947734771\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (13210, 13210) entries\n",
      "Student model 1-27 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9407062668253028\n",
      "Student model 1-27 fidelity: 0.9407062668253028\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (13360, 13360) entries\n",
      "Student model 1-28 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.951795515569969\n",
      "Student model 1-28 fidelity: 0.951795515569969\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (13510, 13510) entries\n",
      "Student model 1-29 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9604943632299255\n",
      "Student model 1-29 fidelity: 0.9604943632299255\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (13660, 13660) entries\n",
      "Student model 1-30 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9801266360717333\n",
      "Student model 1-30 fidelity: 0.9801266360717333\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (13810, 13810) entries\n",
      "Student model 1-31 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.8985188192407012\n",
      "Student model 1-31 fidelity: 0.8985188192407012\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (13960, 13960) entries\n",
      "Student model 1-32 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9267636284550226\n",
      "Student model 1-32 fidelity: 0.9267636284550226\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (14110, 14110) entries\n",
      "Student model 1-33 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9600759734093067\n",
      "Student model 1-33 fidelity: 0.9600759734093067\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (14260, 14260) entries\n",
      "Student model 1-34 trained with depth 6 and 8 leaves:\n",
      "Student model score: 0.9465227496200947\n",
      "Student model 1-34 fidelity: 0.9465227496200947\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (14410, 14410) entries\n",
      "Student model 1-35 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.939837882055477\n",
      "Student model 1-35 fidelity: 0.939837882055477\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (14560, 14560) entries\n",
      "Student model 1-36 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.979933110367893\n",
      "Student model 1-36 fidelity: 0.979933110367893\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (14710, 14710) entries\n",
      "Student model 1-37 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9165934316310257\n",
      "Student model 1-37 fidelity: 0.9165934316310257\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (14860, 14860) entries\n",
      "Student model 1-38 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9138482436999956\n",
      "Student model 1-38 fidelity: 0.9138482436999956\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (15010, 15010) entries\n",
      "Student model 1-39 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.9543521698556935\n",
      "Student model 1-39 fidelity: 0.9543521698556935\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (15160, 15160) entries\n",
      "Student model 1-40 trained with depth 9 and 15 leaves:\n",
      "Student model score: 0.9346469826041409\n",
      "Student model 1-40 fidelity: 0.9346469826041409\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (15310, 15310) entries\n",
      "Student model 1-41 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9517371861025111\n",
      "Student model 1-41 fidelity: 0.9517371861025111\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (15460, 15460) entries\n",
      "Student model 1-42 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9397379473885171\n",
      "Student model 1-42 fidelity: 0.9397379473885171\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (15610, 15610) entries\n",
      "Student model 1-43 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9253442995670241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 1-43 fidelity: 0.9253442995670241\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (15760, 15760) entries\n",
      "Student model 1-44 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9797799422799423\n",
      "Student model 1-44 fidelity: 0.9797799422799423\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (15910, 15910) entries\n",
      "Student model 1-45 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.9607042038132318\n",
      "Student model 1-45 fidelity: 0.9607042038132318\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (16060, 16060) entries\n",
      "Student model 1-46 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.97316243770126\n",
      "Student model 1-46 fidelity: 0.97316243770126\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (16210, 16210) entries\n",
      "Student model 1-47 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9156847950950605\n",
      "Student model 1-47 fidelity: 0.9156847950950605\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (16360, 16360) entries\n",
      "Student model 1-48 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9319729175714774\n",
      "Student model 1-48 fidelity: 0.9319729175714774\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (16510, 16510) entries\n",
      "Student model 1-49 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9542087777535544\n",
      "Student model 1-49 fidelity: 0.9542087777535544\n",
      "########## Outer-loop Iteration 2/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (16660, 16660) entries\n",
      "Student model 2-0 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9533783112146496\n",
      "Student model 2-0 fidelity: 0.9533783112146496\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (16810, 16810) entries\n",
      "Student model 2-1 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9318534836961273\n",
      "Student model 2-1 fidelity: 0.9318534836961273\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (16960, 16960) entries\n",
      "Student model 2-2 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9622409062676106\n",
      "Student model 2-2 fidelity: 0.9622409062676106\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (17110, 17110) entries\n",
      "Student model 2-3 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9526342451874367\n",
      "Student model 2-3 fidelity: 0.9526342451874367\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (17260, 17260) entries\n",
      "Student model 2-4 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9632030072170915\n",
      "Student model 2-4 fidelity: 0.9632030072170915\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (17410, 17410) entries\n",
      "Student model 2-5 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9138918831171036\n",
      "Student model 2-5 fidelity: 0.9138918831171036\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (17560, 17560) entries\n",
      "Student model 2-6 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9305211467302971\n",
      "Student model 2-6 fidelity: 0.9305211467302971\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (17710, 17710) entries\n",
      "Student model 2-7 trained with depth 8 and 17 leaves:\n",
      "Student model score: 0.9528989139515455\n",
      "Student model 2-7 fidelity: 0.9528989139515455\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (17860, 17860) entries\n",
      "Student model 2-8 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.9082229248218407\n",
      "Student model 2-8 fidelity: 0.9082229248218407\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (18010, 18010) entries\n",
      "Student model 2-9 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9563284263988491\n",
      "Student model 2-9 fidelity: 0.9563284263988491\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (18160, 18160) entries\n",
      "Student model 2-10 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.93778677462888\n",
      "Student model 2-10 fidelity: 0.93778677462888\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (18310, 18310) entries\n",
      "Student model 2-11 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9360509115927073\n",
      "Student model 2-11 fidelity: 0.9360509115927073\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (18460, 18460) entries\n",
      "Student model 2-12 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9378952980234089\n",
      "Student model 2-12 fidelity: 0.9378952980234089\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (18610, 18610) entries\n",
      "Student model 2-13 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9665954415954415\n",
      "Student model 2-13 fidelity: 0.9665954415954415\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (18760, 18760) entries\n",
      "Student model 2-14 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9740496421207174\n",
      "Student model 2-14 fidelity: 0.9740496421207174\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (18910, 18910) entries\n",
      "Student model 2-15 trained with depth 7 and 8 leaves:\n",
      "Student model score: 0.9670823885109598\n",
      "Student model 2-15 fidelity: 0.9670823885109598\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (19060, 19060) entries\n",
      "Student model 2-16 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9674079463039802\n",
      "Student model 2-16 fidelity: 0.9674079463039802\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (19210, 19210) entries\n",
      "Student model 2-17 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.912742019884877\n",
      "Student model 2-17 fidelity: 0.912742019884877\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (19360, 19360) entries\n",
      "Student model 2-18 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9464869281045751\n",
      "Student model 2-18 fidelity: 0.9464869281045751\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (19510, 19510) entries\n",
      "Student model 2-19 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9202216217691531\n",
      "Student model 2-19 fidelity: 0.9202216217691531\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (19660, 19660) entries\n",
      "Student model 2-20 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9133946728006134\n",
      "Student model 2-20 fidelity: 0.9133946728006134\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (19810, 19810) entries\n",
      "Student model 2-21 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9590448983613505\n",
      "Student model 2-21 fidelity: 0.9590448983613505\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (19960, 19960) entries\n",
      "Student model 2-22 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.9526083112290009\n",
      "Student model 2-22 fidelity: 0.9526083112290009\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (20110, 20110) entries\n",
      "Student model 2-23 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9660016429679352\n",
      "Student model 2-23 fidelity: 0.9660016429679352\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (20260, 20260) entries\n",
      "Student model 2-24 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9801902520349123\n",
      "Student model 2-24 fidelity: 0.9801902520349123\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (20410, 20410) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 2-25 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9411172553021077\n",
      "Student model 2-25 fidelity: 0.9411172553021077\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (20560, 20560) entries\n",
      "Student model 2-26 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.8929738562091503\n",
      "Student model 2-26 fidelity: 0.8929738562091503\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (20710, 20710) entries\n",
      "Student model 2-27 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9207005866546766\n",
      "Student model 2-27 fidelity: 0.9207005866546766\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (20860, 20860) entries\n",
      "Student model 2-28 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9797373682918881\n",
      "Student model 2-28 fidelity: 0.9797373682918881\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (21010, 21010) entries\n",
      "Student model 2-29 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9407407407407408\n",
      "Student model 2-29 fidelity: 0.9407407407407408\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (21160, 21160) entries\n",
      "Student model 2-30 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9731919434440442\n",
      "Student model 2-30 fidelity: 0.9731919434440442\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (21310, 21310) entries\n",
      "Student model 2-31 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9726819904882927\n",
      "Student model 2-31 fidelity: 0.9726819904882927\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (21460, 21460) entries\n",
      "Student model 2-32 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.97316243770126\n",
      "Student model 2-32 fidelity: 0.97316243770126\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (21610, 21610) entries\n",
      "Student model 2-33 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.939628044065777\n",
      "Student model 2-33 fidelity: 0.939628044065777\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (21760, 21760) entries\n",
      "Student model 2-34 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.987037037037037\n",
      "Student model 2-34 fidelity: 0.987037037037037\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (21910, 21910) entries\n",
      "Student model 2-35 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9527419518260332\n",
      "Student model 2-35 fidelity: 0.9527419518260332\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (22060, 22060) entries\n",
      "Student model 2-36 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9795092838196285\n",
      "Student model 2-36 fidelity: 0.9795092838196285\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (22210, 22210) entries\n",
      "Student model 2-37 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9075469463187975\n",
      "Student model 2-37 fidelity: 0.9075469463187975\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (22360, 22360) entries\n",
      "Student model 2-38 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9469805088209479\n",
      "Student model 2-38 fidelity: 0.9469805088209479\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (22510, 22510) entries\n",
      "Student model 2-39 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9799786324786325\n",
      "Student model 2-39 fidelity: 0.9799786324786325\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (22660, 22660) entries\n",
      "Student model 2-40 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.917572070114443\n",
      "Student model 2-40 fidelity: 0.917572070114443\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (22810, 22810) entries\n",
      "Student model 2-41 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9586611149512304\n",
      "Student model 2-41 fidelity: 0.9586611149512304\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (22960, 22960) entries\n",
      "Student model 2-42 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9033304896892206\n",
      "Student model 2-42 fidelity: 0.9033304896892206\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (23110, 23110) entries\n",
      "Student model 2-43 trained with depth 4 and 12 leaves:\n",
      "Student model score: 0.9583319119904486\n",
      "Student model 2-43 fidelity: 0.9583319119904486\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (23260, 23260) entries\n",
      "Student model 2-44 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9346401871825601\n",
      "Student model 2-44 fidelity: 0.9346401871825601\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (23410, 23410) entries\n",
      "Student model 2-45 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9509482189747844\n",
      "Student model 2-45 fidelity: 0.9509482189747844\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (23560, 23560) entries\n",
      "Student model 2-46 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9599966663332999\n",
      "Student model 2-46 fidelity: 0.9599966663332999\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (23710, 23710) entries\n",
      "Student model 2-47 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9661133069828721\n",
      "Student model 2-47 fidelity: 0.9661133069828721\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (23860, 23860) entries\n",
      "Student model 2-48 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9731521718261004\n",
      "Student model 2-48 fidelity: 0.9731521718261004\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (24010, 24010) entries\n",
      "Student model 2-49 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.8972305890753702\n",
      "Student model 2-49 fidelity: 0.8972305890753702\n",
      "########## Outer-loop Iteration 3/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (24160, 24160) entries\n",
      "Student model 3-0 trained with depth 7 and 17 leaves:\n",
      "Student model score: 0.8629499219136703\n",
      "Student model 3-0 fidelity: 0.8629499219136703\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (24310, 24310) entries\n",
      "Student model 3-1 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9659788809321519\n",
      "Student model 3-1 fidelity: 0.9659788809321519\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (24460, 24460) entries\n",
      "Student model 3-2 trained with depth 6 and 8 leaves:\n",
      "Student model score: 0.9486492573667876\n",
      "Student model 3-2 fidelity: 0.9486492573667876\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (24610, 24610) entries\n",
      "Student model 3-3 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9800136845429442\n",
      "Student model 3-3 fidelity: 0.9800136845429442\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (24760, 24760) entries\n",
      "Student model 3-4 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9462296760978108\n",
      "Student model 3-4 fidelity: 0.9462296760978108\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (24910, 24910) entries\n",
      "Student model 3-5 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9862542424610133\n",
      "Student model 3-5 fidelity: 0.9862542424610133\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (25060, 25060) entries\n",
      "Student model 3-6 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9594627594627595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 3-6 fidelity: 0.9594627594627595\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (25210, 25210) entries\n",
      "Student model 3-7 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9091238235670795\n",
      "Student model 3-7 fidelity: 0.9091238235670795\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (25360, 25360) entries\n",
      "Student model 3-8 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9662261471133292\n",
      "Student model 3-8 fidelity: 0.9662261471133292\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (25510, 25510) entries\n",
      "Student model 3-9 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9776629342520815\n",
      "Student model 3-9 fidelity: 0.9776629342520815\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (25660, 25660) entries\n",
      "Student model 3-10 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9717123725375788\n",
      "Student model 3-10 fidelity: 0.9717123725375788\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (25810, 25810) entries\n",
      "Student model 3-11 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9670411006617904\n",
      "Student model 3-11 fidelity: 0.9670411006617904\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (25960, 25960) entries\n",
      "Student model 3-12 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.978779086305968\n",
      "Student model 3-12 fidelity: 0.978779086305968\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (26110, 26110) entries\n",
      "Student model 3-13 trained with depth 8 and 16 leaves:\n",
      "Student model score: 0.9319150673631355\n",
      "Student model 3-13 fidelity: 0.9319150673631355\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (26260, 26260) entries\n",
      "Student model 3-14 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.8999797938977573\n",
      "Student model 3-14 fidelity: 0.8999797938977573\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (26410, 26410) entries\n",
      "Student model 3-15 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9527287527287527\n",
      "Student model 3-15 fidelity: 0.9527287527287527\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (26560, 26560) entries\n",
      "Student model 3-16 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9870233622662693\n",
      "Student model 3-16 fidelity: 0.9870233622662693\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (26710, 26710) entries\n",
      "Student model 3-17 trained with depth 7 and 9 leaves:\n",
      "Student model score: 0.9655977325640247\n",
      "Student model 3-17 fidelity: 0.9655977325640247\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (26860, 26860) entries\n",
      "Student model 3-18 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9523146893165868\n",
      "Student model 3-18 fidelity: 0.9523146893165868\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (27010, 27010) entries\n",
      "Student model 3-19 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9734308900975567\n",
      "Student model 3-19 fidelity: 0.9734308900975567\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (27160, 27160) entries\n",
      "Student model 3-20 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9258613323106011\n",
      "Student model 3-20 fidelity: 0.9258613323106011\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (27310, 27310) entries\n",
      "Student model 3-21 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9313728676753396\n",
      "Student model 3-21 fidelity: 0.9313728676753396\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (27460, 27460) entries\n",
      "Student model 3-22 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9464701001413341\n",
      "Student model 3-22 fidelity: 0.9464701001413341\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (27610, 27610) entries\n",
      "Student model 3-23 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9582433244391337\n",
      "Student model 3-23 fidelity: 0.9582433244391337\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (27760, 27760) entries\n",
      "Student model 3-24 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9662114547743812\n",
      "Student model 3-24 fidelity: 0.9662114547743812\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (27910, 27910) entries\n",
      "Student model 3-25 trained with depth 8 and 16 leaves:\n",
      "Student model score: 0.9671228938146231\n",
      "Student model 3-25 fidelity: 0.9671228938146231\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (28060, 28060) entries\n",
      "Student model 3-26 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9255766933186287\n",
      "Student model 3-26 fidelity: 0.9255766933186287\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (28210, 28210) entries\n",
      "Student model 3-27 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9737225451511167\n",
      "Student model 3-27 fidelity: 0.9737225451511167\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (28360, 28360) entries\n",
      "Student model 3-28 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9534030784030785\n",
      "Student model 3-28 fidelity: 0.9534030784030785\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (28510, 28510) entries\n",
      "Student model 3-29 trained with depth 7 and 17 leaves:\n",
      "Student model score: 0.9737484737484737\n",
      "Student model 3-29 fidelity: 0.9737484737484737\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (28660, 28660) entries\n",
      "Student model 3-30 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9729830322933771\n",
      "Student model 3-30 fidelity: 0.9729830322933771\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (28810, 28810) entries\n",
      "Student model 3-31 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9319321291735084\n",
      "Student model 3-31 fidelity: 0.9319321291735084\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (28960, 28960) entries\n",
      "Student model 3-32 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9791583044456608\n",
      "Student model 3-32 fidelity: 0.9791583044456608\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (29110, 29110) entries\n",
      "Student model 3-33 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9368530020703933\n",
      "Student model 3-33 fidelity: 0.9368530020703933\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (29260, 29260) entries\n",
      "Student model 3-34 trained with depth 6 and 16 leaves:\n",
      "Student model score: 0.9569412900606737\n",
      "Student model 3-34 fidelity: 0.9569412900606737\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (29410, 29410) entries\n",
      "Student model 3-35 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9746503695870784\n",
      "Student model 3-35 fidelity: 0.9746503695870784\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (29560, 29560) entries\n",
      "Student model 3-36 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9674140280153435\n",
      "Student model 3-36 fidelity: 0.9674140280153435\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (29710, 29710) entries\n",
      "Student model 3-37 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9353956228956228\n",
      "Student model 3-37 fidelity: 0.9353956228956228\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (29860, 29860) entries\n",
      "Student model 3-38 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9462618034046605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 3-38 fidelity: 0.9462618034046605\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (30010, 30010) entries\n",
      "Student model 3-39 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9355089355089355\n",
      "Student model 3-39 fidelity: 0.9355089355089355\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (30160, 30160) entries\n",
      "Student model 3-40 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9648807932689248\n",
      "Student model 3-40 fidelity: 0.9648807932689248\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (30310, 30310) entries\n",
      "Student model 3-41 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9255394059763474\n",
      "Student model 3-41 fidelity: 0.9255394059763474\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (30460, 30460) entries\n",
      "Student model 3-42 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.972667740203972\n",
      "Student model 3-42 fidelity: 0.972667740203972\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (30610, 30610) entries\n",
      "Student model 3-43 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9668263466436815\n",
      "Student model 3-43 fidelity: 0.9668263466436815\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (30760, 30760) entries\n",
      "Student model 3-44 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9466246288326161\n",
      "Student model 3-44 fidelity: 0.9466246288326161\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (30910, 30910) entries\n",
      "Student model 3-45 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9303551257679699\n",
      "Student model 3-45 fidelity: 0.9303551257679699\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (31060, 31060) entries\n",
      "Student model 3-46 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9656659765355418\n",
      "Student model 3-46 fidelity: 0.9656659765355418\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (31210, 31210) entries\n",
      "Student model 3-47 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9719175076788065\n",
      "Student model 3-47 fidelity: 0.9719175076788065\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (31360, 31360) entries\n",
      "Student model 3-48 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9609516000141879\n",
      "Student model 3-48 fidelity: 0.9609516000141879\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (31510, 31510) entries\n",
      "Student model 3-49 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9519171855726589\n",
      "Student model 3-49 fidelity: 0.9519171855726589\n",
      "########## Outer-loop Iteration 4/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (31660, 31660) entries\n",
      "Student model 4-0 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.979600307878388\n",
      "Student model 4-0 fidelity: 0.979600307878388\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (31810, 31810) entries\n",
      "Student model 4-1 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9668977004083387\n",
      "Student model 4-1 fidelity: 0.9668977004083387\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (31960, 31960) entries\n",
      "Student model 4-2 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9786630348428101\n",
      "Student model 4-2 fidelity: 0.9786630348428101\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (32110, 32110) entries\n",
      "Student model 4-3 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9368705527269144\n",
      "Student model 4-3 fidelity: 0.9368705527269144\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (32260, 32260) entries\n",
      "Student model 4-4 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9732323232323233\n",
      "Student model 4-4 fidelity: 0.9732323232323233\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (32410, 32410) entries\n",
      "Student model 4-5 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9667987172231655\n",
      "Student model 4-5 fidelity: 0.9667987172231655\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (32560, 32560) entries\n",
      "Student model 4-6 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9404485130291581\n",
      "Student model 4-6 fidelity: 0.9404485130291581\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (32710, 32710) entries\n",
      "Student model 4-7 trained with depth 6 and 16 leaves:\n",
      "Student model score: 0.9465366902774855\n",
      "Student model 4-7 fidelity: 0.9465366902774855\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (32860, 32860) entries\n",
      "Student model 4-8 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9607021551594578\n",
      "Student model 4-8 fidelity: 0.9607021551594578\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (33010, 33010) entries\n",
      "Student model 4-9 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9798411465078131\n",
      "Student model 4-9 fidelity: 0.9798411465078131\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (33160, 33160) entries\n",
      "Student model 4-10 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9181818181818181\n",
      "Student model 4-10 fidelity: 0.9181818181818181\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (33310, 33310) entries\n",
      "Student model 4-11 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9542317119038467\n",
      "Student model 4-11 fidelity: 0.9542317119038467\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (33460, 33460) entries\n",
      "Student model 4-12 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9936422252211726\n",
      "Student model 4-12 fidelity: 0.9936422252211726\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (33610, 33610) entries\n",
      "Student model 4-13 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9572527935905545\n",
      "Student model 4-13 fidelity: 0.9572527935905545\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (33760, 33760) entries\n",
      "Student model 4-14 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9667677053767458\n",
      "Student model 4-14 fidelity: 0.9667677053767458\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (33910, 33910) entries\n",
      "Student model 4-15 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9855006105006106\n",
      "Student model 4-15 fidelity: 0.9855006105006106\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (34060, 34060) entries\n",
      "Student model 4-16 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9523232323232325\n",
      "Student model 4-16 fidelity: 0.9523232323232325\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (34210, 34210) entries\n",
      "Student model 4-17 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9721975033988383\n",
      "Student model 4-17 fidelity: 0.9721975033988383\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (34360, 34360) entries\n",
      "Student model 4-18 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9520443214526909\n",
      "Student model 4-18 fidelity: 0.9520443214526909\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (34510, 34510) entries\n",
      "Student model 4-19 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9664949006977993\n",
      "Student model 4-19 fidelity: 0.9664949006977993\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (34660, 34660) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 4-20 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9528989139515455\n",
      "Student model 4-20 fidelity: 0.9528989139515455\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (34810, 34810) entries\n",
      "Student model 4-21 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9411199508051808\n",
      "Student model 4-21 fidelity: 0.9411199508051808\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (34960, 34960) entries\n",
      "Student model 4-22 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9540349113670469\n",
      "Student model 4-22 fidelity: 0.9540349113670469\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (35110, 35110) entries\n",
      "Student model 4-23 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9457411645054665\n",
      "Student model 4-23 fidelity: 0.9457411645054665\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (35260, 35260) entries\n",
      "Student model 4-24 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9662482901277817\n",
      "Student model 4-24 fidelity: 0.9662482901277817\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (35410, 35410) entries\n",
      "Student model 4-25 trained with depth 8 and 16 leaves:\n",
      "Student model score: 0.9605922096087322\n",
      "Student model 4-25 fidelity: 0.9605922096087322\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (35560, 35560) entries\n",
      "Student model 4-26 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.959610095063456\n",
      "Student model 4-26 fidelity: 0.959610095063456\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (35710, 35710) entries\n",
      "Student model 4-27 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9565685356930146\n",
      "Student model 4-27 fidelity: 0.9565685356930146\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (35860, 35860) entries\n",
      "Student model 4-28 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9136213653116075\n",
      "Student model 4-28 fidelity: 0.9136213653116075\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (36010, 36010) entries\n",
      "Student model 4-29 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9669900282933085\n",
      "Student model 4-29 fidelity: 0.9669900282933085\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (36160, 36160) entries\n",
      "Student model 4-30 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9861823361823362\n",
      "Student model 4-30 fidelity: 0.9861823361823362\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (36310, 36310) entries\n",
      "Student model 4-31 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9347212758977465\n",
      "Student model 4-31 fidelity: 0.9347212758977465\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (36460, 36460) entries\n",
      "Student model 4-32 trained with depth 7 and 17 leaves:\n",
      "Student model score: 0.9136609012537052\n",
      "Student model 4-32 fidelity: 0.9136609012537052\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (36610, 36610) entries\n",
      "Student model 4-33 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.959925635199339\n",
      "Student model 4-33 fidelity: 0.959925635199339\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (36760, 36760) entries\n",
      "Student model 4-34 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9572937896783564\n",
      "Student model 4-34 fidelity: 0.9572937896783564\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (36910, 36910) entries\n",
      "Student model 4-35 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9507919054600382\n",
      "Student model 4-35 fidelity: 0.9507919054600382\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (37060, 37060) entries\n",
      "Student model 4-36 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9667418427235982\n",
      "Student model 4-36 fidelity: 0.9667418427235982\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (37210, 37210) entries\n",
      "Student model 4-37 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9463007484074271\n",
      "Student model 4-37 fidelity: 0.9463007484074271\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (37360, 37360) entries\n",
      "Student model 4-38 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9928498106261725\n",
      "Student model 4-38 fidelity: 0.9928498106261725\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (37510, 37510) entries\n",
      "Student model 4-39 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9466818642350558\n",
      "Student model 4-39 fidelity: 0.9466818642350558\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (37660, 37660) entries\n",
      "Student model 4-40 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9639701511972495\n",
      "Student model 4-40 fidelity: 0.9639701511972495\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (37810, 37810) entries\n",
      "Student model 4-41 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9612385665017245\n",
      "Student model 4-41 fidelity: 0.9612385665017245\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (37960, 37960) entries\n",
      "Student model 4-42 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9332912954992828\n",
      "Student model 4-42 fidelity: 0.9332912954992828\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (38110, 38110) entries\n",
      "Student model 4-43 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9478882391163093\n",
      "Student model 4-43 fidelity: 0.9478882391163093\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (38260, 38260) entries\n",
      "Student model 4-44 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9570175438596492\n",
      "Student model 4-44 fidelity: 0.9570175438596492\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (38410, 38410) entries\n",
      "Student model 4-45 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9445033366211787\n",
      "Student model 4-45 fidelity: 0.9445033366211787\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (38560, 38560) entries\n",
      "Student model 4-46 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9934882250671725\n",
      "Student model 4-46 fidelity: 0.9934882250671725\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (38710, 38710) entries\n",
      "Student model 4-47 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.960935441370224\n",
      "Student model 4-47 fidelity: 0.960935441370224\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (38860, 38860) entries\n",
      "Student model 4-48 trained with depth 8 and 16 leaves:\n",
      "Student model score: 0.9449481476632352\n",
      "Student model 4-48 fidelity: 0.9449481476632352\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (39010, 39010) entries\n",
      "Student model 4-49 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9214461108073292\n",
      "Student model 4-49 fidelity: 0.9214461108073292\n",
      "########## Outer-loop Iteration 5/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (39160, 39160) entries\n",
      "Student model 5-0 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9574349443657182\n",
      "Student model 5-0 fidelity: 0.9574349443657182\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (39310, 39310) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 5-1 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9322305764411026\n",
      "Student model 5-1 fidelity: 0.9322305764411026\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (39460, 39460) entries\n",
      "Student model 5-2 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9475319242668617\n",
      "Student model 5-2 fidelity: 0.9475319242668617\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (39610, 39610) entries\n",
      "Student model 5-3 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.952543805504118\n",
      "Student model 5-3 fidelity: 0.952543805504118\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (39760, 39760) entries\n",
      "Student model 5-4 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.916255674150411\n",
      "Student model 5-4 fidelity: 0.916255674150411\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (39910, 39910) entries\n",
      "Student model 5-5 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9807643811029257\n",
      "Student model 5-5 fidelity: 0.9807643811029257\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (40060, 40060) entries\n",
      "Student model 5-6 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9271056876358791\n",
      "Student model 5-6 fidelity: 0.9271056876358791\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (40210, 40210) entries\n",
      "Student model 5-7 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.965560851010809\n",
      "Student model 5-7 fidelity: 0.965560851010809\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (40360, 40360) entries\n",
      "Student model 5-8 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9401939443257722\n",
      "Student model 5-8 fidelity: 0.9401939443257722\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (40510, 40510) entries\n",
      "Student model 5-9 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.954959371052582\n",
      "Student model 5-9 fidelity: 0.954959371052582\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (40660, 40660) entries\n",
      "Student model 5-10 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9301089956429762\n",
      "Student model 5-10 fidelity: 0.9301089956429762\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (40810, 40810) entries\n",
      "Student model 5-11 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9581349206349206\n",
      "Student model 5-11 fidelity: 0.9581349206349206\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (40960, 40960) entries\n",
      "Student model 5-12 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9406160821768808\n",
      "Student model 5-12 fidelity: 0.9406160821768808\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (41110, 41110) entries\n",
      "Student model 5-13 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9540688676855987\n",
      "Student model 5-13 fidelity: 0.9540688676855987\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (41260, 41260) entries\n",
      "Student model 5-14 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9476081176875478\n",
      "Student model 5-14 fidelity: 0.9476081176875478\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (41410, 41410) entries\n",
      "Student model 5-15 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9253369989907059\n",
      "Student model 5-15 fidelity: 0.9253369989907059\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (41560, 41560) entries\n",
      "Student model 5-16 trained with depth 6 and 8 leaves:\n",
      "Student model score: 0.9578878991489876\n",
      "Student model 5-16 fidelity: 0.9578878991489876\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (41710, 41710) entries\n",
      "Student model 5-17 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.904884810825405\n",
      "Student model 5-17 fidelity: 0.904884810825405\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (41860, 41860) entries\n",
      "Student model 5-18 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9635882158225754\n",
      "Student model 5-18 fidelity: 0.9635882158225754\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (42010, 42010) entries\n",
      "Student model 5-19 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9575351293797896\n",
      "Student model 5-19 fidelity: 0.9575351293797896\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (42160, 42160) entries\n",
      "Student model 5-20 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9669516929578849\n",
      "Student model 5-20 fidelity: 0.9669516929578849\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (42310, 42310) entries\n",
      "Student model 5-21 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9535714285714286\n",
      "Student model 5-21 fidelity: 0.9535714285714286\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (42460, 42460) entries\n",
      "Student model 5-22 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9534242487501472\n",
      "Student model 5-22 fidelity: 0.9534242487501472\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (42610, 42610) entries\n",
      "Student model 5-23 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9518198906819646\n",
      "Student model 5-23 fidelity: 0.9518198906819646\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (42760, 42760) entries\n",
      "Student model 5-24 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9665703198180116\n",
      "Student model 5-24 fidelity: 0.9665703198180116\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (42910, 42910) entries\n",
      "Student model 5-25 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9664848007151802\n",
      "Student model 5-25 fidelity: 0.9664848007151802\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (43060, 43060) entries\n",
      "Student model 5-26 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9682494030784964\n",
      "Student model 5-26 fidelity: 0.9682494030784964\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (43210, 43210) entries\n",
      "Student model 5-27 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.940233918128655\n",
      "Student model 5-27 fidelity: 0.940233918128655\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (43360, 43360) entries\n",
      "Student model 5-28 trained with depth 6 and 18 leaves:\n",
      "Student model score: 0.9172801460937053\n",
      "Student model 5-28 fidelity: 0.9172801460937053\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (43510, 43510) entries\n",
      "Student model 5-29 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9671380471380471\n",
      "Student model 5-29 fidelity: 0.9671380471380471\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (43660, 43660) entries\n",
      "Student model 5-30 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9474170713717828\n",
      "Student model 5-30 fidelity: 0.9474170713717828\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (43810, 43810) entries\n",
      "Student model 5-31 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9600600510233083\n",
      "Student model 5-31 fidelity: 0.9600600510233083\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (43960, 43960) entries\n",
      "Student model 5-32 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9385667014977358\n",
      "Student model 5-32 fidelity: 0.9385667014977358\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (44110, 44110) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 5-33 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9465199413098574\n",
      "Student model 5-33 fidelity: 0.9465199413098574\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (44260, 44260) entries\n",
      "Student model 5-34 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9582433244391337\n",
      "Student model 5-34 fidelity: 0.9582433244391337\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (44410, 44410) entries\n",
      "Student model 5-35 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9723537493872422\n",
      "Student model 5-35 fidelity: 0.9723537493872422\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (44560, 44560) entries\n",
      "Student model 5-36 trained with depth 7 and 17 leaves:\n",
      "Student model score: 0.9263120134926499\n",
      "Student model 5-36 fidelity: 0.9263120134926499\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (44710, 44710) entries\n",
      "Student model 5-37 trained with depth 6 and 16 leaves:\n",
      "Student model score: 0.9570410397683125\n",
      "Student model 5-37 fidelity: 0.9570410397683125\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (44860, 44860) entries\n",
      "Student model 5-38 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9612433862433862\n",
      "Student model 5-38 fidelity: 0.9612433862433862\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (45010, 45010) entries\n",
      "Student model 5-39 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9059052848801651\n",
      "Student model 5-39 fidelity: 0.9059052848801651\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (45160, 45160) entries\n",
      "Student model 5-40 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9486930519929085\n",
      "Student model 5-40 fidelity: 0.9486930519929085\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (45310, 45310) entries\n",
      "Student model 5-41 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9540060112918844\n",
      "Student model 5-41 fidelity: 0.9540060112918844\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (45460, 45460) entries\n",
      "Student model 5-42 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9662394554867673\n",
      "Student model 5-42 fidelity: 0.9662394554867673\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (45610, 45610) entries\n",
      "Student model 5-43 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9467353206342778\n",
      "Student model 5-43 fidelity: 0.9467353206342778\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (45760, 45760) entries\n",
      "Student model 5-44 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9548548035885376\n",
      "Student model 5-44 fidelity: 0.9548548035885376\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (45910, 45910) entries\n",
      "Student model 5-45 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9506049842617458\n",
      "Student model 5-45 fidelity: 0.9506049842617458\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (46060, 46060) entries\n",
      "Student model 5-46 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9808978422419196\n",
      "Student model 5-46 fidelity: 0.9808978422419196\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (46210, 46210) entries\n",
      "Student model 5-47 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.959483148097949\n",
      "Student model 5-47 fidelity: 0.959483148097949\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (46360, 46360) entries\n",
      "Student model 5-48 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9461355093374696\n",
      "Student model 5-48 fidelity: 0.9461355093374696\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (46510, 46510) entries\n",
      "Student model 5-49 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9403838142312969\n",
      "Student model 5-49 fidelity: 0.9403838142312969\n",
      "########## Outer-loop Iteration 6/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (46660, 46660) entries\n",
      "Student model 6-0 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.986443522556702\n",
      "Student model 6-0 fidelity: 0.986443522556702\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (46810, 46810) entries\n",
      "Student model 6-1 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9559060552909214\n",
      "Student model 6-1 fidelity: 0.9559060552909214\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (46960, 46960) entries\n",
      "Student model 6-2 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9448373875574202\n",
      "Student model 6-2 fidelity: 0.9448373875574202\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (47110, 47110) entries\n",
      "Student model 6-3 trained with depth 8 and 17 leaves:\n",
      "Student model score: 0.9342080417131128\n",
      "Student model 6-3 fidelity: 0.9342080417131128\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (47260, 47260) entries\n",
      "Student model 6-4 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9671875587841975\n",
      "Student model 6-4 fidelity: 0.9671875587841975\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (47410, 47410) entries\n",
      "Student model 6-5 trained with depth 9 and 15 leaves:\n",
      "Student model score: 0.9128759218344884\n",
      "Student model 6-5 fidelity: 0.9128759218344884\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (47560, 47560) entries\n",
      "Student model 6-6 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9254499398988006\n",
      "Student model 6-6 fidelity: 0.9254499398988006\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (47710, 47710) entries\n",
      "Student model 6-7 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9531325803387792\n",
      "Student model 6-7 fidelity: 0.9531325803387792\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (47860, 47860) entries\n",
      "Student model 6-8 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9346092503987241\n",
      "Student model 6-8 fidelity: 0.9346092503987241\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (48010, 48010) entries\n",
      "Student model 6-9 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9739025725232623\n",
      "Student model 6-9 fidelity: 0.9739025725232623\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (48160, 48160) entries\n",
      "Student model 6-10 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9558256439951829\n",
      "Student model 6-10 fidelity: 0.9558256439951829\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (48310, 48310) entries\n",
      "Student model 6-11 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9334817097528961\n",
      "Student model 6-11 fidelity: 0.9334817097528961\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (48460, 48460) entries\n",
      "Student model 6-12 trained with depth 4 and 10 leaves:\n",
      "Student model score: 0.9186081961426141\n",
      "Student model 6-12 fidelity: 0.9186081961426141\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (48610, 48610) entries\n",
      "Student model 6-13 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9065390749601275\n",
      "Student model 6-13 fidelity: 0.9065390749601275\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (48760, 48760) entries\n",
      "Student model 6-14 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9665813363817123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 6-14 fidelity: 0.9665813363817123\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (48910, 48910) entries\n",
      "Student model 6-15 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9592308881237774\n",
      "Student model 6-15 fidelity: 0.9592308881237774\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (49060, 49060) entries\n",
      "Student model 6-16 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9260879731697867\n",
      "Student model 6-16 fidelity: 0.9260879731697867\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (49210, 49210) entries\n",
      "Student model 6-17 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.946020224016776\n",
      "Student model 6-17 fidelity: 0.946020224016776\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (49360, 49360) entries\n",
      "Student model 6-18 trained with depth 8 and 17 leaves:\n",
      "Student model score: 0.972355419936065\n",
      "Student model 6-18 fidelity: 0.972355419936065\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (49510, 49510) entries\n",
      "Student model 6-19 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9457725712706623\n",
      "Student model 6-19 fidelity: 0.9457725712706623\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (49660, 49660) entries\n",
      "Student model 6-20 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9602350427350427\n",
      "Student model 6-20 fidelity: 0.9602350427350427\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (49810, 49810) entries\n",
      "Student model 6-21 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.953139345951748\n",
      "Student model 6-21 fidelity: 0.953139345951748\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (49960, 49960) entries\n",
      "Student model 6-22 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9667677053767458\n",
      "Student model 6-22 fidelity: 0.9667677053767458\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (50110, 50110) entries\n",
      "Student model 6-23 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.9186081961426144\n",
      "Student model 6-23 fidelity: 0.9186081961426144\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (50260, 50260) entries\n",
      "Student model 6-24 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9936415659914615\n",
      "Student model 6-24 fidelity: 0.9936415659914615\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (50410, 50410) entries\n",
      "Student model 6-25 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9504655960744953\n",
      "Student model 6-25 fidelity: 0.9504655960744953\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (50560, 50560) entries\n",
      "Student model 6-26 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9934331240946402\n",
      "Student model 6-26 fidelity: 0.9934331240946402\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (50710, 50710) entries\n",
      "Student model 6-27 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9599299747130909\n",
      "Student model 6-27 fidelity: 0.9599299747130909\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (50860, 50860) entries\n",
      "Student model 6-28 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9652536615852831\n",
      "Student model 6-28 fidelity: 0.9652536615852831\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (51010, 51010) entries\n",
      "Student model 6-29 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9791989704745818\n",
      "Student model 6-29 fidelity: 0.9791989704745818\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (51160, 51160) entries\n",
      "Student model 6-30 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.8815000756372436\n",
      "Student model 6-30 fidelity: 0.8815000756372436\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (51310, 51310) entries\n",
      "Student model 6-31 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9601157163981257\n",
      "Student model 6-31 fidelity: 0.9601157163981257\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (51460, 51460) entries\n",
      "Student model 6-32 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9744831683979757\n",
      "Student model 6-32 fidelity: 0.9744831683979757\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (51610, 51610) entries\n",
      "Student model 6-33 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9667980131346469\n",
      "Student model 6-33 fidelity: 0.9667980131346469\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (51760, 51760) entries\n",
      "Student model 6-34 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.96005476005476\n",
      "Student model 6-34 fidelity: 0.96005476005476\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (51910, 51910) entries\n",
      "Student model 6-35 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9653540903540904\n",
      "Student model 6-35 fidelity: 0.9653540903540904\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (52060, 52060) entries\n",
      "Student model 6-36 trained with depth 8 and 16 leaves:\n",
      "Student model score: 0.9740041825428108\n",
      "Student model 6-36 fidelity: 0.9740041825428108\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (52210, 52210) entries\n",
      "Student model 6-37 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9738461538461539\n",
      "Student model 6-37 fidelity: 0.9738461538461539\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (52360, 52360) entries\n",
      "Student model 6-38 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9537637730408814\n",
      "Student model 6-38 fidelity: 0.9537637730408814\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (52510, 52510) entries\n",
      "Student model 6-39 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9739613359468082\n",
      "Student model 6-39 fidelity: 0.9739613359468082\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (52660, 52660) entries\n",
      "Student model 6-40 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9734555964485475\n",
      "Student model 6-40 fidelity: 0.9734555964485475\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (52810, 52810) entries\n",
      "Student model 6-41 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.959822430382605\n",
      "Student model 6-41 fidelity: 0.959822430382605\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (52960, 52960) entries\n",
      "Student model 6-42 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9736148896661917\n",
      "Student model 6-42 fidelity: 0.9736148896661917\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (53110, 53110) entries\n",
      "Student model 6-43 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9398030179813861\n",
      "Student model 6-43 fidelity: 0.9398030179813861\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (53260, 53260) entries\n",
      "Student model 6-44 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.960525321239607\n",
      "Student model 6-44 fidelity: 0.960525321239607\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (53410, 53410) entries\n",
      "Student model 6-45 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.8865352492338312\n",
      "Student model 6-45 fidelity: 0.8865352492338312\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (53560, 53560) entries\n",
      "Student model 6-46 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9786096256684492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 6-46 fidelity: 0.9786096256684492\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (53710, 53710) entries\n",
      "Student model 6-47 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9407880353368908\n",
      "Student model 6-47 fidelity: 0.9407880353368908\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (53860, 53860) entries\n",
      "Student model 6-48 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9531991744066047\n",
      "Student model 6-48 fidelity: 0.9531991744066047\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (54010, 54010) entries\n",
      "Student model 6-49 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9553988338532604\n",
      "Student model 6-49 fidelity: 0.9553988338532604\n",
      "########## Outer-loop Iteration 7/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (54160, 54160) entries\n",
      "Student model 7-0 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9207111302311519\n",
      "Student model 7-0 fidelity: 0.9207111302311519\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (54310, 54310) entries\n",
      "Student model 7-1 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9589296817880545\n",
      "Student model 7-1 fidelity: 0.9589296817880545\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (54460, 54460) entries\n",
      "Student model 7-2 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9535714285714286\n",
      "Student model 7-2 fidelity: 0.9535714285714286\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (54610, 54610) entries\n",
      "Student model 7-3 trained with depth 5 and 16 leaves:\n",
      "Student model score: 0.9070282563424538\n",
      "Student model 7-3 fidelity: 0.9070282563424538\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (54760, 54760) entries\n",
      "Student model 7-4 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9277861069465269\n",
      "Student model 7-4 fidelity: 0.9277861069465269\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (54910, 54910) entries\n",
      "Student model 7-5 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.94689950488425\n",
      "Student model 7-5 fidelity: 0.94689950488425\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (55060, 55060) entries\n",
      "Student model 7-6 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9201521369232308\n",
      "Student model 7-6 fidelity: 0.9201521369232308\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (55210, 55210) entries\n",
      "Student model 7-7 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9361370815916269\n",
      "Student model 7-7 fidelity: 0.9361370815916269\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (55360, 55360) entries\n",
      "Student model 7-8 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9141142404841344\n",
      "Student model 7-8 fidelity: 0.9141142404841344\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (55510, 55510) entries\n",
      "Student model 7-9 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9675165792812853\n",
      "Student model 7-9 fidelity: 0.9675165792812853\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (55660, 55660) entries\n",
      "Student model 7-10 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9604794454606721\n",
      "Student model 7-10 fidelity: 0.9604794454606721\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (55810, 55810) entries\n",
      "Student model 7-11 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9666362585902816\n",
      "Student model 7-11 fidelity: 0.9666362585902816\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (55960, 55960) entries\n",
      "Student model 7-12 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9864673105624058\n",
      "Student model 7-12 fidelity: 0.9864673105624058\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (56110, 56110) entries\n",
      "Student model 7-13 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.8916971916971917\n",
      "Student model 7-13 fidelity: 0.8916971916971917\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (56260, 56260) entries\n",
      "Student model 7-14 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.9869230769230769\n",
      "Student model 7-14 fidelity: 0.9869230769230769\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (56410, 56410) entries\n",
      "Student model 7-15 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9599572649572651\n",
      "Student model 7-15 fidelity: 0.9599572649572651\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (56560, 56560) entries\n",
      "Student model 7-16 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9364029855833134\n",
      "Student model 7-16 fidelity: 0.9364029855833134\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (56710, 56710) entries\n",
      "Student model 7-17 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9671377899571311\n",
      "Student model 7-17 fidelity: 0.9671377899571311\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (56860, 56860) entries\n",
      "Student model 7-18 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9610423116615067\n",
      "Student model 7-18 fidelity: 0.9610423116615067\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (57010, 57010) entries\n",
      "Student model 7-19 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9083443142849084\n",
      "Student model 7-19 fidelity: 0.9083443142849084\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (57160, 57160) entries\n",
      "Student model 7-20 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9866296316600575\n",
      "Student model 7-20 fidelity: 0.9866296316600575\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (57310, 57310) entries\n",
      "Student model 7-21 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9866925064599483\n",
      "Student model 7-21 fidelity: 0.9866925064599483\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (57460, 57460) entries\n",
      "Student model 7-22 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.9205094422485726\n",
      "Student model 7-22 fidelity: 0.9205094422485726\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (57610, 57610) entries\n",
      "Student model 7-23 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9402405269256864\n",
      "Student model 7-23 fidelity: 0.9402405269256864\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (57760, 57760) entries\n",
      "Student model 7-24 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9609516000141881\n",
      "Student model 7-24 fidelity: 0.9609516000141881\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (57910, 57910) entries\n",
      "Student model 7-25 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9680136420357387\n",
      "Student model 7-25 fidelity: 0.9680136420357387\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (58060, 58060) entries\n",
      "Student model 7-26 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.974313865400335\n",
      "Student model 7-26 fidelity: 0.974313865400335\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (58210, 58210) entries\n",
      "Student model 7-27 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9472121193904236\n",
      "Student model 7-27 fidelity: 0.9472121193904236\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (58360, 58360) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 7-28 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9332156344474374\n",
      "Student model 7-28 fidelity: 0.9332156344474374\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (58510, 58510) entries\n",
      "Student model 7-29 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9485616723219389\n",
      "Student model 7-29 fidelity: 0.9485616723219389\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (58660, 58660) entries\n",
      "Student model 7-30 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9384389772493047\n",
      "Student model 7-30 fidelity: 0.9384389772493047\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (58810, 58810) entries\n",
      "Student model 7-31 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.9242497783075186\n",
      "Student model 7-31 fidelity: 0.9242497783075186\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (58960, 58960) entries\n",
      "Student model 7-32 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9656846889699277\n",
      "Student model 7-32 fidelity: 0.9656846889699277\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (59110, 59110) entries\n",
      "Student model 7-33 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.966478664591872\n",
      "Student model 7-33 fidelity: 0.966478664591872\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (59260, 59260) entries\n",
      "Student model 7-34 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9259167201750934\n",
      "Student model 7-34 fidelity: 0.9259167201750934\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (59410, 59410) entries\n",
      "Student model 7-35 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9868937455543306\n",
      "Student model 7-35 fidelity: 0.9868937455543306\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (59560, 59560) entries\n",
      "Student model 7-36 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9922470137480279\n",
      "Student model 7-36 fidelity: 0.9922470137480279\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (59710, 59710) entries\n",
      "Student model 7-37 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.922659528766399\n",
      "Student model 7-37 fidelity: 0.922659528766399\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (59860, 59860) entries\n",
      "Student model 7-38 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9869597615499255\n",
      "Student model 7-38 fidelity: 0.9869597615499255\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (60010, 60010) entries\n",
      "Student model 7-39 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9458032785763878\n",
      "Student model 7-39 fidelity: 0.9458032785763878\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (60160, 60160) entries\n",
      "Student model 7-40 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9479631354645429\n",
      "Student model 7-40 fidelity: 0.9479631354645429\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (60310, 60310) entries\n",
      "Student model 7-41 trained with depth 8 and 11 leaves:\n",
      "Student model score: 0.9589185011326701\n",
      "Student model 7-41 fidelity: 0.9589185011326701\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (60460, 60460) entries\n",
      "Student model 7-42 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9059000296299912\n",
      "Student model 7-42 fidelity: 0.9059000296299912\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (60610, 60610) entries\n",
      "Student model 7-43 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.952638741689951\n",
      "Student model 7-43 fidelity: 0.952638741689951\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (60760, 60760) entries\n",
      "Student model 7-44 trained with depth 8 and 18 leaves:\n",
      "Student model score: 0.9090244229736983\n",
      "Student model 7-44 fidelity: 0.9090244229736983\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (60910, 60910) entries\n",
      "Student model 7-45 trained with depth 6 and 17 leaves:\n",
      "Student model score: 0.9396040275742278\n",
      "Student model 7-45 fidelity: 0.9396040275742278\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (61060, 61060) entries\n",
      "Student model 7-46 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9531325803387792\n",
      "Student model 7-46 fidelity: 0.9531325803387792\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (61210, 61210) entries\n",
      "Student model 7-47 trained with depth 6 and 16 leaves:\n",
      "Student model score: 0.972636720005141\n",
      "Student model 7-47 fidelity: 0.972636720005141\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (61360, 61360) entries\n",
      "Student model 7-48 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9592765997617857\n",
      "Student model 7-48 fidelity: 0.9592765997617857\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (61510, 61510) entries\n",
      "Student model 7-49 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9348604960545259\n",
      "Student model 7-49 fidelity: 0.9348604960545259\n",
      "########## Outer-loop Iteration 8/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (61660, 61660) entries\n",
      "Student model 8-0 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9240066853281655\n",
      "Student model 8-0 fidelity: 0.9240066853281655\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (61810, 61810) entries\n",
      "Student model 8-1 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9537664528176862\n",
      "Student model 8-1 fidelity: 0.9537664528176862\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (61960, 61960) entries\n",
      "Student model 8-2 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9362344039077658\n",
      "Student model 8-2 fidelity: 0.9362344039077658\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (62110, 62110) entries\n",
      "Student model 8-3 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.9333333333333332\n",
      "Student model 8-3 fidelity: 0.9333333333333332\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (62260, 62260) entries\n",
      "Student model 8-4 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9403466360758995\n",
      "Student model 8-4 fidelity: 0.9403466360758995\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (62410, 62410) entries\n",
      "Student model 8-5 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.973234850768767\n",
      "Student model 8-5 fidelity: 0.973234850768767\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (62560, 62560) entries\n",
      "Student model 8-6 trained with depth 7 and 17 leaves:\n",
      "Student model score: 0.9188256527167127\n",
      "Student model 8-6 fidelity: 0.9188256527167127\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (62710, 62710) entries\n",
      "Student model 8-7 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9481171107070386\n",
      "Student model 8-7 fidelity: 0.9481171107070386\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (62860, 62860) entries\n",
      "Student model 8-8 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9672387198884059\n",
      "Student model 8-8 fidelity: 0.9672387198884059\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (63010, 63010) entries\n",
      "Student model 8-9 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.9449228359312087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 8-9 fidelity: 0.9449228359312087\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (63160, 63160) entries\n",
      "Student model 8-10 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.952152378622967\n",
      "Student model 8-10 fidelity: 0.952152378622967\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (63310, 63310) entries\n",
      "Student model 8-11 trained with depth 8 and 19 leaves:\n",
      "Student model score: 0.9383333333333334\n",
      "Student model 8-11 fidelity: 0.9383333333333334\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (63460, 63460) entries\n",
      "Student model 8-12 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9523811435806424\n",
      "Student model 8-12 fidelity: 0.9523811435806424\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (63610, 63610) entries\n",
      "Student model 8-13 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9726104209799861\n",
      "Student model 8-13 fidelity: 0.9726104209799861\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (63760, 63760) entries\n",
      "Student model 8-14 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9577199096692941\n",
      "Student model 8-14 fidelity: 0.9577199096692941\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (63910, 63910) entries\n",
      "Student model 8-15 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9642634102821456\n",
      "Student model 8-15 fidelity: 0.9642634102821456\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (64060, 64060) entries\n",
      "Student model 8-16 trained with depth 6 and 16 leaves:\n",
      "Student model score: 0.9284739814175108\n",
      "Student model 8-16 fidelity: 0.9284739814175108\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (64210, 64210) entries\n",
      "Student model 8-17 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9268730110876628\n",
      "Student model 8-17 fidelity: 0.9268730110876628\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (64360, 64360) entries\n",
      "Student model 8-18 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9719610105651251\n",
      "Student model 8-18 fidelity: 0.9719610105651251\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (64510, 64510) entries\n",
      "Student model 8-19 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9666646664666466\n",
      "Student model 8-19 fidelity: 0.9666646664666466\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (64660, 64660) entries\n",
      "Student model 8-20 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9457688588007738\n",
      "Student model 8-20 fidelity: 0.9457688588007738\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (64810, 64810) entries\n",
      "Student model 8-21 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9319799887164638\n",
      "Student model 8-21 fidelity: 0.9319799887164638\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (64960, 64960) entries\n",
      "Student model 8-22 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9541468124913847\n",
      "Student model 8-22 fidelity: 0.9541468124913847\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (65110, 65110) entries\n",
      "Student model 8-23 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9732236862598511\n",
      "Student model 8-23 fidelity: 0.9732236862598511\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (65260, 65260) entries\n",
      "Student model 8-24 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9405457151414026\n",
      "Student model 8-24 fidelity: 0.9405457151414026\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (65410, 65410) entries\n",
      "Student model 8-25 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9516307231662103\n",
      "Student model 8-25 fidelity: 0.9516307231662103\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (65560, 65560) entries\n",
      "Student model 8-26 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.986808064884858\n",
      "Student model 8-26 fidelity: 0.986808064884858\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (65710, 65710) entries\n",
      "Student model 8-27 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9521377647523434\n",
      "Student model 8-27 fidelity: 0.9521377647523434\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (65860, 65860) entries\n",
      "Student model 8-28 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9354497884101006\n",
      "Student model 8-28 fidelity: 0.9354497884101006\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (66010, 66010) entries\n",
      "Student model 8-29 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9406341755819033\n",
      "Student model 8-29 fidelity: 0.9406341755819033\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (66160, 66160) entries\n",
      "Student model 8-30 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.953410103721695\n",
      "Student model 8-30 fidelity: 0.953410103721695\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (66310, 66310) entries\n",
      "Student model 8-31 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9526505459534717\n",
      "Student model 8-31 fidelity: 0.9526505459534717\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (66460, 66460) entries\n",
      "Student model 8-32 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.953324381021098\n",
      "Student model 8-32 fidelity: 0.953324381021098\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (66610, 66610) entries\n",
      "Student model 8-33 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9800458861981974\n",
      "Student model 8-33 fidelity: 0.9800458861981974\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (66760, 66760) entries\n",
      "Student model 8-34 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9648351648351648\n",
      "Student model 8-34 fidelity: 0.9648351648351648\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (66910, 66910) entries\n",
      "Student model 8-35 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9535877565142613\n",
      "Student model 8-35 fidelity: 0.9535877565142613\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (67060, 67060) entries\n",
      "Student model 8-36 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9404266040537571\n",
      "Student model 8-36 fidelity: 0.9404266040537571\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (67210, 67210) entries\n",
      "Student model 8-37 trained with depth 8 and 16 leaves:\n",
      "Student model score: 0.8893939393939393\n",
      "Student model 8-37 fidelity: 0.8893939393939393\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (67360, 67360) entries\n",
      "Student model 8-38 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.952379695803555\n",
      "Student model 8-38 fidelity: 0.952379695803555\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (67510, 67510) entries\n",
      "Student model 8-39 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9602277990652238\n",
      "Student model 8-39 fidelity: 0.9602277990652238\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (67660, 67660) entries\n",
      "Student model 8-40 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9606119478587596\n",
      "Student model 8-40 fidelity: 0.9606119478587596\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (67810, 67810) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 8-41 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9534636652400841\n",
      "Student model 8-41 fidelity: 0.9534636652400841\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (67960, 67960) entries\n",
      "Student model 8-42 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.8903238360048652\n",
      "Student model 8-42 fidelity: 0.8903238360048652\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (68110, 68110) entries\n",
      "Student model 8-43 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9596003898635478\n",
      "Student model 8-43 fidelity: 0.9596003898635478\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (68260, 68260) entries\n",
      "Student model 8-44 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9658518660854849\n",
      "Student model 8-44 fidelity: 0.9658518660854849\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (68410, 68410) entries\n",
      "Student model 8-45 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9592878947054778\n",
      "Student model 8-45 fidelity: 0.9592878947054778\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (68560, 68560) entries\n",
      "Student model 8-46 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9667774645460249\n",
      "Student model 8-46 fidelity: 0.9667774645460249\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (68710, 68710) entries\n",
      "Student model 8-47 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9788248231019315\n",
      "Student model 8-47 fidelity: 0.9788248231019315\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (68860, 68860) entries\n",
      "Student model 8-48 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9666646664666466\n",
      "Student model 8-48 fidelity: 0.9666646664666466\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (69010, 69010) entries\n",
      "Student model 8-49 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9505171454538542\n",
      "Student model 8-49 fidelity: 0.9505171454538542\n",
      "########## Outer-loop Iteration 9/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (69160, 69160) entries\n",
      "Student model 9-0 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.960985827264897\n",
      "Student model 9-0 fidelity: 0.960985827264897\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (69310, 69310) entries\n",
      "Student model 9-1 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.961051817227026\n",
      "Student model 9-1 fidelity: 0.961051817227026\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (69460, 69460) entries\n",
      "Student model 9-2 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9429739664935063\n",
      "Student model 9-2 fidelity: 0.9429739664935063\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (69610, 69610) entries\n",
      "Student model 9-3 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.980774120362221\n",
      "Student model 9-3 fidelity: 0.980774120362221\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (69760, 69760) entries\n",
      "Student model 9-4 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9869678205144395\n",
      "Student model 9-4 fidelity: 0.9869678205144395\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (69910, 69910) entries\n",
      "Student model 9-5 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9356719998089212\n",
      "Student model 9-5 fidelity: 0.9356719998089212\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (70060, 70060) entries\n",
      "Student model 9-6 trained with depth 9 and 14 leaves:\n",
      "Student model score: 0.9604619565217392\n",
      "Student model 9-6 fidelity: 0.9604619565217392\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (70210, 70210) entries\n",
      "Student model 9-7 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9141774891774892\n",
      "Student model 9-7 fidelity: 0.9141774891774892\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (70360, 70360) entries\n",
      "Student model 9-8 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9665200391006842\n",
      "Student model 9-8 fidelity: 0.9665200391006842\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (70510, 70510) entries\n",
      "Student model 9-9 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9442200435272464\n",
      "Student model 9-9 fidelity: 0.9442200435272464\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (70660, 70660) entries\n",
      "Student model 9-10 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.9330280830280829\n",
      "Student model 9-10 fidelity: 0.9330280830280829\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (70810, 70810) entries\n",
      "Student model 9-11 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9402996333158722\n",
      "Student model 9-11 fidelity: 0.9402996333158722\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (70960, 70960) entries\n",
      "Student model 9-12 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9601123179486564\n",
      "Student model 9-12 fidelity: 0.9601123179486564\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (71110, 71110) entries\n",
      "Student model 9-13 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.9281838635771219\n",
      "Student model 9-13 fidelity: 0.9281838635771219\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (71260, 71260) entries\n",
      "Student model 9-14 trained with depth 7 and 17 leaves:\n",
      "Student model score: 0.9148105052072181\n",
      "Student model 9-14 fidelity: 0.9148105052072181\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (71410, 71410) entries\n",
      "Student model 9-15 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9801881693524171\n",
      "Student model 9-15 fidelity: 0.9801881693524171\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (71560, 71560) entries\n",
      "Student model 9-16 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9531623397602779\n",
      "Student model 9-16 fidelity: 0.9531623397602779\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (71710, 71710) entries\n",
      "Student model 9-17 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9518106538128785\n",
      "Student model 9-17 fidelity: 0.9518106538128785\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (71860, 71860) entries\n",
      "Student model 9-18 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9511589977435442\n",
      "Student model 9-18 fidelity: 0.9511589977435442\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (72010, 72010) entries\n",
      "Student model 9-19 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9602455692339814\n",
      "Student model 9-19 fidelity: 0.9602455692339814\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (72160, 72160) entries\n",
      "Student model 9-20 trained with depth 7 and 17 leaves:\n",
      "Student model score: 0.9069445705503937\n",
      "Student model 9-20 fidelity: 0.9069445705503937\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (72310, 72310) entries\n",
      "Student model 9-21 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9323169323169322\n",
      "Student model 9-21 fidelity: 0.9323169323169322\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (72460, 72460) entries\n",
      "Student model 9-22 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9592627341787475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 9-22 fidelity: 0.9592627341787475\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (72610, 72610) entries\n",
      "Student model 9-23 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9870440251572328\n",
      "Student model 9-23 fidelity: 0.9870440251572328\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (72760, 72760) entries\n",
      "Student model 9-24 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9723835860106771\n",
      "Student model 9-24 fidelity: 0.9723835860106771\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (72910, 72910) entries\n",
      "Student model 9-25 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9457389793524246\n",
      "Student model 9-25 fidelity: 0.9457389793524246\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (73060, 73060) entries\n",
      "Student model 9-26 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9727400095632665\n",
      "Student model 9-26 fidelity: 0.9727400095632665\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (73210, 73210) entries\n",
      "Student model 9-27 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.947260527246276\n",
      "Student model 9-27 fidelity: 0.947260527246276\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (73360, 73360) entries\n",
      "Student model 9-28 trained with depth 8 and 18 leaves:\n",
      "Student model score: 0.939397430411551\n",
      "Student model 9-28 fidelity: 0.939397430411551\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (73510, 73510) entries\n",
      "Student model 9-29 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9659617512249091\n",
      "Student model 9-29 fidelity: 0.9659617512249091\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (73660, 73660) entries\n",
      "Student model 9-30 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9185794111326026\n",
      "Student model 9-30 fidelity: 0.9185794111326026\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (73810, 73810) entries\n",
      "Student model 9-31 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9585948213277407\n",
      "Student model 9-31 fidelity: 0.9585948213277407\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (73960, 73960) entries\n",
      "Student model 9-32 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.9128398388704086\n",
      "Student model 9-32 fidelity: 0.9128398388704086\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (74110, 74110) entries\n",
      "Student model 9-33 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9399995318680804\n",
      "Student model 9-33 fidelity: 0.9399995318680804\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (74260, 74260) entries\n",
      "Student model 9-34 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9463310828955228\n",
      "Student model 9-34 fidelity: 0.9463310828955228\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (74410, 74410) entries\n",
      "Student model 9-35 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9443079828658841\n",
      "Student model 9-35 fidelity: 0.9443079828658841\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (74560, 74560) entries\n",
      "Student model 9-36 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9847016828148903\n",
      "Student model 9-36 fidelity: 0.9847016828148903\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (74710, 74710) entries\n",
      "Student model 9-37 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9312926245665075\n",
      "Student model 9-37 fidelity: 0.9312926245665075\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (74860, 74860) entries\n",
      "Student model 9-38 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9459481062896621\n",
      "Student model 9-38 fidelity: 0.9459481062896621\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (75010, 75010) entries\n",
      "Student model 9-39 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9610972558457608\n",
      "Student model 9-39 fidelity: 0.9610972558457608\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (75160, 75160) entries\n",
      "Student model 9-40 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9663641818677053\n",
      "Student model 9-40 fidelity: 0.9663641818677053\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (75310, 75310) entries\n",
      "Student model 9-41 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9254052684903749\n",
      "Student model 9-41 fidelity: 0.9254052684903749\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (75460, 75460) entries\n",
      "Student model 9-42 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9555143463805772\n",
      "Student model 9-42 fidelity: 0.9555143463805772\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (75610, 75610) entries\n",
      "Student model 9-43 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.925803765786913\n",
      "Student model 9-43 fidelity: 0.925803765786913\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (75760, 75760) entries\n",
      "Student model 9-44 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9669994965314735\n",
      "Student model 9-44 fidelity: 0.9669994965314735\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (75910, 75910) entries\n",
      "Student model 9-45 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9729914632800666\n",
      "Student model 9-45 fidelity: 0.9729914632800666\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (76060, 76060) entries\n",
      "Student model 9-46 trained with depth 6 and 17 leaves:\n",
      "Student model score: 0.9861298924940147\n",
      "Student model 9-46 fidelity: 0.9861298924940147\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (76210, 76210) entries\n",
      "Student model 9-47 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9421097770154375\n",
      "Student model 9-47 fidelity: 0.9421097770154375\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (76360, 76360) entries\n",
      "Student model 9-48 trained with depth 8 and 16 leaves:\n",
      "Student model score: 0.9284199134199134\n",
      "Student model 9-48 fidelity: 0.9284199134199134\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (76510, 76510) entries\n",
      "Student model 9-49 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.951730648335289\n",
      "Student model 9-49 fidelity: 0.951730648335289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model explanation global fidelity report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   GoogleDoc       0.98      0.97      0.97       349\n",
      " GoogleDrive       0.95      0.98      0.96       324\n",
      "     Youtube       0.96      0.95      0.96       344\n",
      "\n",
      "    accuracy                           0.96      1017\n",
      "   macro avg       0.96      0.96      0.96      1017\n",
      "weighted avg       0.96      0.96      0.96      1017\n",
      "\n",
      "Model explanation score report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   GoogleDoc       0.97      0.97      0.97       346\n",
      " GoogleDrive       0.95      0.97      0.96       325\n",
      "     Youtube       0.97      0.95      0.96       346\n",
      "\n",
      "    accuracy                           0.96      1017\n",
      "   macro avg       0.96      0.96      0.96      1017\n",
      "weighted avg       0.96      0.96      0.96      1017\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "#svm_classifier = joblib.load('quic_text_svm_pca.joblib')\n",
    "num_iter=50\n",
    "num_stability_iter=10\n",
    "\n",
    "trustee = ClassificationTrustee(expert=svm_pooling_classifier)\n",
    "trustee.fit(X_pool_train, y_pool_train, num_iter=num_iter, num_stability_iter=num_stability_iter, samples_size=0.3, verbose=True)\n",
    "dt, pruned_dt, agreement, reward = trustee.explain()\n",
    "dt_y_pred = dt.predict(X_pool_test)\n",
    "pruned_dt_y_pred = pruned_dt.predict(X_pool_test)\n",
    "\n",
    "all_trees = trustee.get_all_students()\n",
    "\n",
    "print(\"Model explanation global fidelity report:\")\n",
    "print(classification_report(y_pool_pred, dt_y_pred))\n",
    "print(\"Model explanation score report:\")\n",
    "print(classification_report(y_pool_test, dt_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "311b127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing training dataset using SVC(kernel='linear') as expert model\n",
      "Expert model score: 1.0\n",
      "Initializing Trustee outer-loop with 5 iterations\n",
      "########## Outer-loop Iteration 0/5 ##########\n",
      "Initializing Trustee inner-loop with 5 iterations\n",
      "########## Inner-loop Iteration 0/10 ##########\n",
      "Sampling 498 points from training dataset with (1660, 1660) entries\n",
      "Student model 0-0 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9125916591528793\n",
      "Student model 0-0 fidelity: 0.9125916591528793\n",
      "########## Inner-loop Iteration 1/10 ##########\n",
      "Sampling 498 points from training dataset with (1810, 1810) entries\n",
      "Student model 0-1 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9928015790084755\n",
      "Student model 0-1 fidelity: 0.9928015790084755\n",
      "########## Inner-loop Iteration 2/10 ##########\n",
      "Sampling 498 points from training dataset with (1960, 1960) entries\n",
      "Student model 0-2 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9505279989779546\n",
      "Student model 0-2 fidelity: 0.9505279989779546\n",
      "########## Inner-loop Iteration 3/10 ##########\n",
      "Sampling 498 points from training dataset with (2110, 2110) entries\n",
      "Student model 0-3 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9190271886629938\n",
      "Student model 0-3 fidelity: 0.9190271886629938\n",
      "########## Inner-loop Iteration 4/10 ##########\n",
      "Sampling 498 points from training dataset with (2260, 2260) entries\n",
      "Student model 0-4 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9804173125560904\n",
      "Student model 0-4 fidelity: 0.9804173125560904\n",
      "########## Inner-loop Iteration 5/10 ##########\n",
      "Sampling 498 points from training dataset with (2410, 2410) entries\n",
      "Student model 0-5 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9591440063917128\n",
      "Student model 0-5 fidelity: 0.9591440063917128\n",
      "########## Inner-loop Iteration 6/10 ##########\n",
      "Sampling 498 points from training dataset with (2560, 2560) entries\n",
      "Student model 0-6 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9852032520325203\n",
      "Student model 0-6 fidelity: 0.9852032520325203\n",
      "########## Inner-loop Iteration 7/10 ##########\n",
      "Sampling 498 points from training dataset with (2710, 2710) entries\n",
      "Student model 0-7 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9692677339144525\n",
      "Student model 0-7 fidelity: 0.9692677339144525\n",
      "########## Inner-loop Iteration 8/10 ##########\n",
      "Sampling 498 points from training dataset with (2860, 2860) entries\n",
      "Student model 0-8 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9245928334030586\n",
      "Student model 0-8 fidelity: 0.9245928334030586\n",
      "########## Inner-loop Iteration 9/10 ##########\n",
      "Sampling 498 points from training dataset with (3010, 3010) entries\n",
      "Student model 0-9 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9572315299285332\n",
      "Student model 0-9 fidelity: 0.9572315299285332\n",
      "########## Outer-loop Iteration 1/5 ##########\n",
      "Initializing Trustee inner-loop with 5 iterations\n",
      "########## Inner-loop Iteration 0/10 ##########\n",
      "Sampling 498 points from training dataset with (3160, 3160) entries\n",
      "Student model 1-0 trained with depth 6 and 16 leaves:\n",
      "Student model score: 0.9565278658493623\n",
      "Student model 1-0 fidelity: 0.9565278658493623\n",
      "########## Inner-loop Iteration 1/10 ##########\n",
      "Sampling 498 points from training dataset with (3310, 3310) entries\n",
      "Student model 1-1 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9718560074801309\n",
      "Student model 1-1 fidelity: 0.9718560074801309\n",
      "########## Inner-loop Iteration 2/10 ##########\n",
      "Sampling 498 points from training dataset with (3460, 3460) entries\n",
      "Student model 1-2 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9011102635816596\n",
      "Student model 1-2 fidelity: 0.9011102635816596\n",
      "########## Inner-loop Iteration 3/10 ##########\n",
      "Sampling 498 points from training dataset with (3610, 3610) entries\n",
      "Student model 1-3 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9671337954464138\n",
      "Student model 1-3 fidelity: 0.9671337954464138\n",
      "########## Inner-loop Iteration 4/10 ##########\n",
      "Sampling 498 points from training dataset with (3760, 3760) entries\n",
      "Student model 1-4 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9595063241563903\n",
      "Student model 1-4 fidelity: 0.9595063241563903\n",
      "########## Inner-loop Iteration 5/10 ##########\n",
      "Sampling 498 points from training dataset with (3910, 3910) entries\n",
      "Student model 1-5 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9492592003112456\n",
      "Student model 1-5 fidelity: 0.9492592003112456\n",
      "########## Inner-loop Iteration 6/10 ##########\n",
      "Sampling 498 points from training dataset with (4060, 4060) entries\n",
      "Student model 1-6 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9342091960902859\n",
      "Student model 1-6 fidelity: 0.9342091960902859\n",
      "########## Inner-loop Iteration 7/10 ##########\n",
      "Sampling 498 points from training dataset with (4210, 4210) entries\n",
      "Student model 1-7 trained with depth 6 and 8 leaves:\n",
      "Student model score: 0.9860219654828127\n",
      "Student model 1-7 fidelity: 0.9860219654828127\n",
      "########## Inner-loop Iteration 8/10 ##########\n",
      "Sampling 498 points from training dataset with (4360, 4360) entries\n",
      "Student model 1-8 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9598853689686323\n",
      "Student model 1-8 fidelity: 0.9598853689686323\n",
      "########## Inner-loop Iteration 9/10 ##########\n",
      "Sampling 498 points from training dataset with (4510, 4510) entries\n",
      "Student model 1-9 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9456593591998849\n",
      "Student model 1-9 fidelity: 0.9456593591998849\n",
      "########## Outer-loop Iteration 2/5 ##########\n",
      "Initializing Trustee inner-loop with 5 iterations\n",
      "########## Inner-loop Iteration 0/10 ##########\n",
      "Sampling 498 points from training dataset with (4660, 4660) entries\n",
      "Student model 2-0 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9933561309233023\n",
      "Student model 2-0 fidelity: 0.9933561309233023\n",
      "########## Inner-loop Iteration 1/10 ##########\n",
      "Sampling 498 points from training dataset with (4810, 4810) entries\n",
      "Student model 2-1 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9233697993646789\n",
      "Student model 2-1 fidelity: 0.9233697993646789\n",
      "########## Inner-loop Iteration 2/10 ##########\n",
      "Sampling 498 points from training dataset with (4960, 4960) entries\n",
      "Student model 2-2 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9475275117123642\n",
      "Student model 2-2 fidelity: 0.9475275117123642\n",
      "########## Inner-loop Iteration 3/10 ##########\n",
      "Sampling 498 points from training dataset with (5110, 5110) entries\n",
      "Student model 2-3 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9866081853750925\n",
      "Student model 2-3 fidelity: 0.9866081853750925\n",
      "########## Inner-loop Iteration 4/10 ##########\n",
      "Sampling 498 points from training dataset with (5260, 5260) entries\n",
      "Student model 2-4 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9186934801698635\n",
      "Student model 2-4 fidelity: 0.9186934801698635\n",
      "########## Inner-loop Iteration 5/10 ##########\n",
      "Sampling 498 points from training dataset with (5410, 5410) entries\n",
      "Student model 2-5 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9936966669639936\n",
      "Student model 2-5 fidelity: 0.9936966669639936\n",
      "########## Inner-loop Iteration 6/10 ##########\n",
      "Sampling 498 points from training dataset with (5560, 5560) entries\n",
      "Student model 2-6 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.928015254379348\n",
      "Student model 2-6 fidelity: 0.928015254379348\n",
      "########## Inner-loop Iteration 7/10 ##########\n",
      "Sampling 498 points from training dataset with (5710, 5710) entries\n",
      "Student model 2-7 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9853339709867687\n",
      "Student model 2-7 fidelity: 0.9853339709867687\n",
      "########## Inner-loop Iteration 8/10 ##########\n",
      "Sampling 498 points from training dataset with (5860, 5860) entries\n",
      "Student model 2-8 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.956959706959707\n",
      "Student model 2-8 fidelity: 0.956959706959707\n",
      "########## Inner-loop Iteration 9/10 ##########\n",
      "Sampling 498 points from training dataset with (6010, 6010) entries\n",
      "Student model 2-9 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9470217924346365\n",
      "Student model 2-9 fidelity: 0.9470217924346365\n",
      "########## Outer-loop Iteration 3/5 ##########\n",
      "Initializing Trustee inner-loop with 5 iterations\n",
      "########## Inner-loop Iteration 0/10 ##########\n",
      "Sampling 498 points from training dataset with (6160, 6160) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 3-0 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.964514338707887\n",
      "Student model 3-0 fidelity: 0.964514338707887\n",
      "########## Inner-loop Iteration 1/10 ##########\n",
      "Sampling 498 points from training dataset with (6310, 6310) entries\n",
      "Student model 3-1 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9593435475327002\n",
      "Student model 3-1 fidelity: 0.9593435475327002\n",
      "########## Inner-loop Iteration 2/10 ##########\n",
      "Sampling 498 points from training dataset with (6460, 6460) entries\n",
      "Student model 3-2 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9734609969249063\n",
      "Student model 3-2 fidelity: 0.9734609969249063\n",
      "########## Inner-loop Iteration 3/10 ##########\n",
      "Sampling 498 points from training dataset with (6610, 6610) entries\n",
      "Student model 3-3 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9503165286297817\n",
      "Student model 3-3 fidelity: 0.9503165286297817\n",
      "########## Inner-loop Iteration 4/10 ##########\n",
      "Sampling 498 points from training dataset with (6760, 6760) entries\n",
      "Student model 3-4 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9373234759436323\n",
      "Student model 3-4 fidelity: 0.9373234759436323\n",
      "########## Inner-loop Iteration 5/10 ##########\n",
      "Sampling 498 points from training dataset with (6910, 6910) entries\n",
      "Student model 3-5 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.93231500006137\n",
      "Student model 3-5 fidelity: 0.93231500006137\n",
      "########## Inner-loop Iteration 6/10 ##########\n",
      "Sampling 498 points from training dataset with (7060, 7060) entries\n",
      "Student model 3-6 trained with depth 4 and 8 leaves:\n",
      "Student model score: 0.9497877379821825\n",
      "Student model 3-6 fidelity: 0.9497877379821825\n",
      "########## Inner-loop Iteration 7/10 ##########\n",
      "Sampling 498 points from training dataset with (7210, 7210) entries\n",
      "Student model 3-7 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9392684610075914\n",
      "Student model 3-7 fidelity: 0.9392684610075914\n",
      "########## Inner-loop Iteration 8/10 ##########\n",
      "Sampling 498 points from training dataset with (7360, 7360) entries\n",
      "Student model 3-8 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9788740920096851\n",
      "Student model 3-8 fidelity: 0.9788740920096851\n",
      "########## Inner-loop Iteration 9/10 ##########\n",
      "Sampling 498 points from training dataset with (7510, 7510) entries\n",
      "Student model 3-9 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9728596279941121\n",
      "Student model 3-9 fidelity: 0.9728596279941121\n",
      "########## Outer-loop Iteration 4/5 ##########\n",
      "Initializing Trustee inner-loop with 5 iterations\n",
      "########## Inner-loop Iteration 0/10 ##########\n",
      "Sampling 498 points from training dataset with (7660, 7660) entries\n",
      "Student model 4-0 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9521929824561403\n",
      "Student model 4-0 fidelity: 0.9521929824561403\n",
      "########## Inner-loop Iteration 1/10 ##########\n",
      "Sampling 498 points from training dataset with (7810, 7810) entries\n",
      "Student model 4-1 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9537448957661724\n",
      "Student model 4-1 fidelity: 0.9537448957661724\n",
      "########## Inner-loop Iteration 2/10 ##########\n",
      "Sampling 498 points from training dataset with (7960, 7960) entries\n",
      "Student model 4-2 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9535129381812736\n",
      "Student model 4-2 fidelity: 0.9535129381812736\n",
      "########## Inner-loop Iteration 3/10 ##########\n",
      "Sampling 498 points from training dataset with (8110, 8110) entries\n",
      "Student model 4-3 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9572611322443499\n",
      "Student model 4-3 fidelity: 0.9572611322443499\n",
      "########## Inner-loop Iteration 4/10 ##########\n",
      "Sampling 498 points from training dataset with (8260, 8260) entries\n",
      "Student model 4-4 trained with depth 8 and 16 leaves:\n",
      "Student model score: 0.9728464719877201\n",
      "Student model 4-4 fidelity: 0.9728464719877201\n",
      "########## Inner-loop Iteration 5/10 ##########\n",
      "Sampling 498 points from training dataset with (8410, 8410) entries\n",
      "Student model 4-5 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.8894335511982572\n",
      "Student model 4-5 fidelity: 0.8894335511982572\n",
      "########## Inner-loop Iteration 6/10 ##########\n",
      "Sampling 498 points from training dataset with (8560, 8560) entries\n",
      "Student model 4-6 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9413798111837327\n",
      "Student model 4-6 fidelity: 0.9413798111837327\n",
      "########## Inner-loop Iteration 7/10 ##########\n",
      "Sampling 498 points from training dataset with (8710, 8710) entries\n",
      "Student model 4-7 trained with depth 6 and 8 leaves:\n",
      "Student model score: 0.9581941306149683\n",
      "Student model 4-7 fidelity: 0.9581941306149683\n",
      "########## Inner-loop Iteration 8/10 ##########\n",
      "Sampling 498 points from training dataset with (8860, 8860) entries\n",
      "Student model 4-8 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9488567544184897\n",
      "Student model 4-8 fidelity: 0.9488567544184897\n",
      "########## Inner-loop Iteration 9/10 ##########\n",
      "Sampling 498 points from training dataset with (9010, 9010) entries\n",
      "Student model 4-9 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9317719298245614\n",
      "Student model 4-9 fidelity: 0.9317719298245614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model explanation global fidelity report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   GoogleDoc       0.95      0.96      0.95       349\n",
      " GoogleDrive       0.96      0.99      0.97       324\n",
      "     Youtube       0.96      0.91      0.93       344\n",
      "\n",
      "    accuracy                           0.95      1017\n",
      "   macro avg       0.95      0.95      0.95      1017\n",
      "weighted avg       0.95      0.95      0.95      1017\n",
      "\n",
      "Model explanation score report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   GoogleDoc       0.94      0.97      0.96       346\n",
      " GoogleDrive       0.96      0.98      0.97       325\n",
      "     Youtube       0.96      0.91      0.93       346\n",
      "\n",
      "    accuracy                           0.95      1017\n",
      "   macro avg       0.95      0.95      0.95      1017\n",
      "weighted avg       0.95      0.95      0.95      1017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "#svm_classifier = joblib.load('quic_text_svm_pca.joblib')\n",
    "\n",
    "trustee = ClassificationTrustee(expert=svm_pooling_classifier)\n",
    "trustee.fit(X_pool_train, y_pool_train, num_iter=10, num_stability_iter=5, samples_size=0.3, verbose=True)\n",
    "dt, pruned_dt, agreement, reward = trustee.explain()\n",
    "dt_y_pred = dt.predict(X_pool_test)\n",
    "pruned_dt_y_pred = pruned_dt.predict(X_pool_test)\n",
    "\n",
    "print(\"Model explanation global fidelity report:\")\n",
    "print(classification_report(y_pool_pred, dt_y_pred))\n",
    "print(\"Model explanation score report:\")\n",
    "print(classification_report(y_pool_test, dt_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7150b589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flowpic_x,y_svm_pruned_pool.pdf'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output decision tree to pdf\n",
    "features = ['feature_{}'.format(MyFeature(i)) for i in range(1, 10001)]\n",
    "classes = ['GoogleDoc', 'GoogleDrive', 'Youtube']\n",
    "\n",
    "dot_data = tree.export_graphviz(\n",
    "    dt,\n",
    "    class_names=classes,\n",
    "    feature_names= features,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True,\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"flowpic_x,y_svm_pool\")\n",
    "\n",
    "# Output pruned decision tree to pdf\n",
    "dot_data = tree.export_graphviz(\n",
    "    pruned_dt,\n",
    "    class_names=classes,\n",
    "    feature_names=features,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True,\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"flowpic_x,y_svm_pruned_pool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14e267f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "all tree:\n",
      "feat_name: (1485-1500,1425-1440), count_total: 201, num_trees: 196, samples: 42469\n",
      "feat_name: (1425-1440,1425-1440), count_total: 18, num_trees: 18, samples: 2732\n",
      "feat_name: (0-15,330-345), count_total: 284, num_trees: 283, samples: 38384\n",
      "feat_name: (1485-1500,1395-1410), count_total: 264, num_trees: 263, samples: 35518\n",
      "feat_name: (1470-1485,1290-1305), count_total: 28, num_trees: 28, samples: 3423\n",
      "feat_name: (75-90,360-375), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1335-1350,1410-1425), count_total: 44, num_trees: 43, samples: 10591\n",
      "feat_name: (1485-1500,90-105), count_total: 25, num_trees: 25, samples: 2011\n",
      "feat_name: (1470-1485,510-525), count_total: 4, num_trees: 4, samples: 360\n",
      "feat_name: (90-105,120-135), count_total: 17, num_trees: 17, samples: 1438\n",
      "feat_name: (1410-1425,1425-1440), count_total: 22, num_trees: 22, samples: 3309\n",
      "feat_name: (1485-1500,1305-1320), count_total: 31, num_trees: 31, samples: 3522\n",
      "feat_name: (315-330,315-330), count_total: 3, num_trees: 3, samples: 27\n",
      "feat_name: (1245-1260,1380-1395), count_total: 5, num_trees: 5, samples: 149\n",
      "feat_name: (1440-1455,90-105), count_total: 14, num_trees: 14, samples: 1693\n",
      "feat_name: (360-375,75-90), count_total: 2, num_trees: 2, samples: 172\n",
      "feat_name: (180-195,105-120), count_total: 2, num_trees: 2, samples: 103\n",
      "feat_name: (0-15,75-90), count_total: 95, num_trees: 79, samples: 19964\n",
      "feat_name: (1485-1500,150-165), count_total: 26, num_trees: 24, samples: 3811\n",
      "feat_name: (0-15,60-75), count_total: 36, num_trees: 30, samples: 3099\n",
      "feat_name: (75-90,120-135), count_total: 7, num_trees: 7, samples: 629\n",
      "feat_name: (1485-1500,1275-1290), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1065-1080,1425-1440), count_total: 7, num_trees: 7, samples: 837\n",
      "feat_name: (1485-1500,75-90), count_total: 18, num_trees: 16, samples: 1258\n",
      "feat_name: (1350-1365,1410-1425), count_total: 16, num_trees: 16, samples: 3508\n",
      "feat_name: (270-285,120-135), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1470-1485,60-75), count_total: 8, num_trees: 8, samples: 738\n",
      "feat_name: (30-45,420-435), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1125-1140,60-75), count_total: 22, num_trees: 22, samples: 1716\n",
      "feat_name: (1485-1500,135-150), count_total: 357, num_trees: 348, samples: 115728\n",
      "feat_name: (1125-1140,1410-1425), count_total: 6, num_trees: 6, samples: 699\n",
      "feat_name: (1140-1155,1425-1440), count_total: 14, num_trees: 14, samples: 1851\n",
      "feat_name: (1425-1440,1410-1425), count_total: 91, num_trees: 90, samples: 23610\n",
      "feat_name: (1485-1500,105-120), count_total: 27, num_trees: 27, samples: 2194\n",
      "feat_name: (585-600,480-495), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (1410-1425,105-120), count_total: 5, num_trees: 5, samples: 430\n",
      "feat_name: (1320-1335,75-90), count_total: 3, num_trees: 3, samples: 118\n",
      "feat_name: (105-120,60-75), count_total: 46, num_trees: 46, samples: 3967\n",
      "feat_name: (1335-1350,135-150), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1440-1455,1410-1425), count_total: 80, num_trees: 80, samples: 20227\n",
      "feat_name: (1335-1350,1425-1440), count_total: 22, num_trees: 22, samples: 3409\n",
      "feat_name: (1470-1485,1380-1395), count_total: 35, num_trees: 35, samples: 4436\n",
      "feat_name: (1485-1500,930-945), count_total: 3, num_trees: 3, samples: 20\n",
      "feat_name: (1350-1365,90-105), count_total: 15, num_trees: 15, samples: 1152\n",
      "feat_name: (1185-1200,120-135), count_total: 3, num_trees: 3, samples: 99\n",
      "feat_name: (1380-1395,1425-1440), count_total: 25, num_trees: 25, samples: 3725\n",
      "feat_name: (360-375,930-945), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1485-1500,855-870), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1380-1395,60-75), count_total: 3, num_trees: 3, samples: 144\n",
      "feat_name: (1260-1275,90-105), count_total: 9, num_trees: 9, samples: 707\n",
      "feat_name: (1395-1410,900-915), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1410-1425,1410-1425), count_total: 35, num_trees: 35, samples: 7556\n",
      "feat_name: (1230-1245,1425-1440), count_total: 6, num_trees: 6, samples: 566\n",
      "feat_name: (90-105,1095-1110), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (210-225,1290-1305), count_total: 7, num_trees: 7, samples: 883\n",
      "feat_name: (0-15,1410-1425), count_total: 224, num_trees: 200, samples: 29533\n",
      "feat_name: (1485-1500,1335-1350), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (120-135,1410-1425), count_total: 5, num_trees: 5, samples: 472\n",
      "feat_name: (1320-1335,1425-1440), count_total: 20, num_trees: 20, samples: 3214\n",
      "feat_name: (75-90,1410-1425), count_total: 9, num_trees: 9, samples: 881\n",
      "feat_name: (15-30,225-240), count_total: 3, num_trees: 3, samples: 370\n",
      "feat_name: (675-690,1410-1425), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1200-1215,1380-1395), count_total: 4, num_trees: 4, samples: 132\n",
      "feat_name: (45-60,810-825), count_total: 3, num_trees: 3, samples: 40\n",
      "feat_name: (750-765,105-120), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (1470-1485,1410-1425), count_total: 41, num_trees: 41, samples: 8476\n",
      "feat_name: (1110-1125,60-75), count_total: 21, num_trees: 21, samples: 2557\n",
      "feat_name: (1050-1065,60-75), count_total: 2, num_trees: 2, samples: 63\n",
      "feat_name: (840-855,195-210), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1170-1185,90-105), count_total: 5, num_trees: 5, samples: 442\n",
      "feat_name: (720-735,735-750), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (390-405,750-765), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (45-60,630-645), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (975-990,1410-1425), count_total: 4, num_trees: 4, samples: 144\n",
      "feat_name: (1485-1500,1440-1455), count_total: 13, num_trees: 13, samples: 2016\n",
      "feat_name: (0-15,1380-1395), count_total: 20, num_trees: 20, samples: 2466\n",
      "feat_name: (195-210,1290-1305), count_total: 3, num_trees: 3, samples: 364\n",
      "feat_name: (1305-1320,75-90), count_total: 6, num_trees: 6, samples: 55\n",
      "feat_name: (90-105,105-120), count_total: 3, num_trees: 3, samples: 110\n",
      "feat_name: (1395-1410,105-120), count_total: 18, num_trees: 17, samples: 1670\n",
      "feat_name: (1395-1410,1410-1425), count_total: 20, num_trees: 20, samples: 4071\n",
      "feat_name: (870-885,60-75), count_total: 7, num_trees: 7, samples: 964\n",
      "feat_name: (15-30,720-735), count_total: 2, num_trees: 2, samples: 8\n",
      "feat_name: (600-615,105-120), count_total: 3, num_trees: 3, samples: 203\n",
      "feat_name: (1200-1215,240-255), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1230-1245,1410-1425), count_total: 3, num_trees: 3, samples: 210\n",
      "feat_name: (1065-1080,60-75), count_total: 19, num_trees: 19, samples: 2858\n",
      "feat_name: (555-570,60-75), count_total: 3, num_trees: 3, samples: 358\n",
      "feat_name: (990-1005,1380-1395), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1290-1305,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (120-135,60-75), count_total: 8, num_trees: 8, samples: 188\n",
      "feat_name: (1200-1215,60-75), count_total: 4, num_trees: 4, samples: 155\n",
      "feat_name: (1290-1305,60-75), count_total: 5, num_trees: 5, samples: 285\n",
      "feat_name: (180-195,1410-1425), count_total: 6, num_trees: 6, samples: 514\n",
      "feat_name: (255-270,1410-1425), count_total: 2, num_trees: 2, samples: 138\n",
      "feat_name: (1365-1380,1425-1440), count_total: 20, num_trees: 20, samples: 3080\n",
      "feat_name: (135-150,1290-1305), count_total: 5, num_trees: 5, samples: 612\n",
      "feat_name: (1140-1155,765-780), count_total: 1, num_trees: 1, samples: 145\n",
      "feat_name: (45-60,60-75), count_total: 4, num_trees: 4, samples: 219\n",
      "feat_name: (1200-1215,135-150), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1275-1290,1350-1365), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (105-120,750-765), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (1365-1380,90-105), count_total: 20, num_trees: 20, samples: 2211\n",
      "feat_name: (1275-1290,60-75), count_total: 12, num_trees: 12, samples: 552\n",
      "feat_name: (1200-1215,1410-1425), count_total: 4, num_trees: 4, samples: 297\n",
      "feat_name: (285-300,90-105), count_total: 3, num_trees: 3, samples: 376\n",
      "feat_name: (1215-1230,195-210), count_total: 2, num_trees: 2, samples: 98\n",
      "feat_name: (195-210,165-180), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1410-1425,1380-1395), count_total: 6, num_trees: 6, samples: 388\n",
      "feat_name: (60-75,675-690), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1110-1125,1410-1425), count_total: 4, num_trees: 4, samples: 484\n",
      "feat_name: (1245-1260,60-75), count_total: 6, num_trees: 6, samples: 528\n",
      "feat_name: (1170-1185,1425-1440), count_total: 9, num_trees: 9, samples: 1416\n",
      "feat_name: (75-90,1170-1185), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1470-1485,135-150), count_total: 5, num_trees: 5, samples: 385\n",
      "feat_name: (1110-1125,90-105), count_total: 6, num_trees: 6, samples: 442\n",
      "feat_name: (0-15,90-105), count_total: 103, num_trees: 100, samples: 19523\n",
      "feat_name: (1155-1170,1425-1440), count_total: 13, num_trees: 13, samples: 1799\n",
      "feat_name: (990-1005,1410-1425), count_total: 2, num_trees: 2, samples: 239\n",
      "feat_name: (1335-1350,75-90), count_total: 5, num_trees: 5, samples: 39\n",
      "feat_name: (1485-1500,285-300), count_total: 21, num_trees: 21, samples: 1910\n",
      "feat_name: (615-630,75-90), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (1275-1290,75-90), count_total: 7, num_trees: 7, samples: 234\n",
      "feat_name: (180-195,120-135), count_total: 4, num_trees: 4, samples: 430\n",
      "feat_name: (15-30,1380-1395), count_total: 4, num_trees: 4, samples: 465\n",
      "feat_name: (360-375,1290-1305), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1095-1110,1425-1440), count_total: 6, num_trees: 6, samples: 437\n",
      "feat_name: (1485-1500,1080-1095), count_total: 6, num_trees: 6, samples: 645\n",
      "feat_name: (1470-1485,1350-1365), count_total: 8, num_trees: 8, samples: 633\n",
      "feat_name: (690-705,90-105), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1155-1170,60-75), count_total: 6, num_trees: 6, samples: 235\n",
      "feat_name: (1290-1305,1410-1425), count_total: 4, num_trees: 4, samples: 1212\n",
      "feat_name: (1185-1200,60-75), count_total: 7, num_trees: 7, samples: 640\n",
      "feat_name: (90-105,1410-1425), count_total: 10, num_trees: 10, samples: 801\n",
      "feat_name: (1485-1500,450-465), count_total: 2, num_trees: 2, samples: 257\n",
      "feat_name: (1275-1290,1380-1395), count_total: 7, num_trees: 7, samples: 482\n",
      "feat_name: (1440-1455,210-225), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (105-120,210-225), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (1305-1320,1425-1440), count_total: 13, num_trees: 13, samples: 1986\n",
      "feat_name: (1485-1500,165-180), count_total: 19, num_trees: 19, samples: 2167\n",
      "feat_name: (225-240,525-540), count_total: 5, num_trees: 5, samples: 653\n",
      "feat_name: (495-510,930-945), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1455-1470,90-105), count_total: 11, num_trees: 11, samples: 713\n",
      "feat_name: (1065-1080,375-390), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (240-255,105-120), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (615-630,105-120), count_total: 2, num_trees: 2, samples: 190\n",
      "feat_name: (270-285,1410-1425), count_total: 4, num_trees: 4, samples: 241\n",
      "feat_name: (1470-1485,120-135), count_total: 2, num_trees: 2, samples: 24\n",
      "feat_name: (1425-1440,480-495), count_total: 3, num_trees: 3, samples: 215\n",
      "feat_name: (135-150,60-75), count_total: 7, num_trees: 7, samples: 434\n",
      "feat_name: (1185-1200,1425-1440), count_total: 6, num_trees: 6, samples: 931\n",
      "feat_name: (1455-1470,1290-1305), count_total: 7, num_trees: 7, samples: 729\n",
      "feat_name: (15-30,285-300), count_total: 1, num_trees: 1, samples: 138\n",
      "feat_name: (1185-1200,90-105), count_total: 3, num_trees: 3, samples: 20\n",
      "feat_name: (1005-1020,825-840), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (1005-1020,1425-1440), count_total: 2, num_trees: 2, samples: 170\n",
      "feat_name: (1350-1365,60-75), count_total: 4, num_trees: 4, samples: 246\n",
      "feat_name: (975-990,1110-1125), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1170-1185,60-75), count_total: 24, num_trees: 24, samples: 3494\n",
      "feat_name: (450-465,120-135), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (645-660,1290-1305), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1215-1230,270-285), count_total: 4, num_trees: 4, samples: 150\n",
      "feat_name: (1485-1500,1380-1395), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1080-1095,60-75), count_total: 31, num_trees: 31, samples: 4638\n",
      "feat_name: (1140-1155,75-90), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1020-1035,60-75), count_total: 11, num_trees: 11, samples: 1094\n",
      "feat_name: (960-975,1425-1440), count_total: 3, num_trees: 3, samples: 55\n",
      "feat_name: (960-975,285-300), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1290-1305,1425-1440), count_total: 9, num_trees: 9, samples: 1387\n",
      "feat_name: (1200-1215,90-105), count_total: 5, num_trees: 5, samples: 156\n",
      "feat_name: (915-930,300-315), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (1410-1425,60-75), count_total: 9, num_trees: 9, samples: 478\n",
      "feat_name: (225-240,1050-1065), count_total: 5, num_trees: 5, samples: 616\n",
      "feat_name: (495-510,90-105), count_total: 3, num_trees: 3, samples: 268\n",
      "feat_name: (90-105,60-75), count_total: 35, num_trees: 35, samples: 2364\n",
      "feat_name: (1095-1110,345-360), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (1035-1050,480-495), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (240-255,1410-1425), count_total: 3, num_trees: 3, samples: 189\n",
      "feat_name: (1305-1320,60-75), count_total: 3, num_trees: 3, samples: 259\n",
      "feat_name: (1395-1410,390-405), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1455-1470,1065-1080), count_total: 3, num_trees: 3, samples: 372\n",
      "feat_name: (1095-1110,90-105), count_total: 5, num_trees: 5, samples: 212\n",
      "feat_name: (45-60,135-150), count_total: 5, num_trees: 5, samples: 299\n",
      "feat_name: (1485-1500,915-930), count_total: 10, num_trees: 10, samples: 1004\n",
      "feat_name: (165-180,1290-1305), count_total: 6, num_trees: 6, samples: 673\n",
      "feat_name: (150-165,60-75), count_total: 4, num_trees: 4, samples: 202\n",
      "feat_name: (45-60,1290-1305), count_total: 1, num_trees: 1, samples: 31\n",
      "feat_name: (195-210,1380-1395), count_total: 2, num_trees: 2, samples: 126\n",
      "feat_name: (540-555,120-135), count_total: 1, num_trees: 1, samples: 74\n",
      "feat_name: (315-330,1365-1380), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (960-975,135-150), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (0-15,1290-1305), count_total: 15, num_trees: 15, samples: 1574\n",
      "feat_name: (225-240,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (840-855,75-90), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1080-1095,1335-1350), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (1440-1455,375-390), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1455-1470,435-450), count_total: 2, num_trees: 2, samples: 202\n",
      "feat_name: (315-330,690-705), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1320-1335,60-75), count_total: 4, num_trees: 4, samples: 330\n",
      "feat_name: (315-330,1290-1305), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (240-255,1380-1395), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1305-1320,90-105), count_total: 30, num_trees: 30, samples: 3611\n",
      "feat_name: (840-855,1425-1440), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (0-15,960-975), count_total: 3, num_trees: 3, samples: 369\n",
      "feat_name: (1215-1230,1380-1395), count_total: 3, num_trees: 3, samples: 31\n",
      "feat_name: (975-990,105-120), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (30-45,285-300), count_total: 2, num_trees: 2, samples: 242\n",
      "feat_name: (90-105,75-90), count_total: 2, num_trees: 2, samples: 133\n",
      "feat_name: (180-195,60-75), count_total: 3, num_trees: 3, samples: 169\n",
      "feat_name: (1470-1485,465-480), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (765-780,1290-1305), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1395-1410,1380-1395), count_total: 9, num_trees: 9, samples: 735\n",
      "feat_name: (105-120,135-150), count_total: 5, num_trees: 5, samples: 105\n",
      "feat_name: (1140-1155,1380-1395), count_total: 6, num_trees: 6, samples: 491\n",
      "feat_name: (1425-1440,1305-1320), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (1485-1500,435-450), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (1425-1440,90-105), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (945-960,495-510), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (1485-1500,120-135), count_total: 4, num_trees: 4, samples: 117\n",
      "feat_name: (1440-1455,135-150), count_total: 2, num_trees: 2, samples: 199\n",
      "feat_name: (1095-1110,60-75), count_total: 4, num_trees: 4, samples: 440\n",
      "feat_name: (990-1005,1425-1440), count_total: 2, num_trees: 2, samples: 322\n",
      "feat_name: (0-15,585-600), count_total: 17, num_trees: 17, samples: 2151\n",
      "feat_name: (90-105,930-945), count_total: 7, num_trees: 7, samples: 618\n",
      "feat_name: (1020-1035,75-90), count_total: 5, num_trees: 5, samples: 50\n",
      "feat_name: (1305-1320,1380-1395), count_total: 5, num_trees: 5, samples: 33\n",
      "feat_name: (1305-1320,990-1005), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1305-1320,1410-1425), count_total: 3, num_trees: 3, samples: 363\n",
      "feat_name: (270-285,1290-1305), count_total: 2, num_trees: 2, samples: 251\n",
      "feat_name: (855-870,105-120), count_total: 4, num_trees: 4, samples: 310\n",
      "feat_name: (360-375,1410-1425), count_total: 3, num_trees: 3, samples: 10\n",
      "feat_name: (1260-1275,1410-1425), count_total: 4, num_trees: 4, samples: 105\n",
      "feat_name: (1440-1455,1425-1440), count_total: 15, num_trees: 15, samples: 2158\n",
      "feat_name: (105-120,1410-1425), count_total: 11, num_trees: 11, samples: 976\n",
      "feat_name: (375-390,120-135), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (15-30,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1125-1140,1380-1395), count_total: 6, num_trees: 6, samples: 290\n",
      "feat_name: (1365-1380,795-810), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (480-495,90-105), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (780-795,1110-1125), count_total: 2, num_trees: 2, samples: 260\n",
      "feat_name: (60-75,1290-1305), count_total: 4, num_trees: 4, samples: 510\n",
      "feat_name: (960-975,975-990), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (840-855,510-525), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (795-810,270-285), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (675-690,90-105), count_total: 6, num_trees: 6, samples: 573\n",
      "feat_name: (1035-1050,150-165), count_total: 5, num_trees: 5, samples: 553\n",
      "feat_name: (450-465,1110-1125), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1275-1290,480-495), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1395-1410,1425-1440), count_total: 27, num_trees: 26, samples: 3787\n",
      "feat_name: (930-945,1410-1425), count_total: 3, num_trees: 3, samples: 116\n",
      "feat_name: (1425-1440,135-150), count_total: 7, num_trees: 7, samples: 688\n",
      "feat_name: (1065-1080,1410-1425), count_total: 4, num_trees: 4, samples: 400\n",
      "feat_name: (810-825,1410-1425), count_total: 2, num_trees: 2, samples: 127\n",
      "feat_name: (105-120,945-960), count_total: 4, num_trees: 4, samples: 392\n",
      "feat_name: (45-60,720-735), count_total: 2, num_trees: 2, samples: 201\n",
      "feat_name: (90-105,1140-1155), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (420-435,360-375), count_total: 1, num_trees: 1, samples: 130\n",
      "feat_name: (1335-1350,315-330), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (585-600,75-90), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1335-1350,60-75), count_total: 7, num_trees: 7, samples: 244\n",
      "feat_name: (1365-1380,480-495), count_total: 2, num_trees: 2, samples: 98\n",
      "feat_name: (1470-1485,1425-1440), count_total: 14, num_trees: 14, samples: 1799\n",
      "feat_name: (0-15,660-675), count_total: 2, num_trees: 2, samples: 132\n",
      "feat_name: (345-360,165-180), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1365-1380,120-135), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1245-1260,465-480), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1365-1380,1410-1425), count_total: 17, num_trees: 17, samples: 3562\n",
      "feat_name: (570-585,90-105), count_total: 3, num_trees: 3, samples: 264\n",
      "feat_name: (990-1005,135-150), count_total: 2, num_trees: 2, samples: 208\n",
      "feat_name: (150-165,105-120), count_total: 4, num_trees: 4, samples: 299\n",
      "feat_name: (1200-1215,75-90), count_total: 4, num_trees: 4, samples: 27\n",
      "feat_name: (1470-1485,615-630), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (660-675,1410-1425), count_total: 2, num_trees: 2, samples: 137\n",
      "feat_name: (225-240,75-90), count_total: 2, num_trees: 2, samples: 11\n",
      "feat_name: (735-750,135-150), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1335-1350,1320-1335), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1455-1470,1410-1425), count_total: 53, num_trees: 52, samples: 12021\n",
      "feat_name: (1455-1470,1425-1440), count_total: 18, num_trees: 18, samples: 2711\n",
      "feat_name: (1470-1485,75-90), count_total: 1, num_trees: 1, samples: 14\n",
      "feat_name: (1425-1440,120-135), count_total: 10, num_trees: 10, samples: 788\n",
      "feat_name: (1470-1485,525-540), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (1005-1020,1410-1425), count_total: 3, num_trees: 3, samples: 330\n",
      "feat_name: (420-435,75-90), count_total: 4, num_trees: 4, samples: 392\n",
      "feat_name: (45-60,120-135), count_total: 8, num_trees: 8, samples: 682\n",
      "feat_name: (435-450,1140-1155), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1365-1380,135-150), count_total: 14, num_trees: 14, samples: 1463\n",
      "feat_name: (1485-1500,945-960), count_total: 8, num_trees: 8, samples: 2100\n",
      "feat_name: (975-990,225-240), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (600-615,330-345), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (315-330,1380-1395), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (165-180,1410-1425), count_total: 4, num_trees: 4, samples: 396\n",
      "feat_name: (1485-1500,225-240), count_total: 3, num_trees: 3, samples: 338\n",
      "feat_name: (195-210,915-930), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (1470-1485,960-975), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (510-525,945-960), count_total: 3, num_trees: 3, samples: 363\n",
      "feat_name: (15-30,1185-1200), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1440-1455,120-135), count_total: 7, num_trees: 7, samples: 411\n",
      "feat_name: (1200-1215,105-120), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1395-1410,930-945), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (165-180,930-945), count_total: 3, num_trees: 3, samples: 110\n",
      "feat_name: (45-60,1185-1200), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (885-900,1380-1395), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (930-945,135-150), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1470-1485,1320-1335), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (645-660,945-960), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (0-15,315-330), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1455-1470,60-75), count_total: 14, num_trees: 14, samples: 1538\n",
      "feat_name: (630-645,60-75), count_total: 4, num_trees: 4, samples: 298\n",
      "feat_name: (765-780,465-480), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1155-1170,1410-1425), count_total: 2, num_trees: 2, samples: 571\n",
      "feat_name: (510-525,90-105), count_total: 3, num_trees: 3, samples: 122\n",
      "feat_name: (0-15,150-165), count_total: 4, num_trees: 4, samples: 16\n",
      "feat_name: (885-900,645-660), count_total: 1, num_trees: 1, samples: 77\n",
      "feat_name: (270-285,540-555), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1410-1425,120-135), count_total: 10, num_trees: 10, samples: 1026\n",
      "feat_name: (1035-1050,60-75), count_total: 7, num_trees: 7, samples: 974\n",
      "feat_name: (1110-1125,105-120), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (675-690,165-180), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1155-1170,540-555), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1455-1470,360-375), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (255-270,45-60), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (150-165,690-705), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1335-1350,90-105), count_total: 13, num_trees: 13, samples: 1244\n",
      "feat_name: (1485-1500,405-420), count_total: 4, num_trees: 4, samples: 332\n",
      "feat_name: (1125-1140,135-150), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (255-270,510-525), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (840-855,60-75), count_total: 9, num_trees: 9, samples: 1070\n",
      "feat_name: (525-540,1410-1425), count_total: 2, num_trees: 2, samples: 125\n",
      "feat_name: (1395-1410,1305-1320), count_total: 4, num_trees: 4, samples: 471\n",
      "feat_name: (60-75,900-915), count_total: 4, num_trees: 4, samples: 248\n",
      "feat_name: (0-15,270-285), count_total: 3, num_trees: 3, samples: 217\n",
      "feat_name: (1230-1245,90-105), count_total: 4, num_trees: 4, samples: 211\n",
      "feat_name: (1095-1110,240-255), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (675-690,135-150), count_total: 2, num_trees: 2, samples: 193\n",
      "feat_name: (1485-1500,1320-1335), count_total: 3, num_trees: 3, samples: 248\n",
      "feat_name: (435-450,90-105), count_total: 5, num_trees: 5, samples: 432\n",
      "feat_name: (195-210,90-105), count_total: 2, num_trees: 2, samples: 10\n",
      "feat_name: (195-210,105-120), count_total: 5, num_trees: 5, samples: 125\n",
      "feat_name: (90-105,1290-1305), count_total: 10, num_trees: 10, samples: 1306\n",
      "feat_name: (1200-1215,120-135), count_total: 2, num_trees: 2, samples: 189\n",
      "feat_name: (1320-1335,225-240), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1110-1125,1380-1395), count_total: 11, num_trees: 11, samples: 1150\n",
      "feat_name: (0-15,105-120), count_total: 5, num_trees: 3, samples: 261\n",
      "feat_name: (90-105,1380-1395), count_total: 3, num_trees: 3, samples: 202\n",
      "feat_name: (690-705,105-120), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (1395-1410,135-150), count_total: 13, num_trees: 13, samples: 1313\n",
      "feat_name: (300-315,1485-1500), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (60-75,120-135), count_total: 4, num_trees: 4, samples: 354\n",
      "feat_name: (1455-1470,480-495), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (105-120,120-135), count_total: 11, num_trees: 11, samples: 971\n",
      "feat_name: (90-105,135-150), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (345-360,60-75), count_total: 3, num_trees: 3, samples: 202\n",
      "feat_name: (1410-1425,885-900), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1110-1125,1425-1440), count_total: 4, num_trees: 4, samples: 517\n",
      "feat_name: (1440-1455,1380-1395), count_total: 6, num_trees: 6, samples: 603\n",
      "feat_name: (1125-1140,90-105), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (150-165,1410-1425), count_total: 4, num_trees: 4, samples: 414\n",
      "feat_name: (1455-1470,1380-1395), count_total: 16, num_trees: 16, samples: 1902\n",
      "feat_name: (180-195,1305-1320), count_total: 2, num_trees: 2, samples: 239\n",
      "feat_name: (1380-1395,1380-1395), count_total: 5, num_trees: 5, samples: 565\n",
      "feat_name: (1185-1200,675-690), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (810-825,810-825), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1365-1380,105-120), count_total: 17, num_trees: 16, samples: 1414\n",
      "feat_name: (315-330,90-105), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (195-210,1305-1320), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1350-1365,1425-1440), count_total: 16, num_trees: 16, samples: 2487\n",
      "feat_name: (1470-1485,105-120), count_total: 3, num_trees: 3, samples: 130\n",
      "feat_name: (435-450,300-315), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (120-135,120-135), count_total: 5, num_trees: 5, samples: 399\n",
      "feat_name: (1140-1155,60-75), count_total: 8, num_trees: 8, samples: 617\n",
      "feat_name: (570-585,135-150), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (1140-1155,270-285), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (1365-1380,60-75), count_total: 5, num_trees: 5, samples: 258\n",
      "feat_name: (15-30,60-75), count_total: 3, num_trees: 3, samples: 17\n",
      "feat_name: (165-180,1125-1140), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1455-1470,135-150), count_total: 4, num_trees: 4, samples: 289\n",
      "feat_name: (780-795,1410-1425), count_total: 2, num_trees: 2, samples: 112\n",
      "feat_name: (645-660,1320-1335), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (285-300,1290-1305), count_total: 3, num_trees: 3, samples: 354\n",
      "feat_name: (1080-1095,75-90), count_total: 3, num_trees: 3, samples: 18\n",
      "feat_name: (210-225,1335-1350), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (15-30,810-825), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (0-15,615-630), count_total: 2, num_trees: 2, samples: 259\n",
      "feat_name: (1440-1455,1065-1080), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (60-75,1410-1425), count_total: 6, num_trees: 6, samples: 308\n",
      "feat_name: (315-330,75-90), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (1185-1200,75-90), count_total: 2, num_trees: 2, samples: 19\n",
      "feat_name: (1260-1275,1380-1395), count_total: 3, num_trees: 3, samples: 385\n",
      "feat_name: (300-315,930-945), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (30-45,690-705), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1245-1260,375-390), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1215-1230,60-75), count_total: 3, num_trees: 3, samples: 55\n",
      "feat_name: (165-180,1110-1125), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (645-660,75-90), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (480-495,945-960), count_total: 2, num_trees: 2, samples: 8\n",
      "feat_name: (150-165,45-60), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (0-15,120-135), count_total: 10, num_trees: 10, samples: 1083\n",
      "feat_name: (1305-1320,105-120), count_total: 2, num_trees: 2, samples: 5\n",
      "feat_name: (105-120,900-915), count_total: 4, num_trees: 4, samples: 308\n",
      "feat_name: (1050-1065,240-255), count_total: 2, num_trees: 2, samples: 23\n",
      "feat_name: (675-690,75-90), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1230-1245,1380-1395), count_total: 6, num_trees: 6, samples: 280\n",
      "feat_name: (1410-1425,945-960), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1065-1080,75-90), count_total: 2, num_trees: 2, samples: 115\n",
      "feat_name: (1470-1485,90-105), count_total: 11, num_trees: 11, samples: 1036\n",
      "feat_name: (1140-1155,1410-1425), count_total: 9, num_trees: 9, samples: 1935\n",
      "feat_name: (105-120,720-735), count_total: 2, num_trees: 2, samples: 137\n",
      "feat_name: (405-420,900-915), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (960-975,1410-1425), count_total: 2, num_trees: 2, samples: 249\n",
      "feat_name: (1470-1485,1065-1080), count_total: 5, num_trees: 5, samples: 601\n",
      "feat_name: (1200-1215,165-180), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (30-45,1410-1425), count_total: 6, num_trees: 6, samples: 463\n",
      "feat_name: (150-165,1380-1395), count_total: 2, num_trees: 2, samples: 107\n",
      "feat_name: (645-660,180-195), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (150-165,1095-1110), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (900-915,615-630), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (900-915,390-405), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (975-990,60-75), count_total: 5, num_trees: 5, samples: 375\n",
      "feat_name: (1170-1185,1035-1050), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (855-870,705-720), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (1440-1455,60-75), count_total: 4, num_trees: 4, samples: 230\n",
      "feat_name: (195-210,1410-1425), count_total: 2, num_trees: 2, samples: 200\n",
      "feat_name: (165-180,75-90), count_total: 2, num_trees: 2, samples: 179\n",
      "feat_name: (1050-1065,75-90), count_total: 5, num_trees: 5, samples: 111\n",
      "feat_name: (330-345,165-180), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (750-765,960-975), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (45-60,945-960), count_total: 2, num_trees: 2, samples: 247\n",
      "feat_name: (180-195,255-270), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1170-1185,900-915), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (180-195,1290-1305), count_total: 5, num_trees: 5, samples: 560\n",
      "feat_name: (1290-1305,1380-1395), count_total: 2, num_trees: 2, samples: 27\n",
      "feat_name: (1260-1275,255-270), count_total: 3, num_trees: 3, samples: 122\n",
      "feat_name: (30-45,660-675), count_total: 4, num_trees: 4, samples: 299\n",
      "feat_name: (165-180,1260-1275), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (1095-1110,1335-1350), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (15-30,465-480), count_total: 3, num_trees: 3, samples: 208\n",
      "feat_name: (1050-1065,840-855), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (960-975,270-285), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (645-660,1185-1200), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (45-60,90-105), count_total: 5, num_trees: 5, samples: 115\n",
      "feat_name: (990-1005,90-105), count_total: 3, num_trees: 3, samples: 287\n",
      "feat_name: (735-750,1410-1425), count_total: 3, num_trees: 3, samples: 124\n",
      "feat_name: (1230-1245,270-285), count_total: 6, num_trees: 6, samples: 566\n",
      "feat_name: (1005-1020,930-945), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (1155-1170,75-90), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (225-240,1290-1305), count_total: 14, num_trees: 14, samples: 1675\n",
      "feat_name: (1380-1395,750-765), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (1275-1290,1005-1020), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1485-1500,480-495), count_total: 6, num_trees: 6, samples: 562\n",
      "feat_name: (1185-1200,1380-1395), count_total: 6, num_trees: 6, samples: 539\n",
      "feat_name: (585-600,975-990), count_total: 2, num_trees: 2, samples: 8\n",
      "feat_name: (315-330,840-855), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (45-60,75-90), count_total: 4, num_trees: 4, samples: 329\n",
      "feat_name: (1485-1500,900-915), count_total: 5, num_trees: 5, samples: 508\n",
      "feat_name: (1245-1260,90-105), count_total: 3, num_trees: 3, samples: 207\n",
      "feat_name: (720-735,165-180), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (735-750,270-285), count_total: 2, num_trees: 2, samples: 202\n",
      "feat_name: (1260-1275,645-660), count_total: 3, num_trees: 3, samples: 30\n",
      "feat_name: (1170-1185,360-375), count_total: 1, num_trees: 1, samples: 43\n",
      "feat_name: (705-720,810-825), count_total: 1, num_trees: 1, samples: 35\n",
      "feat_name: (1350-1365,960-975), count_total: 4, num_trees: 4, samples: 384\n",
      "feat_name: (1080-1095,1380-1395), count_total: 7, num_trees: 7, samples: 566\n",
      "feat_name: (1380-1395,1410-1425), count_total: 7, num_trees: 7, samples: 1387\n",
      "feat_name: (1350-1365,390-405), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (510-525,1410-1425), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (795-810,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (90-105,1125-1140), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (240-255,195-210), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (135-150,105-120), count_total: 3, num_trees: 3, samples: 301\n",
      "feat_name: (1320-1335,90-105), count_total: 14, num_trees: 14, samples: 1645\n",
      "feat_name: (1395-1410,60-75), count_total: 7, num_trees: 7, samples: 339\n",
      "feat_name: (1035-1050,90-105), count_total: 5, num_trees: 5, samples: 154\n",
      "feat_name: (495-510,105-120), count_total: 2, num_trees: 2, samples: 209\n",
      "feat_name: (1320-1335,1380-1395), count_total: 8, num_trees: 8, samples: 636\n",
      "feat_name: (285-300,105-120), count_total: 4, num_trees: 4, samples: 370\n",
      "feat_name: (120-135,375-390), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1335-1350,120-135), count_total: 4, num_trees: 4, samples: 285\n",
      "feat_name: (1455-1470,960-975), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (0-15,390-405), count_total: 31, num_trees: 31, samples: 3587\n",
      "feat_name: (660-675,105-120), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (480-495,420-435), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (135-150,120-135), count_total: 3, num_trees: 3, samples: 266\n",
      "feat_name: (870-885,1410-1425), count_total: 3, num_trees: 3, samples: 16\n",
      "feat_name: (30-45,120-135), count_total: 5, num_trees: 5, samples: 134\n",
      "feat_name: (630-645,90-105), count_total: 3, num_trees: 3, samples: 34\n",
      "feat_name: (1470-1485,270-285), count_total: 2, num_trees: 2, samples: 55\n",
      "feat_name: (15-30,1290-1305), count_total: 3, num_trees: 3, samples: 123\n",
      "feat_name: (1050-1065,90-105), count_total: 5, num_trees: 5, samples: 50\n",
      "feat_name: (675-690,105-120), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1260-1275,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (420-435,1380-1395), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1455-1470,105-120), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1305-1320,360-375), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (75-90,735-750), count_total: 2, num_trees: 2, samples: 185\n",
      "feat_name: (1050-1065,1425-1440), count_total: 5, num_trees: 5, samples: 651\n",
      "feat_name: (1065-1080,1380-1395), count_total: 9, num_trees: 9, samples: 581\n",
      "feat_name: (1470-1485,495-510), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1350-1365,360-375), count_total: 4, num_trees: 4, samples: 205\n",
      "feat_name: (975-990,345-360), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (0-15,570-585), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1350-1365,105-120), count_total: 8, num_trees: 8, samples: 792\n",
      "feat_name: (1380-1395,315-330), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (30-45,165-180), count_total: 2, num_trees: 2, samples: 39\n",
      "feat_name: (1365-1380,270-285), count_total: 2, num_trees: 2, samples: 36\n",
      "feat_name: (660-675,1305-1320), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (1275-1290,1425-1440), count_total: 6, num_trees: 6, samples: 491\n",
      "feat_name: (960-975,960-975), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (225-240,465-480), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1485-1500,510-525), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (240-255,540-555), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (105-120,930-945), count_total: 6, num_trees: 6, samples: 621\n",
      "feat_name: (15-30,1095-1110), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (1125-1140,660-675), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (330-345,75-90), count_total: 5, num_trees: 5, samples: 360\n",
      "feat_name: (75-90,1290-1305), count_total: 6, num_trees: 6, samples: 615\n",
      "feat_name: (1155-1170,480-495), count_total: 2, num_trees: 2, samples: 87\n",
      "feat_name: (735-750,930-945), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1245-1260,1425-1440), count_total: 9, num_trees: 9, samples: 1000\n",
      "feat_name: (1335-1350,1380-1395), count_total: 8, num_trees: 8, samples: 560\n",
      "feat_name: (285-300,135-150), count_total: 3, num_trees: 3, samples: 398\n",
      "feat_name: (0-15,720-735), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (1485-1500,795-810), count_total: 2, num_trees: 2, samples: 227\n",
      "feat_name: (1440-1455,255-270), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1470-1485,420-435), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (375-390,1485-1500), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (1020-1035,210-225), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (105-120,1290-1305), count_total: 3, num_trees: 3, samples: 167\n",
      "feat_name: (1005-1020,1395-1410), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (975-990,1425-1440), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1035-1050,1410-1425), count_total: 4, num_trees: 4, samples: 247\n",
      "feat_name: (1035-1050,1425-1440), count_total: 3, num_trees: 3, samples: 343\n",
      "feat_name: (1050-1065,1290-1305), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (1080-1095,165-180), count_total: 2, num_trees: 2, samples: 247\n",
      "feat_name: (1395-1410,465-480), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (165-180,300-315), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (780-795,105-120), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (885-900,1425-1440), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (540-555,945-960), count_total: 1, num_trees: 1, samples: 14\n",
      "feat_name: (195-210,60-75), count_total: 4, num_trees: 4, samples: 153\n",
      "feat_name: (150-165,285-300), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (345-360,135-150), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1200-1215,1425-1440), count_total: 2, num_trees: 2, samples: 279\n",
      "feat_name: (1155-1170,1380-1395), count_total: 5, num_trees: 5, samples: 629\n",
      "feat_name: (375-390,1065-1080), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1215-1230,360-375), count_total: 2, num_trees: 2, samples: 10\n",
      "feat_name: (1005-1020,300-315), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (345-360,1380-1395), count_total: 2, num_trees: 2, samples: 24\n",
      "feat_name: (765-780,1410-1425), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (1410-1425,135-150), count_total: 2, num_trees: 2, samples: 211\n",
      "feat_name: (300-315,1290-1305), count_total: 5, num_trees: 5, samples: 597\n",
      "feat_name: (1260-1275,60-75), count_total: 3, num_trees: 3, samples: 388\n",
      "feat_name: (645-660,105-120), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (750-765,90-105), count_total: 2, num_trees: 2, samples: 14\n",
      "feat_name: (825-840,735-750), count_total: 2, num_trees: 2, samples: 208\n",
      "feat_name: (795-810,1425-1440), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (450-465,90-105), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (330-345,60-75), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (405-420,435-450), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (720-735,90-105), count_total: 3, num_trees: 3, samples: 391\n",
      "feat_name: (1470-1485,450-465), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (15-30,555-570), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (105-120,285-300), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (180-195,90-105), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (390-405,135-150), count_total: 2, num_trees: 2, samples: 236\n",
      "feat_name: (960-975,1260-1275), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (780-795,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (165-180,840-855), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (375-390,1410-1425), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (75-90,930-945), count_total: 6, num_trees: 6, samples: 453\n",
      "feat_name: (885-900,285-300), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (855-870,60-75), count_total: 4, num_trees: 4, samples: 441\n",
      "feat_name: (270-285,1395-1410), count_total: 3, num_trees: 3, samples: 267\n",
      "feat_name: (1200-1215,270-285), count_total: 3, num_trees: 3, samples: 24\n",
      "feat_name: (330-345,660-675), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (15-30,90-105), count_total: 8, num_trees: 8, samples: 697\n",
      "feat_name: (90-105,705-720), count_total: 2, num_trees: 2, samples: 138\n",
      "feat_name: (1485-1500,1500-1515), count_total: 2, num_trees: 2, samples: 265\n",
      "feat_name: (1380-1395,75-90), count_total: 3, num_trees: 3, samples: 30\n",
      "feat_name: (630-645,75-90), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (1455-1470,930-945), count_total: 6, num_trees: 6, samples: 475\n",
      "feat_name: (1440-1455,435-450), count_total: 8, num_trees: 8, samples: 761\n",
      "feat_name: (1425-1440,1290-1305), count_total: 3, num_trees: 3, samples: 254\n",
      "feat_name: (1005-1020,120-135), count_total: 2, num_trees: 2, samples: 130\n",
      "feat_name: (90-105,270-285), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (1485-1500,495-510), count_total: 5, num_trees: 5, samples: 317\n",
      "feat_name: (255-270,75-90), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (90-105,210-225), count_total: 4, num_trees: 4, samples: 216\n",
      "feat_name: (630-645,135-150), count_total: 4, num_trees: 4, samples: 368\n",
      "feat_name: (915-930,360-375), count_total: 2, num_trees: 2, samples: 30\n",
      "feat_name: (1365-1380,75-90), count_total: 7, num_trees: 7, samples: 161\n",
      "feat_name: (1230-1245,360-375), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (1440-1455,705-720), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (1290-1305,120-135), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (1395-1410,420-435), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1080-1095,1410-1425), count_total: 4, num_trees: 4, samples: 352\n",
      "feat_name: (165-180,105-120), count_total: 3, num_trees: 3, samples: 123\n",
      "feat_name: (360-375,60-75), count_total: 4, num_trees: 4, samples: 343\n",
      "feat_name: (465-480,450-465), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (105-120,915-930), count_total: 2, num_trees: 2, samples: 6\n",
      "feat_name: (360-375,1245-1260), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (810-825,120-135), count_total: 3, num_trees: 3, samples: 121\n",
      "feat_name: (300-315,1065-1080), count_total: 3, num_trees: 3, samples: 371\n",
      "feat_name: (30-45,1380-1395), count_total: 2, num_trees: 2, samples: 17\n",
      "feat_name: (30-45,195-210), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1080-1095,90-105), count_total: 5, num_trees: 5, samples: 340\n",
      "feat_name: (225-240,825-840), count_total: 2, num_trees: 2, samples: 252\n",
      "feat_name: (825-840,105-120), count_total: 2, num_trees: 2, samples: 9\n",
      "feat_name: (30-45,885-900), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (300-315,60-75), count_total: 4, num_trees: 4, samples: 146\n",
      "feat_name: (915-930,1380-1395), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (885-900,105-120), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (210-225,120-135), count_total: 6, num_trees: 6, samples: 541\n",
      "feat_name: (945-960,1290-1305), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (45-60,1380-1395), count_total: 5, num_trees: 5, samples: 252\n",
      "feat_name: (540-555,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (390-405,285-300), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (1335-1350,240-255), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (915-930,270-285), count_total: 3, num_trees: 3, samples: 30\n",
      "feat_name: (165-180,1080-1095), count_total: 1, num_trees: 1, samples: 79\n",
      "feat_name: (1335-1350,105-120), count_total: 9, num_trees: 9, samples: 917\n",
      "feat_name: (1470-1485,435-450), count_total: 2, num_trees: 2, samples: 215\n",
      "feat_name: (705-720,465-480), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (495-510,75-90), count_total: 4, num_trees: 4, samples: 188\n",
      "feat_name: (585-600,930-945), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (225-240,1410-1425), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (480-495,1380-1395), count_total: 2, num_trees: 2, samples: 228\n",
      "feat_name: (900-915,1410-1425), count_total: 2, num_trees: 2, samples: 112\n",
      "feat_name: (915-930,255-270), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (885-900,435-450), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (975-990,90-105), count_total: 4, num_trees: 4, samples: 297\n",
      "feat_name: (840-855,1410-1425), count_total: 2, num_trees: 2, samples: 248\n",
      "feat_name: (420-435,195-210), count_total: 2, num_trees: 2, samples: 238\n",
      "feat_name: (1215-1230,735-750), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1245-1260,105-120), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1440-1455,480-495), count_total: 5, num_trees: 5, samples: 492\n",
      "feat_name: (270-285,105-120), count_total: 2, num_trees: 2, samples: 223\n",
      "feat_name: (630-645,735-750), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (210-225,210-225), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (1455-1470,120-135), count_total: 2, num_trees: 2, samples: 94\n",
      "feat_name: (1380-1395,945-960), count_total: 2, num_trees: 2, samples: 107\n",
      "feat_name: (555-570,210-225), count_total: 1, num_trees: 1, samples: 19\n",
      "feat_name: (660-675,720-735), count_total: 2, num_trees: 2, samples: 188\n",
      "feat_name: (435-450,1380-1395), count_total: 4, num_trees: 4, samples: 245\n",
      "feat_name: (75-90,60-75), count_total: 2, num_trees: 2, samples: 66\n",
      "feat_name: (870-885,105-120), count_total: 3, num_trees: 3, samples: 213\n",
      "feat_name: (120-135,105-120), count_total: 3, num_trees: 3, samples: 104\n",
      "feat_name: (585-600,60-75), count_total: 2, num_trees: 2, samples: 15\n",
      "feat_name: (1185-1200,1410-1425), count_total: 5, num_trees: 5, samples: 474\n",
      "feat_name: (60-75,105-120), count_total: 2, num_trees: 2, samples: 114\n",
      "feat_name: (60-75,1230-1245), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (60-75,45-60), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (1395-1410,225-240), count_total: 2, num_trees: 2, samples: 86\n",
      "feat_name: (450-465,225-240), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (945-960,1185-1200), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1005-1020,270-285), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (1290-1305,225-240), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (450-465,915-930), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (1095-1110,1410-1425), count_total: 5, num_trees: 5, samples: 443\n",
      "feat_name: (1470-1485,900-915), count_total: 5, num_trees: 5, samples: 403\n",
      "feat_name: (570-585,105-120), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (990-1005,930-945), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (75-90,900-915), count_total: 2, num_trees: 2, samples: 138\n",
      "feat_name: (390-405,1410-1425), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1275-1290,1410-1425), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1230-1245,105-120), count_total: 2, num_trees: 2, samples: 201\n",
      "feat_name: (1425-1440,1380-1395), count_total: 2, num_trees: 2, samples: 9\n",
      "feat_name: (1185-1200,1110-1125), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (240-255,135-150), count_total: 2, num_trees: 2, samples: 73\n",
      "feat_name: (45-60,1410-1425), count_total: 7, num_trees: 7, samples: 407\n",
      "feat_name: (1065-1080,90-105), count_total: 4, num_trees: 4, samples: 221\n",
      "feat_name: (900-915,1425-1440), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (15-30,1230-1245), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (390-405,930-945), count_total: 2, num_trees: 2, samples: 239\n",
      "feat_name: (1410-1425,75-90), count_total: 5, num_trees: 5, samples: 110\n",
      "feat_name: (405-420,75-90), count_total: 2, num_trees: 2, samples: 188\n",
      "feat_name: (1470-1485,915-930), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (210-225,225-240), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (75-90,225-240), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (1350-1365,270-285), count_total: 2, num_trees: 2, samples: 118\n",
      "feat_name: (495-510,60-75), count_total: 2, num_trees: 2, samples: 104\n",
      "feat_name: (870-885,930-945), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1395-1410,240-255), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (60-75,915-930), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (690-705,135-150), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (915-930,210-225), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (825-840,1380-1395), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (270-285,75-90), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1275-1290,270-285), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (30-45,60-75), count_total: 4, num_trees: 4, samples: 96\n",
      "feat_name: (420-435,585-600), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1410-1425,1335-1350), count_total: 3, num_trees: 3, samples: 118\n",
      "feat_name: (300-315,90-105), count_total: 2, num_trees: 2, samples: 88\n",
      "feat_name: (825-840,90-105), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1395-1410,90-105), count_total: 8, num_trees: 8, samples: 616\n",
      "feat_name: (1215-1230,75-90), count_total: 2, num_trees: 2, samples: 25\n",
      "feat_name: (75-90,105-120), count_total: 4, num_trees: 4, samples: 381\n",
      "feat_name: (75-90,1380-1395), count_total: 4, num_trees: 4, samples: 367\n",
      "feat_name: (1155-1170,255-270), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1455-1470,495-510), count_total: 2, num_trees: 2, samples: 106\n",
      "feat_name: (210-225,90-105), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1275-1290,240-255), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1125-1140,1425-1440), count_total: 1, num_trees: 1, samples: 149\n",
      "feat_name: (615-630,435-450), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (180-195,900-915), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (1350-1365,120-135), count_total: 3, num_trees: 3, samples: 118\n",
      "feat_name: (1440-1455,1290-1305), count_total: 2, num_trees: 2, samples: 251\n",
      "feat_name: (210-225,60-75), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1140-1155,1290-1305), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (990-1005,450-465), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (255-270,900-915), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (30-45,915-930), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (210-225,960-975), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (390-405,465-480), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1425-1440,705-720), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (630-645,1410-1425), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1290-1305,495-510), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (60-75,1260-1275), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (1440-1455,615-630), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (135-150,1170-1185), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (1425-1440,885-900), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (585-600,90-105), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (1425-1440,75-90), count_total: 6, num_trees: 6, samples: 134\n",
      "feat_name: (1455-1470,270-285), count_total: 2, num_trees: 2, samples: 118\n",
      "feat_name: (390-405,150-165), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (210-225,945-960), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (930-945,660-675), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (960-975,60-75), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1470-1485,840-855), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (0-15,135-150), count_total: 3, num_trees: 3, samples: 248\n",
      "feat_name: (915-930,90-105), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (300-315,975-990), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (1395-1410,75-90), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (105-120,225-240), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (105-120,105-120), count_total: 2, num_trees: 2, samples: 89\n",
      "feat_name: (945-960,555-570), count_total: 2, num_trees: 2, samples: 24\n",
      "feat_name: (30-45,510-525), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (1260-1275,1425-1440), count_total: 5, num_trees: 5, samples: 754\n",
      "feat_name: (75-90,1485-1500), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (1155-1170,210-225), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1425-1440,960-975), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (60-75,930-945), count_total: 2, num_trees: 2, samples: 293\n",
      "feat_name: (735-750,90-105), count_total: 3, num_trees: 3, samples: 369\n",
      "feat_name: (990-1005,60-75), count_total: 4, num_trees: 4, samples: 143\n",
      "feat_name: (135-150,1410-1425), count_total: 4, num_trees: 4, samples: 365\n",
      "feat_name: (345-360,105-120), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (45-60,1170-1185), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (120-135,1290-1305), count_total: 3, num_trees: 3, samples: 145\n",
      "feat_name: (330-345,930-945), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (990-1005,375-390), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (450-465,135-150), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (90-105,885-900), count_total: 2, num_trees: 2, samples: 206\n",
      "feat_name: (30-45,1185-1200), count_total: 2, num_trees: 2, samples: 113\n",
      "feat_name: (1095-1110,330-345), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (45-60,555-570), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1095-1110,1380-1395), count_total: 3, num_trees: 3, samples: 34\n",
      "feat_name: (420-435,1290-1305), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (1290-1305,90-105), count_total: 2, num_trees: 2, samples: 24\n",
      "feat_name: (660-675,735-750), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (105-120,1050-1065), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (375-390,720-735), count_total: 2, num_trees: 2, samples: 259\n",
      "feat_name: (360-375,390-405), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (1140-1155,225-240), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (600-615,60-75), count_total: 2, num_trees: 2, samples: 108\n",
      "feat_name: (1275-1290,975-990), count_total: 1, num_trees: 1, samples: 20\n",
      "feat_name: (195-210,435-450), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (45-60,105-120), count_total: 5, num_trees: 5, samples: 138\n",
      "feat_name: (675-690,660-675), count_total: 1, num_trees: 1, samples: 25\n",
      "feat_name: (120-135,1110-1125), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1485-1500,1245-1260), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (15-30,345-360), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1065-1080,210-225), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (45-60,1035-1050), count_total: 3, num_trees: 3, samples: 264\n",
      "feat_name: (1470-1485,330-345), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (720-735,105-120), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (600-615,75-90), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1155-1170,1290-1305), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1155-1170,105-120), count_total: 2, num_trees: 2, samples: 114\n",
      "feat_name: (780-795,1245-1260), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1485-1500,1365-1380), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (705-720,90-105), count_total: 2, num_trees: 2, samples: 202\n",
      "feat_name: (105-120,75-90), count_total: 3, num_trees: 3, samples: 199\n",
      "feat_name: (225-240,60-75), count_total: 4, num_trees: 4, samples: 361\n",
      "feat_name: (975-990,1020-1035), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (435-450,375-390), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1425-1440,270-285), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (195-210,135-150), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1005-1020,480-495), count_total: 3, num_trees: 3, samples: 109\n",
      "feat_name: (15-30,1275-1290), count_total: 2, num_trees: 2, samples: 152\n",
      "feat_name: (150-165,75-90), count_total: 2, num_trees: 2, samples: 131\n",
      "feat_name: (660-675,495-510), count_total: 2, num_trees: 2, samples: 34\n",
      "feat_name: (345-360,1290-1305), count_total: 3, num_trees: 3, samples: 83\n",
      "feat_name: (405-420,1410-1425), count_total: 1, num_trees: 1, samples: 69\n",
      "feat_name: (615-630,90-105), count_total: 6, num_trees: 6, samples: 626\n",
      "feat_name: (315-330,1410-1425), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (810-825,315-330), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (330-345,105-120), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (165-180,1245-1260), count_total: 2, num_trees: 2, samples: 256\n",
      "feat_name: (1245-1260,330-345), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1440-1455,675-690), count_total: 1, num_trees: 1, samples: 130\n",
      "feat_name: (135-150,1425-1440), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (435-450,495-510), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (1050-1065,1380-1395), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (810-825,90-105), count_total: 3, num_trees: 3, samples: 23\n",
      "feat_name: (0-15,165-180), count_total: 4, num_trees: 4, samples: 533\n",
      "feat_name: (1470-1485,930-945), count_total: 5, num_trees: 5, samples: 450\n",
      "feat_name: (1095-1110,105-120), count_total: 3, num_trees: 3, samples: 326\n",
      "feat_name: (1245-1260,270-285), count_total: 2, num_trees: 2, samples: 51\n",
      "feat_name: (915-930,495-510), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (450-465,60-75), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (1080-1095,1050-1065), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (1005-1020,60-75), count_total: 3, num_trees: 3, samples: 294\n",
      "feat_name: (1425-1440,1395-1410), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (165-180,1335-1350), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (165-180,60-75), count_total: 6, num_trees: 6, samples: 387\n",
      "feat_name: (300-315,1410-1425), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1095-1110,1050-1065), count_total: 2, num_trees: 2, samples: 231\n",
      "feat_name: (0-15,1155-1170), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (795-810,465-480), count_total: 3, num_trees: 3, samples: 240\n",
      "feat_name: (675-690,495-510), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (1035-1050,210-225), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1425-1440,1320-1335), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (315-330,990-1005), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (75-90,90-105), count_total: 4, num_trees: 4, samples: 134\n",
      "feat_name: (450-465,1425-1440), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (540-555,1425-1440), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (480-495,105-120), count_total: 3, num_trees: 3, samples: 211\n",
      "feat_name: (255-270,720-735), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (645-660,1335-1350), count_total: 2, num_trees: 2, samples: 113\n",
      "feat_name: (180-195,1065-1080), count_total: 1, num_trees: 1, samples: 25\n",
      "feat_name: (0-15,900-915), count_total: 2, num_trees: 2, samples: 201\n",
      "feat_name: (1365-1380,465-480), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (1260-1275,990-1005), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (15-30,75-90), count_total: 2, num_trees: 2, samples: 168\n",
      "feat_name: (645-660,810-825), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1260-1275,75-90), count_total: 4, num_trees: 4, samples: 122\n",
      "feat_name: (30-45,90-105), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (105-120,1380-1395), count_total: 2, num_trees: 2, samples: 119\n",
      "feat_name: (270-285,240-255), count_total: 2, num_trees: 2, samples: 119\n",
      "feat_name: (330-345,1200-1215), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (1395-1410,975-990), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (315-330,450-465), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (30-45,255-270), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (15-30,945-960), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (105-120,165-180), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (30-45,675-690), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (585-600,735-750), count_total: 1, num_trees: 1, samples: 14\n",
      "feat_name: (90-105,720-735), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (765-780,105-120), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (480-495,75-90), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (810-825,345-360), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (1170-1185,1380-1395), count_total: 4, num_trees: 4, samples: 146\n",
      "feat_name: (825-840,375-390), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (1485-1500,600-615), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (660-675,330-345), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (375-390,735-750), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (660-675,1290-1305), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1170-1185,105-120), count_total: 5, num_trees: 5, samples: 127\n",
      "feat_name: (405-420,240-255), count_total: 3, num_trees: 3, samples: 279\n",
      "feat_name: (1245-1260,1410-1425), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (525-540,840-855), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (165-180,780-795), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (165-180,945-960), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1365-1380,945-960), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (165-180,135-150), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (645-660,720-735), count_total: 2, num_trees: 2, samples: 113\n",
      "feat_name: (1245-1260,75-90), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (600-615,540-555), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (240-255,315-330), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (270-285,1245-1260), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (795-810,1410-1425), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (165-180,120-135), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (345-360,240-255), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (105-120,1305-1320), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (1215-1230,90-105), count_total: 2, num_trees: 2, samples: 99\n",
      "feat_name: (315-330,150-165), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (855-870,435-450), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (75-90,165-180), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1455-1470,75-90), count_total: 4, num_trees: 4, samples: 51\n",
      "feat_name: (375-390,60-75), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (30-45,930-945), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (750-765,75-90), count_total: 2, num_trees: 2, samples: 112\n",
      "feat_name: (15-30,150-165), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1350-1365,135-150), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (885-900,270-285), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1230-1245,1050-1065), count_total: 2, num_trees: 2, samples: 14\n",
      "feat_name: (90-105,90-105), count_total: 2, num_trees: 2, samples: 19\n",
      "feat_name: (1275-1290,90-105), count_total: 4, num_trees: 4, samples: 19\n",
      "feat_name: (825-840,1005-1020), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (375-390,90-105), count_total: 2, num_trees: 2, samples: 188\n",
      "feat_name: (900-915,495-510), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1050-1065,1410-1425), count_total: 3, num_trees: 3, samples: 196\n",
      "feat_name: (1485-1500,555-570), count_total: 2, num_trees: 2, samples: 249\n",
      "feat_name: (720-735,780-795), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (990-1005,690-705), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1050-1065,270-285), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (420-435,1410-1425), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (1485-1500,270-285), count_total: 3, num_trees: 3, samples: 212\n",
      "feat_name: (1440-1455,945-960), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (1425-1440,975-990), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (900-915,315-330), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (735-750,780-795), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1425-1440,330-345), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (855-870,915-930), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1365-1380,1380-1395), count_total: 2, num_trees: 2, samples: 243\n",
      "feat_name: (1275-1290,105-120), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (75-90,1080-1095), count_total: 2, num_trees: 2, samples: 11\n",
      "feat_name: (1485-1500,570-585), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (285-300,585-600), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (165-180,405-420), count_total: 2, num_trees: 2, samples: 30\n",
      "feat_name: (525-540,120-135), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1005-1020,330-345), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (390-405,75-90), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (855-870,930-945), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (630-645,255-270), count_total: 4, num_trees: 4, samples: 388\n",
      "feat_name: (1005-1020,420-435), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (225-240,480-495), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (330-345,480-495), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (255-270,60-75), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (900-915,285-300), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (1260-1275,105-120), count_total: 3, num_trees: 3, samples: 254\n",
      "feat_name: (825-840,120-135), count_total: 3, num_trees: 3, samples: 230\n",
      "feat_name: (1470-1485,480-495), count_total: 3, num_trees: 3, samples: 305\n",
      "feat_name: (105-120,150-165), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1080-1095,105-120), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (15-30,960-975), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1440-1455,1350-1365), count_total: 2, num_trees: 2, samples: 114\n",
      "feat_name: (405-420,135-150), count_total: 4, num_trees: 4, samples: 383\n",
      "feat_name: (210-225,1410-1425), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (945-960,885-900), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (1320-1335,1410-1425), count_total: 2, num_trees: 2, samples: 246\n",
      "feat_name: (1140-1155,360-375), count_total: 4, num_trees: 4, samples: 290\n",
      "feat_name: (960-975,450-465), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1470-1485,825-840), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (1200-1215,315-330), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1050-1065,480-495), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (15-30,1065-1080), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1485-1500,195-210), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (60-75,240-255), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (465-480,135-150), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (270-285,135-150), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (15-30,105-120), count_total: 3, num_trees: 3, samples: 18\n",
      "feat_name: (1470-1485,255-270), count_total: 2, num_trees: 2, samples: 95\n",
      "feat_name: (465-480,720-735), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (15-30,165-180), count_total: 3, num_trees: 3, samples: 292\n",
      "feat_name: (1215-1230,135-150), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1395-1410,870-885), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (60-75,1380-1395), count_total: 3, num_trees: 3, samples: 362\n",
      "feat_name: (1275-1290,600-615), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (15-30,495-510), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (165-180,990-1005), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (885-900,630-645), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (615-630,720-735), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (30-45,105-120), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (1380-1395,135-150), count_total: 3, num_trees: 3, samples: 307\n",
      "feat_name: (1260-1275,225-240), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (705-720,1050-1065), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (30-45,900-915), count_total: 2, num_trees: 2, samples: 132\n",
      "feat_name: (885-900,60-75), count_total: 2, num_trees: 2, samples: 180\n",
      "feat_name: (435-450,1395-1410), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1350-1365,240-255), count_total: 2, num_trees: 2, samples: 8\n",
      "feat_name: (1185-1200,315-330), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1425-1440,1335-1350), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (1215-1230,315-330), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (90-105,900-915), count_total: 4, num_trees: 4, samples: 313\n",
      "feat_name: (900-915,60-75), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (330-345,390-405), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (120-135,135-150), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (405-420,90-105), count_total: 3, num_trees: 3, samples: 308\n",
      "feat_name: (330-345,90-105), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (495-510,450-465), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1230-1245,75-90), count_total: 3, num_trees: 3, samples: 206\n",
      "feat_name: (480-495,1125-1140), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (825-840,435-450), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (240-255,90-105), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (45-60,345-360), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (1260-1275,885-900), count_total: 1, num_trees: 1, samples: 147\n",
      "feat_name: (420-435,105-120), count_total: 2, num_trees: 2, samples: 132\n",
      "feat_name: (1350-1365,75-90), count_total: 5, num_trees: 5, samples: 42\n",
      "feat_name: (1440-1455,390-405), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (915-930,105-120), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (870-885,90-105), count_total: 2, num_trees: 2, samples: 131\n",
      "feat_name: (1395-1410,1260-1275), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (1215-1230,1425-1440), count_total: 1, num_trees: 1, samples: 153\n",
      "feat_name: (825-840,75-90), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (735-750,150-165), count_total: 2, num_trees: 2, samples: 8\n",
      "feat_name: (1350-1365,1380-1395), count_total: 2, num_trees: 2, samples: 8\n",
      "feat_name: (375-390,1290-1305), count_total: 3, num_trees: 3, samples: 263\n",
      "feat_name: (210-225,885-900), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1335-1350,300-315), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (630-645,480-495), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (0-15,345-360), count_total: 3, num_trees: 3, samples: 385\n",
      "feat_name: (495-510,900-915), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (705-720,105-120), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (315-330,1035-1050), count_total: 1, num_trees: 1, samples: 78\n",
      "feat_name: (1380-1395,960-975), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (1050-1065,255-270), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (825-840,225-240), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (30-45,1065-1080), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (420-435,120-135), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (735-750,1155-1170), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (870-885,450-465), count_total: 2, num_trees: 2, samples: 211\n",
      "feat_name: (1035-1050,1380-1395), count_total: 2, num_trees: 2, samples: 21\n",
      "feat_name: (180-195,945-960), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (1125-1140,210-225), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (45-60,585-600), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (900-915,90-105), count_total: 2, num_trees: 2, samples: 6\n",
      "feat_name: (585-600,225-240), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (0-15,945-960), count_total: 2, num_trees: 2, samples: 196\n",
      "feat_name: (1245-1260,225-240), count_total: 1, num_trees: 1, samples: 28\n",
      "feat_name: (1230-1245,390-405), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (885-900,510-525), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (600-615,450-465), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (690-705,975-990), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (690-705,240-255), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (945-960,660-675), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (930-945,270-285), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (1455-1470,1335-1350), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (405-420,1155-1170), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (15-30,210-225), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (15-30,705-720), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (975-990,75-90), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1080-1095,150-165), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (300-315,510-525), count_total: 2, num_trees: 2, samples: 239\n",
      "feat_name: (1110-1125,345-360), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (1050-1065,300-315), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (585-600,960-975), count_total: 2, num_trees: 2, samples: 143\n",
      "feat_name: (1485-1500,315-330), count_total: 2, num_trees: 2, samples: 186\n",
      "feat_name: (120-135,495-510), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (300-315,150-165), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (90-105,480-495), count_total: 3, num_trees: 3, samples: 37\n",
      "feat_name: (1185-1200,1290-1305), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (450-465,975-990), count_total: 2, num_trees: 2, samples: 26\n",
      "feat_name: (1260-1275,330-345), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (630-645,585-600), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (1365-1380,225-240), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (300-315,105-120), count_total: 2, num_trees: 2, samples: 185\n",
      "feat_name: (1455-1470,1050-1065), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (180-195,1380-1395), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (345-360,945-960), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (195-210,945-960), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (30-45,225-240), count_total: 1, num_trees: 1, samples: 31\n",
      "feat_name: (705-720,210-225), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (285-300,1410-1425), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (990-1005,120-135), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (225-240,285-300), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (645-660,1095-1110), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (90-105,1080-1095), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (840-855,330-345), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (1380-1395,495-510), count_total: 2, num_trees: 2, samples: 207\n",
      "feat_name: (420-435,1125-1140), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1485-1500,1350-1365), count_total: 2, num_trees: 2, samples: 182\n",
      "feat_name: (1035-1050,225-240), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (210-225,900-915), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (1485-1500,240-255), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (105-120,1080-1095), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (1410-1425,90-105), count_total: 3, num_trees: 3, samples: 413\n",
      "feat_name: (390-405,165-180), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1425-1440,465-480), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (975-990,150-165), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1485-1500,300-315), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1215-1230,120-135), count_total: 1, num_trees: 1, samples: 31\n",
      "feat_name: (1425-1440,945-960), count_total: 2, num_trees: 2, samples: 113\n",
      "feat_name: (765-780,150-165), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (1095-1110,75-90), count_total: 2, num_trees: 2, samples: 13\n",
      "feat_name: (1080-1095,1020-1035), count_total: 2, num_trees: 2, samples: 33\n",
      "feat_name: (270-285,195-210), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (60-75,795-810), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (1080-1095,255-270), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1035-1050,255-270), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (660-675,570-585), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (120-135,1155-1170), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (150-165,885-900), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (120-135,150-165), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (885-900,300-315), count_total: 2, num_trees: 2, samples: 90\n",
      "feat_name: (420-435,450-465), count_total: 1, num_trees: 1, samples: 144\n",
      "feat_name: (630-645,180-195), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (405-420,150-165), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (645-660,135-150), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1065-1080,660-675), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (135-150,930-945), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (150-165,645-660), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (30-45,150-165), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (330-345,255-270), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (645-660,465-480), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (285-300,1485-1500), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1395-1410,270-285), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (120-135,930-945), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (1125-1140,615-630), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (330-345,1410-1425), count_total: 2, num_trees: 2, samples: 88\n",
      "feat_name: (105-120,345-360), count_total: 1, num_trees: 1, samples: 19\n",
      "feat_name: (30-45,1020-1035), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (60-75,60-75), count_total: 2, num_trees: 2, samples: 113\n",
      "feat_name: (120-135,210-225), count_total: 2, num_trees: 2, samples: 6\n",
      "feat_name: (30-45,75-90), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (795-810,60-75), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (1065-1080,285-300), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (615-630,390-405), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (150-165,120-135), count_total: 2, num_trees: 2, samples: 216\n",
      "feat_name: (1230-1245,180-195), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (1275-1290,795-810), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (135-150,90-105), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (510-525,60-75), count_total: 2, num_trees: 2, samples: 141\n",
      "feat_name: (420-435,1065-1080), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (1110-1125,690-705), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (750-765,120-135), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (1440-1455,720-735), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (180-195,450-465), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (210-225,1380-1395), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (435-450,345-360), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (135-150,1245-1260), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (720-735,720-735), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (330-345,120-135), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (435-450,120-135), count_total: 2, num_trees: 2, samples: 98\n",
      "feat_name: (285-300,360-375), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (150-165,930-945), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (210-225,135-150), count_total: 2, num_trees: 2, samples: 176\n",
      "feat_name: (1290-1305,270-285), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (1425-1440,360-375), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (210-225,540-555), count_total: 2, num_trees: 2, samples: 127\n",
      "feat_name: (780-795,240-255), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (780-795,675-690), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (195-210,900-915), count_total: 2, num_trees: 2, samples: 252\n",
      "feat_name: (1230-1245,375-390), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1110-1125,990-1005), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1395-1410,1350-1365), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (1020-1035,1020-1035), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (1485-1500,975-990), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (195-210,255-270), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (105-120,960-975), count_total: 3, num_trees: 3, samples: 120\n",
      "feat_name: (915-930,60-75), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (390-405,1290-1305), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (375-390,45-60), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (285-300,240-255), count_total: 2, num_trees: 2, samples: 233\n",
      "feat_name: (180-195,75-90), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (45-60,855-870), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (795-810,390-405), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (660-675,615-630), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (435-450,270-285), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (135-150,1080-1095), count_total: 1, num_trees: 1, samples: 20\n",
      "feat_name: (75-90,690-705), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1305-1320,210-225), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (1275-1290,120-135), count_total: 3, num_trees: 3, samples: 139\n",
      "feat_name: (1035-1050,135-150), count_total: 2, num_trees: 2, samples: 257\n",
      "feat_name: (345-360,1410-1425), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (105-120,885-900), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (405-420,420-435), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1455-1470,390-405), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (375-390,150-165), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (555-570,120-135), count_total: 1, num_trees: 1, samples: 141\n",
      "feat_name: (1020-1035,270-285), count_total: 2, num_trees: 2, samples: 13\n",
      "feat_name: (1095-1110,150-165), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1425-1440,870-885), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (945-960,615-630), count_total: 2, num_trees: 2, samples: 23\n",
      "feat_name: (855-870,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (90-105,1170-1185), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (1440-1455,105-120), count_total: 2, num_trees: 2, samples: 346\n",
      "feat_name: (735-750,915-930), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (135-150,75-90), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (90-105,735-750), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (345-360,285-300), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (1170-1185,75-90), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (450-465,255-270), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (30-45,1485-1500), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (900-915,480-495), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (165-180,1020-1035), count_total: 1, num_trees: 1, samples: 20\n",
      "feat_name: (105-120,330-345), count_total: 2, num_trees: 2, samples: 15\n",
      "feat_name: (255-270,90-105), count_total: 2, num_trees: 2, samples: 135\n",
      "feat_name: (450-465,330-345), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (285-300,1380-1395), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (1425-1440,60-75), count_total: 3, num_trees: 3, samples: 313\n",
      "feat_name: (930-945,90-105), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1410-1425,225-240), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (15-30,195-210), count_total: 2, num_trees: 2, samples: 116\n",
      "feat_name: (1065-1080,480-495), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1350-1365,930-945), count_total: 2, num_trees: 2, samples: 103\n",
      "feat_name: (0-15,1485-1500), count_total: 2, num_trees: 2, samples: 250\n",
      "feat_name: (915-930,225-240), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (885-900,1335-1350), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (600-615,120-135), count_total: 2, num_trees: 2, samples: 231\n",
      "feat_name: (1260-1275,540-555), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (315-330,165-180), count_total: 1, num_trees: 1, samples: 19\n",
      "feat_name: (1140-1155,105-120), count_total: 2, num_trees: 2, samples: 17\n",
      "feat_name: (870-885,1425-1440), count_total: 2, num_trees: 2, samples: 48\n",
      "feat_name: (240-255,360-375), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1035-1050,645-660), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (495-510,1065-1080), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (915-930,840-855), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (975-990,270-285), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (360-375,1365-1380), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (855-870,1380-1395), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (15-30,570-585), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (390-405,540-555), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (975-990,135-150), count_total: 2, num_trees: 2, samples: 196\n",
      "feat_name: (975-990,975-990), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (930-945,360-375), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1170-1185,255-270), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (390-405,1305-1320), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (1125-1140,540-555), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (45-60,675-690), count_total: 2, num_trees: 2, samples: 193\n",
      "feat_name: (0-15,180-195), count_total: 1, num_trees: 1, samples: 143\n",
      "feat_name: (1305-1320,255-270), count_total: 2, num_trees: 2, samples: 99\n",
      "feat_name: (1440-1455,450-465), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1440-1455,930-945), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1440-1455,360-375), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (120-135,945-960), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (1425-1440,1350-1365), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (765-780,165-180), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (735-750,240-255), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (450-465,1410-1425), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1485-1500,390-405), count_total: 2, num_trees: 2, samples: 123\n",
      "feat_name: (75-90,675-690), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (525-540,90-105), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (225-240,720-735), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (1065-1080,105-120), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (195-210,120-135), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (450-465,840-855), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (525-540,60-75), count_total: 1, num_trees: 1, samples: 20\n",
      "feat_name: (120-135,180-195), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (450-465,735-750), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1170-1185,390-405), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (780-795,1050-1065), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1440-1455,1140-1155), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (600-615,225-240), count_total: 1, num_trees: 1, samples: 36\n",
      "feat_name: (420-435,1425-1440), count_total: 1, num_trees: 1, samples: 30\n",
      "feat_name: (15-30,405-420), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (75-90,270-285), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (465-480,165-180), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1380-1395,435-450), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (180-195,885-900), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (45-60,255-270), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (975-990,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (60-75,1155-1170), count_total: 2, num_trees: 2, samples: 192\n",
      "feat_name: (1155-1170,270-285), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (225-240,270-285), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (780-795,285-300), count_total: 1, num_trees: 1, samples: 121\n",
      "feat_name: (705-720,330-345), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (180-195,135-150), count_total: 2, num_trees: 2, samples: 214\n",
      "feat_name: (240-255,1290-1305), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (435-450,60-75), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1050-1065,945-960), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (660-675,1320-1335), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1020-1035,1410-1425), count_total: 3, num_trees: 3, samples: 133\n",
      "feat_name: (15-30,330-345), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (615-630,120-135), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (1455-1470,915-930), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (810-825,1290-1305), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (1005-1020,75-90), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (900-915,1245-1260), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (75-90,480-495), count_total: 2, num_trees: 2, samples: 137\n",
      "feat_name: (585-600,1380-1395), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (135-150,375-390), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (885-900,1410-1425), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (1140-1155,90-105), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (90-105,690-705), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (1230-1245,210-225), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (1380-1395,105-120), count_total: 2, num_trees: 2, samples: 353\n",
      "feat_name: (750-765,1410-1425), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (990-1005,270-285), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (195-210,225-240), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (390-405,60-75), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (1275-1290,555-570), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (45-60,1350-1365), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (720-735,1185-1200), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (285-300,60-75), count_total: 2, num_trees: 2, samples: 213\n",
      "feat_name: (1470-1485,390-405), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (675-690,1290-1305), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (615-630,420-435), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1380-1395,480-495), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (45-60,900-915), count_total: 2, num_trees: 2, samples: 245\n",
      "feat_name: (195-210,480-495), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (435-450,255-270), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (810-825,495-510), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1185-1200,270-285), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (885-900,120-135), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (450-465,810-825), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (135-150,885-900), count_total: 2, num_trees: 2, samples: 211\n",
      "feat_name: (480-495,735-750), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1245-1260,120-135), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1320-1335,120-135), count_total: 1, num_trees: 1, samples: 35\n",
      "feat_name: (90-105,1215-1230), count_total: 1, num_trees: 1, samples: 31\n",
      "feat_name: (780-795,1320-1335), count_total: 1, num_trees: 1, samples: 72\n",
      "feat_name: (1305-1320,225-240), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (990-1005,465-480), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (870-885,75-90), count_total: 1, num_trees: 1, samples: 14\n",
      "feat_name: (0-15,405-420), count_total: 2, num_trees: 2, samples: 236\n",
      "feat_name: (1125-1140,900-915), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (405-420,1290-1305), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (0-15,210-225), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (825-840,360-375), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (930-945,150-165), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (1035-1050,75-90), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (465-480,210-225), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (915-930,315-330), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (615-630,900-915), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (30-45,135-150), count_total: 3, num_trees: 3, samples: 15\n",
      "feat_name: (1320-1335,105-120), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1050-1065,795-810), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (180-195,465-480), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (360-375,105-120), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (285-300,1065-1080), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (720-735,210-225), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (1185-1200,255-270), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (135-150,1380-1395), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (315-330,120-135), count_total: 1, num_trees: 1, samples: 139\n",
      "feat_name: (240-255,75-90), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (720-735,60-75), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1470-1485,1365-1380), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (615-630,135-150), count_total: 2, num_trees: 2, samples: 222\n",
      "feat_name: (705-720,75-90), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (0-15,300-315), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (495-510,915-930), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1275-1290,1320-1335), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (570-585,330-345), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1440-1455,495-510), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (900-915,1035-1050), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (165-180,675-690), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1260-1275,660-675), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (1050-1065,105-120), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (120-135,90-105), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (1230-1245,60-75), count_total: 3, num_trees: 3, samples: 153\n",
      "feat_name: (915-930,690-705), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (15-30,690-705), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (1215-1230,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (210-225,1050-1065), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (435-450,750-765), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (930-945,1425-1440), count_total: 1, num_trees: 1, samples: 34\n",
      "feat_name: (1485-1500,1050-1065), count_total: 2, num_trees: 2, samples: 98\n",
      "feat_name: (1215-1230,255-270), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (1095-1110,420-435), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1335-1350,225-240), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1395-1410,120-135), count_total: 2, num_trees: 2, samples: 24\n",
      "feat_name: (150-165,600-615), count_total: 1, num_trees: 1, samples: 75\n",
      "feat_name: (420-435,90-105), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (360-375,1260-1275), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (1140-1155,210-225), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1110-1125,1005-1020), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (90-105,915-930), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1230-1245,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (600-615,1425-1440), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (870-885,315-330), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (915-930,120-135), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (15-30,825-840), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1080-1095,1425-1440), count_total: 2, num_trees: 2, samples: 311\n",
      "feat_name: (420-435,405-420), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (780-795,1290-1305), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1410-1425,1290-1305), count_total: 1, num_trees: 1, samples: 138\n",
      "feat_name: (150-165,705-720), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (1005-1020,105-120), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1380-1395,870-885), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (315-330,255-270), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (90-105,300-315), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (960-975,420-435), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (270-285,1485-1500), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (45-60,690-705), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1380-1395,225-240), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1470-1485,945-960), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (405-420,330-345), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1125-1140,1065-1080), count_total: 1, num_trees: 1, samples: 130\n",
      "feat_name: (795-810,285-300), count_total: 3, num_trees: 3, samples: 35\n",
      "feat_name: (270-285,990-1005), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (75-90,750-765), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (1005-1020,600-615), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (975-990,945-960), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1005-1020,90-105), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (885-900,945-960), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (360-375,1335-1350), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (795-810,150-165), count_total: 1, num_trees: 1, samples: 70\n",
      "feat_name: (720-735,195-210), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (90-105,435-450), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1380-1395,615-630), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (585-600,750-765), count_total: 2, num_trees: 2, samples: 188\n",
      "feat_name: (120-135,900-915), count_total: 1, num_trees: 1, samples: 133\n",
      "feat_name: (975-990,165-180), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (30-45,240-255), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (795-810,345-360), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (645-660,1410-1425), count_total: 1, num_trees: 1, samples: 139\n",
      "feat_name: (345-360,390-405), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (75-90,720-735), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1095-1110,210-225), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1200-1215,825-840), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (825-840,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1020-1035,315-330), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1365-1380,390-405), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (105-120,480-495), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (645-660,90-105), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (30-45,780-795), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (285-300,435-450), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (120-135,1095-1110), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (0-15,1425-1440), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1485-1500,735-750), count_total: 2, num_trees: 2, samples: 114\n",
      "feat_name: (1395-1410,480-495), count_total: 2, num_trees: 2, samples: 218\n",
      "feat_name: (45-60,180-195), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (945-960,1425-1440), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1020-1035,660-675), count_total: 1, num_trees: 1, samples: 31\n",
      "feat_name: (135-150,780-795), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (210-225,480-495), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (1410-1425,390-405), count_total: 2, num_trees: 2, samples: 219\n",
      "feat_name: (1305-1320,885-900), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (1335-1350,465-480), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (30-45,735-750), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (1410-1425,420-435), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (1110-1125,300-315), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (465-480,75-90), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (1365-1380,195-210), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (585-600,900-915), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (615-630,60-75), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (1440-1455,1020-1035), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (555-570,930-945), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (0-15,420-435), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (0-15,630-645), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (765-780,120-135), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (390-405,345-360), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (375-390,135-150), count_total: 2, num_trees: 2, samples: 129\n",
      "feat_name: (660-675,60-75), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (1095-1110,1095-1110), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (315-330,780-795), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (150-165,840-855), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (1410-1425,270-285), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1395-1410,1320-1335), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (135-150,900-915), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1155-1170,90-105), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (165-180,1305-1320), count_total: 1, num_trees: 1, samples: 73\n",
      "feat_name: (975-990,915-930), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (825-840,60-75), count_total: 1, num_trees: 1, samples: 146\n",
      "feat_name: (210-225,1065-1080), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (1275-1290,930-945), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (330-345,1290-1305), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (780-795,90-105), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (210-225,915-930), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (210-225,165-180), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1260-1275,270-285), count_total: 1, num_trees: 1, samples: 30\n",
      "feat_name: (1185-1200,105-120), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1410-1425,1395-1410), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (1110-1125,1110-1125), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1320-1335,270-285), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (930-945,195-210), count_total: 2, num_trees: 2, samples: 98\n",
      "feat_name: (1005-1020,405-420), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (45-60,930-945), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (720-735,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (900-915,1290-1305), count_total: 1, num_trees: 1, samples: 130\n",
      "feat_name: (735-750,180-195), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (90-105,660-675), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (435-450,75-90), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (45-60,915-930), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1350-1365,465-480), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (135-150,150-165), count_total: 1, num_trees: 1, samples: 76\n",
      "feat_name: (75-90,645-660), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (45-60,435-450), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (90-105,465-480), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (225-240,1080-1095), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1110-1125,1050-1065), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (225-240,300-315), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (30-45,1035-1050), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (960-975,105-120), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (660-675,465-480), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (675-690,300-315), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (705-720,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1455-1470,675-690), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (60-75,90-105), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (15-30,390-405), count_total: 1, num_trees: 1, samples: 28\n",
      "feat_name: (345-360,90-105), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1485-1500,960-975), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (405-420,540-555), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (630-645,420-435), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (735-750,165-180), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (270-285,60-75), count_total: 1, num_trees: 1, samples: 37\n",
      "feat_name: (165-180,1095-1110), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (765-780,375-390), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (60-75,510-525), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1470-1485,555-570), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (135-150,525-540), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1110-1125,135-150), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (75-90,1275-1290), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (390-405,660-675), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (765-780,690-705), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (315-330,930-945), count_total: 1, num_trees: 1, samples: 144\n",
      "feat_name: (1065-1080,390-405), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1395-1410,255-270), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (660-675,90-105), count_total: 2, num_trees: 2, samples: 28\n",
      "feat_name: (1440-1455,600-615), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1455-1470,705-720), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (510-525,270-285), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (1140-1155,150-165), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (840-855,105-120), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (570-585,990-1005), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (600-615,435-450), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (375-390,105-120), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (225-240,735-750), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (300-315,1245-1260), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (345-360,75-90), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (105-120,1065-1080), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (885-900,825-840), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (825-840,510-525), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (195-210,285-300), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (90-105,450-465), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (510-525,1290-1305), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (600-615,525-540), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (465-480,1365-1380), count_total: 1, num_trees: 1, samples: 123\n",
      "\n",
      "sorted features:\n",
      "feat_name: (1485-1500,135-150), count_total: 357, num_trees: 348, samples: 115728\n",
      "feat_name: (0-15,330-345), count_total: 284, num_trees: 283, samples: 38384\n",
      "feat_name: (1485-1500,1395-1410), count_total: 264, num_trees: 263, samples: 35518\n",
      "feat_name: (0-15,1410-1425), count_total: 224, num_trees: 200, samples: 29533\n",
      "feat_name: (1485-1500,1425-1440), count_total: 201, num_trees: 196, samples: 42469\n",
      "feat_name: (0-15,90-105), count_total: 103, num_trees: 100, samples: 19523\n",
      "feat_name: (1425-1440,1410-1425), count_total: 91, num_trees: 90, samples: 23610\n",
      "feat_name: (1440-1455,1410-1425), count_total: 80, num_trees: 80, samples: 20227\n",
      "feat_name: (0-15,75-90), count_total: 95, num_trees: 79, samples: 19964\n",
      "feat_name: (1455-1470,1410-1425), count_total: 53, num_trees: 52, samples: 12021\n",
      "feat_name: (105-120,60-75), count_total: 46, num_trees: 46, samples: 3967\n",
      "feat_name: (1335-1350,1410-1425), count_total: 44, num_trees: 43, samples: 10591\n",
      "feat_name: (1470-1485,1410-1425), count_total: 41, num_trees: 41, samples: 8476\n",
      "feat_name: (1410-1425,1410-1425), count_total: 35, num_trees: 35, samples: 7556\n",
      "feat_name: (1470-1485,1380-1395), count_total: 35, num_trees: 35, samples: 4436\n",
      "feat_name: (90-105,60-75), count_total: 35, num_trees: 35, samples: 2364\n",
      "feat_name: (1080-1095,60-75), count_total: 31, num_trees: 31, samples: 4638\n",
      "feat_name: (0-15,390-405), count_total: 31, num_trees: 31, samples: 3587\n",
      "feat_name: (1485-1500,1305-1320), count_total: 31, num_trees: 31, samples: 3522\n",
      "feat_name: (1305-1320,90-105), count_total: 30, num_trees: 30, samples: 3611\n",
      "feat_name: (0-15,60-75), count_total: 36, num_trees: 30, samples: 3099\n",
      "feat_name: (1470-1485,1290-1305), count_total: 28, num_trees: 28, samples: 3423\n",
      "feat_name: (1485-1500,105-120), count_total: 27, num_trees: 27, samples: 2194\n",
      "feat_name: (1395-1410,1425-1440), count_total: 27, num_trees: 26, samples: 3787\n",
      "feat_name: (1380-1395,1425-1440), count_total: 25, num_trees: 25, samples: 3725\n",
      "feat_name: (1485-1500,90-105), count_total: 25, num_trees: 25, samples: 2011\n",
      "feat_name: (1485-1500,150-165), count_total: 26, num_trees: 24, samples: 3811\n",
      "feat_name: (1170-1185,60-75), count_total: 24, num_trees: 24, samples: 3494\n",
      "feat_name: (1335-1350,1425-1440), count_total: 22, num_trees: 22, samples: 3409\n",
      "feat_name: (1410-1425,1425-1440), count_total: 22, num_trees: 22, samples: 3309\n",
      "feat_name: (1125-1140,60-75), count_total: 22, num_trees: 22, samples: 1716\n",
      "feat_name: (1110-1125,60-75), count_total: 21, num_trees: 21, samples: 2557\n",
      "feat_name: (1485-1500,285-300), count_total: 21, num_trees: 21, samples: 1910\n",
      "feat_name: (1395-1410,1410-1425), count_total: 20, num_trees: 20, samples: 4071\n",
      "feat_name: (1320-1335,1425-1440), count_total: 20, num_trees: 20, samples: 3214\n",
      "feat_name: (1365-1380,1425-1440), count_total: 20, num_trees: 20, samples: 3080\n",
      "feat_name: (0-15,1380-1395), count_total: 20, num_trees: 20, samples: 2466\n",
      "feat_name: (1365-1380,90-105), count_total: 20, num_trees: 20, samples: 2211\n",
      "feat_name: (1065-1080,60-75), count_total: 19, num_trees: 19, samples: 2858\n",
      "feat_name: (1485-1500,165-180), count_total: 19, num_trees: 19, samples: 2167\n",
      "feat_name: (1425-1440,1425-1440), count_total: 18, num_trees: 18, samples: 2732\n",
      "feat_name: (1455-1470,1425-1440), count_total: 18, num_trees: 18, samples: 2711\n",
      "feat_name: (1365-1380,1410-1425), count_total: 17, num_trees: 17, samples: 3562\n",
      "feat_name: (0-15,585-600), count_total: 17, num_trees: 17, samples: 2151\n",
      "feat_name: (1395-1410,105-120), count_total: 18, num_trees: 17, samples: 1670\n",
      "feat_name: (90-105,120-135), count_total: 17, num_trees: 17, samples: 1438\n",
      "feat_name: (1350-1365,1410-1425), count_total: 16, num_trees: 16, samples: 3508\n",
      "feat_name: (1350-1365,1425-1440), count_total: 16, num_trees: 16, samples: 2487\n",
      "feat_name: (1455-1470,1380-1395), count_total: 16, num_trees: 16, samples: 1902\n",
      "feat_name: (1365-1380,105-120), count_total: 17, num_trees: 16, samples: 1414\n",
      "feat_name: (1485-1500,75-90), count_total: 18, num_trees: 16, samples: 1258\n",
      "feat_name: (1440-1455,1425-1440), count_total: 15, num_trees: 15, samples: 2158\n",
      "feat_name: (0-15,1290-1305), count_total: 15, num_trees: 15, samples: 1574\n",
      "feat_name: (1350-1365,90-105), count_total: 15, num_trees: 15, samples: 1152\n",
      "feat_name: (1140-1155,1425-1440), count_total: 14, num_trees: 14, samples: 1851\n",
      "feat_name: (1470-1485,1425-1440), count_total: 14, num_trees: 14, samples: 1799\n",
      "feat_name: (1440-1455,90-105), count_total: 14, num_trees: 14, samples: 1693\n",
      "feat_name: (225-240,1290-1305), count_total: 14, num_trees: 14, samples: 1675\n",
      "feat_name: (1320-1335,90-105), count_total: 14, num_trees: 14, samples: 1645\n",
      "feat_name: (1455-1470,60-75), count_total: 14, num_trees: 14, samples: 1538\n",
      "feat_name: (1365-1380,135-150), count_total: 14, num_trees: 14, samples: 1463\n",
      "feat_name: (1485-1500,1440-1455), count_total: 13, num_trees: 13, samples: 2016\n",
      "feat_name: (1305-1320,1425-1440), count_total: 13, num_trees: 13, samples: 1986\n",
      "feat_name: (1155-1170,1425-1440), count_total: 13, num_trees: 13, samples: 1799\n",
      "feat_name: (1395-1410,135-150), count_total: 13, num_trees: 13, samples: 1313\n",
      "feat_name: (1335-1350,90-105), count_total: 13, num_trees: 13, samples: 1244\n",
      "feat_name: (1275-1290,60-75), count_total: 12, num_trees: 12, samples: 552\n",
      "feat_name: (1110-1125,1380-1395), count_total: 11, num_trees: 11, samples: 1150\n",
      "feat_name: (1020-1035,60-75), count_total: 11, num_trees: 11, samples: 1094\n",
      "feat_name: (1470-1485,90-105), count_total: 11, num_trees: 11, samples: 1036\n",
      "feat_name: (105-120,1410-1425), count_total: 11, num_trees: 11, samples: 976\n",
      "feat_name: (105-120,120-135), count_total: 11, num_trees: 11, samples: 971\n",
      "feat_name: (1455-1470,90-105), count_total: 11, num_trees: 11, samples: 713\n",
      "feat_name: (90-105,1290-1305), count_total: 10, num_trees: 10, samples: 1306\n",
      "feat_name: (0-15,120-135), count_total: 10, num_trees: 10, samples: 1083\n",
      "feat_name: (1410-1425,120-135), count_total: 10, num_trees: 10, samples: 1026\n",
      "feat_name: (1485-1500,915-930), count_total: 10, num_trees: 10, samples: 1004\n",
      "feat_name: (90-105,1410-1425), count_total: 10, num_trees: 10, samples: 801\n",
      "feat_name: (1425-1440,120-135), count_total: 10, num_trees: 10, samples: 788\n",
      "feat_name: (1140-1155,1410-1425), count_total: 9, num_trees: 9, samples: 1935\n",
      "feat_name: (1170-1185,1425-1440), count_total: 9, num_trees: 9, samples: 1416\n",
      "feat_name: (1290-1305,1425-1440), count_total: 9, num_trees: 9, samples: 1387\n",
      "feat_name: (840-855,60-75), count_total: 9, num_trees: 9, samples: 1070\n",
      "feat_name: (1245-1260,1425-1440), count_total: 9, num_trees: 9, samples: 1000\n",
      "feat_name: (1335-1350,105-120), count_total: 9, num_trees: 9, samples: 917\n",
      "feat_name: (75-90,1410-1425), count_total: 9, num_trees: 9, samples: 881\n",
      "feat_name: (1395-1410,1380-1395), count_total: 9, num_trees: 9, samples: 735\n",
      "feat_name: (1260-1275,90-105), count_total: 9, num_trees: 9, samples: 707\n",
      "feat_name: (1065-1080,1380-1395), count_total: 9, num_trees: 9, samples: 581\n",
      "feat_name: (1410-1425,60-75), count_total: 9, num_trees: 9, samples: 478\n",
      "feat_name: (1485-1500,945-960), count_total: 8, num_trees: 8, samples: 2100\n",
      "feat_name: (1350-1365,105-120), count_total: 8, num_trees: 8, samples: 792\n",
      "feat_name: (1440-1455,435-450), count_total: 8, num_trees: 8, samples: 761\n",
      "feat_name: (1470-1485,60-75), count_total: 8, num_trees: 8, samples: 738\n",
      "feat_name: (15-30,90-105), count_total: 8, num_trees: 8, samples: 697\n",
      "feat_name: (45-60,120-135), count_total: 8, num_trees: 8, samples: 682\n",
      "feat_name: (1320-1335,1380-1395), count_total: 8, num_trees: 8, samples: 636\n",
      "feat_name: (1470-1485,1350-1365), count_total: 8, num_trees: 8, samples: 633\n",
      "feat_name: (1140-1155,60-75), count_total: 8, num_trees: 8, samples: 617\n",
      "feat_name: (1395-1410,90-105), count_total: 8, num_trees: 8, samples: 616\n",
      "feat_name: (1335-1350,1380-1395), count_total: 8, num_trees: 8, samples: 560\n",
      "feat_name: (120-135,60-75), count_total: 8, num_trees: 8, samples: 188\n",
      "feat_name: (1380-1395,1410-1425), count_total: 7, num_trees: 7, samples: 1387\n",
      "feat_name: (1035-1050,60-75), count_total: 7, num_trees: 7, samples: 974\n",
      "feat_name: (870-885,60-75), count_total: 7, num_trees: 7, samples: 964\n",
      "feat_name: (210-225,1290-1305), count_total: 7, num_trees: 7, samples: 883\n",
      "feat_name: (1065-1080,1425-1440), count_total: 7, num_trees: 7, samples: 837\n",
      "feat_name: (1455-1470,1290-1305), count_total: 7, num_trees: 7, samples: 729\n",
      "feat_name: (1425-1440,135-150), count_total: 7, num_trees: 7, samples: 688\n",
      "feat_name: (1185-1200,60-75), count_total: 7, num_trees: 7, samples: 640\n",
      "feat_name: (75-90,120-135), count_total: 7, num_trees: 7, samples: 629\n",
      "feat_name: (90-105,930-945), count_total: 7, num_trees: 7, samples: 618\n",
      "feat_name: (1080-1095,1380-1395), count_total: 7, num_trees: 7, samples: 566\n",
      "feat_name: (1275-1290,1380-1395), count_total: 7, num_trees: 7, samples: 482\n",
      "feat_name: (135-150,60-75), count_total: 7, num_trees: 7, samples: 434\n",
      "feat_name: (1440-1455,120-135), count_total: 7, num_trees: 7, samples: 411\n",
      "feat_name: (45-60,1410-1425), count_total: 7, num_trees: 7, samples: 407\n",
      "feat_name: (1395-1410,60-75), count_total: 7, num_trees: 7, samples: 339\n",
      "feat_name: (1335-1350,60-75), count_total: 7, num_trees: 7, samples: 244\n",
      "feat_name: (1275-1290,75-90), count_total: 7, num_trees: 7, samples: 234\n",
      "feat_name: (1365-1380,75-90), count_total: 7, num_trees: 7, samples: 161\n",
      "feat_name: (1185-1200,1425-1440), count_total: 6, num_trees: 6, samples: 931\n",
      "feat_name: (1125-1140,1410-1425), count_total: 6, num_trees: 6, samples: 699\n",
      "feat_name: (165-180,1290-1305), count_total: 6, num_trees: 6, samples: 673\n",
      "feat_name: (1485-1500,1080-1095), count_total: 6, num_trees: 6, samples: 645\n",
      "feat_name: (615-630,90-105), count_total: 6, num_trees: 6, samples: 626\n",
      "feat_name: (105-120,930-945), count_total: 6, num_trees: 6, samples: 621\n",
      "feat_name: (75-90,1290-1305), count_total: 6, num_trees: 6, samples: 615\n",
      "feat_name: (1440-1455,1380-1395), count_total: 6, num_trees: 6, samples: 603\n",
      "feat_name: (675-690,90-105), count_total: 6, num_trees: 6, samples: 573\n",
      "feat_name: (1230-1245,1425-1440), count_total: 6, num_trees: 6, samples: 566\n",
      "feat_name: (1230-1245,270-285), count_total: 6, num_trees: 6, samples: 566\n",
      "feat_name: (1485-1500,480-495), count_total: 6, num_trees: 6, samples: 562\n",
      "feat_name: (210-225,120-135), count_total: 6, num_trees: 6, samples: 541\n",
      "feat_name: (1185-1200,1380-1395), count_total: 6, num_trees: 6, samples: 539\n",
      "feat_name: (1245-1260,60-75), count_total: 6, num_trees: 6, samples: 528\n",
      "feat_name: (180-195,1410-1425), count_total: 6, num_trees: 6, samples: 514\n",
      "feat_name: (1140-1155,1380-1395), count_total: 6, num_trees: 6, samples: 491\n",
      "feat_name: (1275-1290,1425-1440), count_total: 6, num_trees: 6, samples: 491\n",
      "feat_name: (1455-1470,930-945), count_total: 6, num_trees: 6, samples: 475\n",
      "feat_name: (30-45,1410-1425), count_total: 6, num_trees: 6, samples: 463\n",
      "feat_name: (75-90,930-945), count_total: 6, num_trees: 6, samples: 453\n",
      "feat_name: (1110-1125,90-105), count_total: 6, num_trees: 6, samples: 442\n",
      "feat_name: (1095-1110,1425-1440), count_total: 6, num_trees: 6, samples: 437\n",
      "feat_name: (1410-1425,1380-1395), count_total: 6, num_trees: 6, samples: 388\n",
      "feat_name: (165-180,60-75), count_total: 6, num_trees: 6, samples: 387\n",
      "feat_name: (60-75,1410-1425), count_total: 6, num_trees: 6, samples: 308\n",
      "feat_name: (1125-1140,1380-1395), count_total: 6, num_trees: 6, samples: 290\n",
      "feat_name: (1230-1245,1380-1395), count_total: 6, num_trees: 6, samples: 280\n",
      "feat_name: (1155-1170,60-75), count_total: 6, num_trees: 6, samples: 235\n",
      "feat_name: (1425-1440,75-90), count_total: 6, num_trees: 6, samples: 134\n",
      "feat_name: (1305-1320,75-90), count_total: 6, num_trees: 6, samples: 55\n",
      "feat_name: (1260-1275,1425-1440), count_total: 5, num_trees: 5, samples: 754\n",
      "feat_name: (225-240,525-540), count_total: 5, num_trees: 5, samples: 653\n",
      "feat_name: (1050-1065,1425-1440), count_total: 5, num_trees: 5, samples: 651\n",
      "feat_name: (1155-1170,1380-1395), count_total: 5, num_trees: 5, samples: 629\n",
      "feat_name: (225-240,1050-1065), count_total: 5, num_trees: 5, samples: 616\n",
      "feat_name: (135-150,1290-1305), count_total: 5, num_trees: 5, samples: 612\n",
      "feat_name: (1470-1485,1065-1080), count_total: 5, num_trees: 5, samples: 601\n",
      "feat_name: (300-315,1290-1305), count_total: 5, num_trees: 5, samples: 597\n",
      "feat_name: (1380-1395,1380-1395), count_total: 5, num_trees: 5, samples: 565\n",
      "feat_name: (180-195,1290-1305), count_total: 5, num_trees: 5, samples: 560\n",
      "feat_name: (1035-1050,150-165), count_total: 5, num_trees: 5, samples: 553\n",
      "feat_name: (1485-1500,900-915), count_total: 5, num_trees: 5, samples: 508\n",
      "feat_name: (1440-1455,480-495), count_total: 5, num_trees: 5, samples: 492\n",
      "feat_name: (1185-1200,1410-1425), count_total: 5, num_trees: 5, samples: 474\n",
      "feat_name: (120-135,1410-1425), count_total: 5, num_trees: 5, samples: 472\n",
      "feat_name: (1470-1485,930-945), count_total: 5, num_trees: 5, samples: 450\n",
      "feat_name: (1095-1110,1410-1425), count_total: 5, num_trees: 5, samples: 443\n",
      "feat_name: (1170-1185,90-105), count_total: 5, num_trees: 5, samples: 442\n",
      "feat_name: (435-450,90-105), count_total: 5, num_trees: 5, samples: 432\n",
      "feat_name: (1410-1425,105-120), count_total: 5, num_trees: 5, samples: 430\n",
      "feat_name: (1470-1485,900-915), count_total: 5, num_trees: 5, samples: 403\n",
      "feat_name: (120-135,120-135), count_total: 5, num_trees: 5, samples: 399\n",
      "feat_name: (1470-1485,135-150), count_total: 5, num_trees: 5, samples: 385\n",
      "feat_name: (975-990,60-75), count_total: 5, num_trees: 5, samples: 375\n",
      "feat_name: (330-345,75-90), count_total: 5, num_trees: 5, samples: 360\n",
      "feat_name: (1080-1095,90-105), count_total: 5, num_trees: 5, samples: 340\n",
      "feat_name: (1485-1500,495-510), count_total: 5, num_trees: 5, samples: 317\n",
      "feat_name: (45-60,135-150), count_total: 5, num_trees: 5, samples: 299\n",
      "feat_name: (1290-1305,60-75), count_total: 5, num_trees: 5, samples: 285\n",
      "feat_name: (1365-1380,60-75), count_total: 5, num_trees: 5, samples: 258\n",
      "feat_name: (45-60,1380-1395), count_total: 5, num_trees: 5, samples: 252\n",
      "feat_name: (1095-1110,90-105), count_total: 5, num_trees: 5, samples: 212\n",
      "feat_name: (1200-1215,90-105), count_total: 5, num_trees: 5, samples: 156\n",
      "feat_name: (1035-1050,90-105), count_total: 5, num_trees: 5, samples: 154\n",
      "feat_name: (1245-1260,1380-1395), count_total: 5, num_trees: 5, samples: 149\n",
      "feat_name: (45-60,105-120), count_total: 5, num_trees: 5, samples: 138\n",
      "feat_name: (30-45,120-135), count_total: 5, num_trees: 5, samples: 134\n",
      "feat_name: (1170-1185,105-120), count_total: 5, num_trees: 5, samples: 127\n",
      "feat_name: (195-210,105-120), count_total: 5, num_trees: 5, samples: 125\n",
      "feat_name: (45-60,90-105), count_total: 5, num_trees: 5, samples: 115\n",
      "feat_name: (1050-1065,75-90), count_total: 5, num_trees: 5, samples: 111\n",
      "feat_name: (1410-1425,75-90), count_total: 5, num_trees: 5, samples: 110\n",
      "feat_name: (105-120,135-150), count_total: 5, num_trees: 5, samples: 105\n",
      "feat_name: (1020-1035,75-90), count_total: 5, num_trees: 5, samples: 50\n",
      "feat_name: (1050-1065,90-105), count_total: 5, num_trees: 5, samples: 50\n",
      "feat_name: (1350-1365,75-90), count_total: 5, num_trees: 5, samples: 42\n",
      "feat_name: (1335-1350,75-90), count_total: 5, num_trees: 5, samples: 39\n",
      "feat_name: (1305-1320,1380-1395), count_total: 5, num_trees: 5, samples: 33\n",
      "feat_name: (1290-1305,1410-1425), count_total: 4, num_trees: 4, samples: 1212\n",
      "feat_name: (0-15,165-180), count_total: 4, num_trees: 4, samples: 533\n",
      "feat_name: (1110-1125,1425-1440), count_total: 4, num_trees: 4, samples: 517\n",
      "feat_name: (60-75,1290-1305), count_total: 4, num_trees: 4, samples: 510\n",
      "feat_name: (1110-1125,1410-1425), count_total: 4, num_trees: 4, samples: 484\n",
      "feat_name: (1395-1410,1305-1320), count_total: 4, num_trees: 4, samples: 471\n",
      "feat_name: (15-30,1380-1395), count_total: 4, num_trees: 4, samples: 465\n",
      "feat_name: (855-870,60-75), count_total: 4, num_trees: 4, samples: 441\n",
      "feat_name: (1095-1110,60-75), count_total: 4, num_trees: 4, samples: 440\n",
      "feat_name: (180-195,120-135), count_total: 4, num_trees: 4, samples: 430\n",
      "feat_name: (150-165,1410-1425), count_total: 4, num_trees: 4, samples: 414\n",
      "feat_name: (1065-1080,1410-1425), count_total: 4, num_trees: 4, samples: 400\n",
      "feat_name: (165-180,1410-1425), count_total: 4, num_trees: 4, samples: 396\n",
      "feat_name: (105-120,945-960), count_total: 4, num_trees: 4, samples: 392\n",
      "feat_name: (420-435,75-90), count_total: 4, num_trees: 4, samples: 392\n",
      "feat_name: (630-645,255-270), count_total: 4, num_trees: 4, samples: 388\n",
      "feat_name: (1350-1365,960-975), count_total: 4, num_trees: 4, samples: 384\n",
      "feat_name: (405-420,135-150), count_total: 4, num_trees: 4, samples: 383\n",
      "feat_name: (75-90,105-120), count_total: 4, num_trees: 4, samples: 381\n",
      "feat_name: (285-300,105-120), count_total: 4, num_trees: 4, samples: 370\n",
      "feat_name: (630-645,135-150), count_total: 4, num_trees: 4, samples: 368\n",
      "feat_name: (75-90,1380-1395), count_total: 4, num_trees: 4, samples: 367\n",
      "feat_name: (135-150,1410-1425), count_total: 4, num_trees: 4, samples: 365\n",
      "feat_name: (225-240,60-75), count_total: 4, num_trees: 4, samples: 361\n",
      "feat_name: (1470-1485,510-525), count_total: 4, num_trees: 4, samples: 360\n",
      "feat_name: (60-75,120-135), count_total: 4, num_trees: 4, samples: 354\n",
      "feat_name: (1080-1095,1410-1425), count_total: 4, num_trees: 4, samples: 352\n",
      "feat_name: (360-375,60-75), count_total: 4, num_trees: 4, samples: 343\n",
      "feat_name: (1485-1500,405-420), count_total: 4, num_trees: 4, samples: 332\n",
      "feat_name: (1320-1335,60-75), count_total: 4, num_trees: 4, samples: 330\n",
      "feat_name: (45-60,75-90), count_total: 4, num_trees: 4, samples: 329\n",
      "feat_name: (90-105,900-915), count_total: 4, num_trees: 4, samples: 313\n",
      "feat_name: (855-870,105-120), count_total: 4, num_trees: 4, samples: 310\n",
      "feat_name: (105-120,900-915), count_total: 4, num_trees: 4, samples: 308\n",
      "feat_name: (150-165,105-120), count_total: 4, num_trees: 4, samples: 299\n",
      "feat_name: (30-45,660-675), count_total: 4, num_trees: 4, samples: 299\n",
      "feat_name: (630-645,60-75), count_total: 4, num_trees: 4, samples: 298\n",
      "feat_name: (1200-1215,1410-1425), count_total: 4, num_trees: 4, samples: 297\n",
      "feat_name: (975-990,90-105), count_total: 4, num_trees: 4, samples: 297\n",
      "feat_name: (1140-1155,360-375), count_total: 4, num_trees: 4, samples: 290\n",
      "feat_name: (1455-1470,135-150), count_total: 4, num_trees: 4, samples: 289\n",
      "feat_name: (1335-1350,120-135), count_total: 4, num_trees: 4, samples: 285\n",
      "feat_name: (60-75,900-915), count_total: 4, num_trees: 4, samples: 248\n",
      "feat_name: (1035-1050,1410-1425), count_total: 4, num_trees: 4, samples: 247\n",
      "feat_name: (1350-1365,60-75), count_total: 4, num_trees: 4, samples: 246\n",
      "feat_name: (435-450,1380-1395), count_total: 4, num_trees: 4, samples: 245\n",
      "feat_name: (270-285,1410-1425), count_total: 4, num_trees: 4, samples: 241\n",
      "feat_name: (1440-1455,60-75), count_total: 4, num_trees: 4, samples: 230\n",
      "feat_name: (1065-1080,90-105), count_total: 4, num_trees: 4, samples: 221\n",
      "feat_name: (45-60,60-75), count_total: 4, num_trees: 4, samples: 219\n",
      "feat_name: (90-105,210-225), count_total: 4, num_trees: 4, samples: 216\n",
      "feat_name: (1230-1245,90-105), count_total: 4, num_trees: 4, samples: 211\n",
      "feat_name: (1350-1365,360-375), count_total: 4, num_trees: 4, samples: 205\n",
      "feat_name: (150-165,60-75), count_total: 4, num_trees: 4, samples: 202\n",
      "feat_name: (495-510,75-90), count_total: 4, num_trees: 4, samples: 188\n",
      "feat_name: (1200-1215,60-75), count_total: 4, num_trees: 4, samples: 155\n",
      "feat_name: (195-210,60-75), count_total: 4, num_trees: 4, samples: 153\n",
      "feat_name: (1215-1230,270-285), count_total: 4, num_trees: 4, samples: 150\n",
      "feat_name: (300-315,60-75), count_total: 4, num_trees: 4, samples: 146\n",
      "feat_name: (1170-1185,1380-1395), count_total: 4, num_trees: 4, samples: 146\n",
      "feat_name: (975-990,1410-1425), count_total: 4, num_trees: 4, samples: 144\n",
      "feat_name: (990-1005,60-75), count_total: 4, num_trees: 4, samples: 143\n",
      "feat_name: (75-90,90-105), count_total: 4, num_trees: 4, samples: 134\n",
      "feat_name: (1200-1215,1380-1395), count_total: 4, num_trees: 4, samples: 132\n",
      "feat_name: (1260-1275,75-90), count_total: 4, num_trees: 4, samples: 122\n",
      "feat_name: (1485-1500,120-135), count_total: 4, num_trees: 4, samples: 117\n",
      "feat_name: (1260-1275,1410-1425), count_total: 4, num_trees: 4, samples: 105\n",
      "feat_name: (30-45,60-75), count_total: 4, num_trees: 4, samples: 96\n",
      "feat_name: (1455-1470,75-90), count_total: 4, num_trees: 4, samples: 51\n",
      "feat_name: (1200-1215,75-90), count_total: 4, num_trees: 4, samples: 27\n",
      "feat_name: (1275-1290,90-105), count_total: 4, num_trees: 4, samples: 19\n",
      "feat_name: (0-15,150-165), count_total: 4, num_trees: 4, samples: 16\n",
      "feat_name: (1410-1425,90-105), count_total: 3, num_trees: 3, samples: 413\n",
      "feat_name: (285-300,135-150), count_total: 3, num_trees: 3, samples: 398\n",
      "feat_name: (720-735,90-105), count_total: 3, num_trees: 3, samples: 391\n",
      "feat_name: (1260-1275,60-75), count_total: 3, num_trees: 3, samples: 388\n",
      "feat_name: (1260-1275,1380-1395), count_total: 3, num_trees: 3, samples: 385\n",
      "feat_name: (0-15,345-360), count_total: 3, num_trees: 3, samples: 385\n",
      "feat_name: (285-300,90-105), count_total: 3, num_trees: 3, samples: 376\n",
      "feat_name: (1455-1470,1065-1080), count_total: 3, num_trees: 3, samples: 372\n",
      "feat_name: (300-315,1065-1080), count_total: 3, num_trees: 3, samples: 371\n",
      "feat_name: (15-30,225-240), count_total: 3, num_trees: 3, samples: 370\n",
      "feat_name: (0-15,960-975), count_total: 3, num_trees: 3, samples: 369\n",
      "feat_name: (735-750,90-105), count_total: 3, num_trees: 3, samples: 369\n",
      "feat_name: (195-210,1290-1305), count_total: 3, num_trees: 3, samples: 364\n",
      "feat_name: (1305-1320,1410-1425), count_total: 3, num_trees: 3, samples: 363\n",
      "feat_name: (510-525,945-960), count_total: 3, num_trees: 3, samples: 363\n",
      "feat_name: (60-75,1380-1395), count_total: 3, num_trees: 3, samples: 362\n",
      "feat_name: (555-570,60-75), count_total: 3, num_trees: 3, samples: 358\n",
      "feat_name: (285-300,1290-1305), count_total: 3, num_trees: 3, samples: 354\n",
      "feat_name: (1035-1050,1425-1440), count_total: 3, num_trees: 3, samples: 343\n",
      "feat_name: (1485-1500,225-240), count_total: 3, num_trees: 3, samples: 338\n",
      "feat_name: (1005-1020,1410-1425), count_total: 3, num_trees: 3, samples: 330\n",
      "feat_name: (1095-1110,105-120), count_total: 3, num_trees: 3, samples: 326\n",
      "feat_name: (1425-1440,60-75), count_total: 3, num_trees: 3, samples: 313\n",
      "feat_name: (405-420,90-105), count_total: 3, num_trees: 3, samples: 308\n",
      "feat_name: (1380-1395,135-150), count_total: 3, num_trees: 3, samples: 307\n",
      "feat_name: (1470-1485,480-495), count_total: 3, num_trees: 3, samples: 305\n",
      "feat_name: (135-150,105-120), count_total: 3, num_trees: 3, samples: 301\n",
      "feat_name: (1005-1020,60-75), count_total: 3, num_trees: 3, samples: 294\n",
      "feat_name: (15-30,165-180), count_total: 3, num_trees: 3, samples: 292\n",
      "feat_name: (990-1005,90-105), count_total: 3, num_trees: 3, samples: 287\n",
      "feat_name: (405-420,240-255), count_total: 3, num_trees: 3, samples: 279\n",
      "feat_name: (495-510,90-105), count_total: 3, num_trees: 3, samples: 268\n",
      "feat_name: (270-285,1395-1410), count_total: 3, num_trees: 3, samples: 267\n",
      "feat_name: (135-150,120-135), count_total: 3, num_trees: 3, samples: 266\n",
      "feat_name: (570-585,90-105), count_total: 3, num_trees: 3, samples: 264\n",
      "feat_name: (45-60,1035-1050), count_total: 3, num_trees: 3, samples: 264\n",
      "feat_name: (375-390,1290-1305), count_total: 3, num_trees: 3, samples: 263\n",
      "feat_name: (0-15,105-120), count_total: 5, num_trees: 3, samples: 261\n",
      "feat_name: (1305-1320,60-75), count_total: 3, num_trees: 3, samples: 259\n",
      "feat_name: (1425-1440,1290-1305), count_total: 3, num_trees: 3, samples: 254\n",
      "feat_name: (1260-1275,105-120), count_total: 3, num_trees: 3, samples: 254\n",
      "feat_name: (1485-1500,1320-1335), count_total: 3, num_trees: 3, samples: 248\n",
      "feat_name: (0-15,135-150), count_total: 3, num_trees: 3, samples: 248\n",
      "feat_name: (795-810,465-480), count_total: 3, num_trees: 3, samples: 240\n",
      "feat_name: (825-840,120-135), count_total: 3, num_trees: 3, samples: 230\n",
      "feat_name: (0-15,270-285), count_total: 3, num_trees: 3, samples: 217\n",
      "feat_name: (1425-1440,480-495), count_total: 3, num_trees: 3, samples: 215\n",
      "feat_name: (870-885,105-120), count_total: 3, num_trees: 3, samples: 213\n",
      "feat_name: (1485-1500,270-285), count_total: 3, num_trees: 3, samples: 212\n",
      "feat_name: (480-495,105-120), count_total: 3, num_trees: 3, samples: 211\n",
      "feat_name: (1230-1245,1410-1425), count_total: 3, num_trees: 3, samples: 210\n",
      "feat_name: (15-30,465-480), count_total: 3, num_trees: 3, samples: 208\n",
      "feat_name: (1245-1260,90-105), count_total: 3, num_trees: 3, samples: 207\n",
      "feat_name: (1230-1245,75-90), count_total: 3, num_trees: 3, samples: 206\n",
      "feat_name: (600-615,105-120), count_total: 3, num_trees: 3, samples: 203\n",
      "feat_name: (90-105,1380-1395), count_total: 3, num_trees: 3, samples: 202\n",
      "feat_name: (345-360,60-75), count_total: 3, num_trees: 3, samples: 202\n",
      "feat_name: (105-120,75-90), count_total: 3, num_trees: 3, samples: 199\n",
      "feat_name: (1050-1065,1410-1425), count_total: 3, num_trees: 3, samples: 196\n",
      "feat_name: (240-255,1410-1425), count_total: 3, num_trees: 3, samples: 189\n",
      "feat_name: (180-195,60-75), count_total: 3, num_trees: 3, samples: 169\n",
      "feat_name: (105-120,1290-1305), count_total: 3, num_trees: 3, samples: 167\n",
      "feat_name: (1230-1245,60-75), count_total: 3, num_trees: 3, samples: 153\n",
      "feat_name: (120-135,1290-1305), count_total: 3, num_trees: 3, samples: 145\n",
      "feat_name: (1380-1395,60-75), count_total: 3, num_trees: 3, samples: 144\n",
      "feat_name: (1275-1290,120-135), count_total: 3, num_trees: 3, samples: 139\n",
      "feat_name: (1020-1035,1410-1425), count_total: 3, num_trees: 3, samples: 133\n",
      "feat_name: (1470-1485,105-120), count_total: 3, num_trees: 3, samples: 130\n",
      "feat_name: (735-750,1410-1425), count_total: 3, num_trees: 3, samples: 124\n",
      "feat_name: (15-30,1290-1305), count_total: 3, num_trees: 3, samples: 123\n",
      "feat_name: (165-180,105-120), count_total: 3, num_trees: 3, samples: 123\n",
      "feat_name: (510-525,90-105), count_total: 3, num_trees: 3, samples: 122\n",
      "feat_name: (1260-1275,255-270), count_total: 3, num_trees: 3, samples: 122\n",
      "feat_name: (810-825,120-135), count_total: 3, num_trees: 3, samples: 121\n",
      "feat_name: (105-120,960-975), count_total: 3, num_trees: 3, samples: 120\n",
      "feat_name: (1320-1335,75-90), count_total: 3, num_trees: 3, samples: 118\n",
      "feat_name: (1410-1425,1335-1350), count_total: 3, num_trees: 3, samples: 118\n",
      "feat_name: (1350-1365,120-135), count_total: 3, num_trees: 3, samples: 118\n",
      "feat_name: (930-945,1410-1425), count_total: 3, num_trees: 3, samples: 116\n",
      "feat_name: (90-105,105-120), count_total: 3, num_trees: 3, samples: 110\n",
      "feat_name: (165-180,930-945), count_total: 3, num_trees: 3, samples: 110\n",
      "feat_name: (1005-1020,480-495), count_total: 3, num_trees: 3, samples: 109\n",
      "feat_name: (120-135,105-120), count_total: 3, num_trees: 3, samples: 104\n",
      "feat_name: (1185-1200,120-135), count_total: 3, num_trees: 3, samples: 99\n",
      "feat_name: (345-360,1290-1305), count_total: 3, num_trees: 3, samples: 83\n",
      "feat_name: (960-975,1425-1440), count_total: 3, num_trees: 3, samples: 55\n",
      "feat_name: (1215-1230,60-75), count_total: 3, num_trees: 3, samples: 55\n",
      "feat_name: (45-60,810-825), count_total: 3, num_trees: 3, samples: 40\n",
      "feat_name: (90-105,480-495), count_total: 3, num_trees: 3, samples: 37\n",
      "feat_name: (795-810,285-300), count_total: 3, num_trees: 3, samples: 35\n",
      "feat_name: (630-645,90-105), count_total: 3, num_trees: 3, samples: 34\n",
      "feat_name: (1095-1110,1380-1395), count_total: 3, num_trees: 3, samples: 34\n",
      "feat_name: (1215-1230,1380-1395), count_total: 3, num_trees: 3, samples: 31\n",
      "feat_name: (1260-1275,645-660), count_total: 3, num_trees: 3, samples: 30\n",
      "feat_name: (1380-1395,75-90), count_total: 3, num_trees: 3, samples: 30\n",
      "feat_name: (915-930,270-285), count_total: 3, num_trees: 3, samples: 30\n",
      "feat_name: (315-330,315-330), count_total: 3, num_trees: 3, samples: 27\n",
      "feat_name: (1200-1215,270-285), count_total: 3, num_trees: 3, samples: 24\n",
      "feat_name: (810-825,90-105), count_total: 3, num_trees: 3, samples: 23\n",
      "feat_name: (1485-1500,930-945), count_total: 3, num_trees: 3, samples: 20\n",
      "feat_name: (1185-1200,90-105), count_total: 3, num_trees: 3, samples: 20\n",
      "feat_name: (1080-1095,75-90), count_total: 3, num_trees: 3, samples: 18\n",
      "feat_name: (15-30,105-120), count_total: 3, num_trees: 3, samples: 18\n",
      "feat_name: (15-30,60-75), count_total: 3, num_trees: 3, samples: 17\n",
      "feat_name: (870-885,1410-1425), count_total: 3, num_trees: 3, samples: 16\n",
      "feat_name: (30-45,135-150), count_total: 3, num_trees: 3, samples: 15\n",
      "feat_name: (360-375,1410-1425), count_total: 3, num_trees: 3, samples: 10\n",
      "feat_name: (1155-1170,1410-1425), count_total: 2, num_trees: 2, samples: 571\n",
      "feat_name: (1380-1395,105-120), count_total: 2, num_trees: 2, samples: 353\n",
      "feat_name: (1440-1455,105-120), count_total: 2, num_trees: 2, samples: 346\n",
      "feat_name: (990-1005,1425-1440), count_total: 2, num_trees: 2, samples: 322\n",
      "feat_name: (1080-1095,1425-1440), count_total: 2, num_trees: 2, samples: 311\n",
      "feat_name: (60-75,930-945), count_total: 2, num_trees: 2, samples: 293\n",
      "feat_name: (1200-1215,1425-1440), count_total: 2, num_trees: 2, samples: 279\n",
      "feat_name: (1485-1500,1500-1515), count_total: 2, num_trees: 2, samples: 265\n",
      "feat_name: (780-795,1110-1125), count_total: 2, num_trees: 2, samples: 260\n",
      "feat_name: (0-15,615-630), count_total: 2, num_trees: 2, samples: 259\n",
      "feat_name: (375-390,720-735), count_total: 2, num_trees: 2, samples: 259\n",
      "feat_name: (1485-1500,450-465), count_total: 2, num_trees: 2, samples: 257\n",
      "feat_name: (1035-1050,135-150), count_total: 2, num_trees: 2, samples: 257\n",
      "feat_name: (165-180,1245-1260), count_total: 2, num_trees: 2, samples: 256\n",
      "feat_name: (225-240,825-840), count_total: 2, num_trees: 2, samples: 252\n",
      "feat_name: (195-210,900-915), count_total: 2, num_trees: 2, samples: 252\n",
      "feat_name: (270-285,1290-1305), count_total: 2, num_trees: 2, samples: 251\n",
      "feat_name: (1440-1455,1290-1305), count_total: 2, num_trees: 2, samples: 251\n",
      "feat_name: (0-15,1485-1500), count_total: 2, num_trees: 2, samples: 250\n",
      "feat_name: (960-975,1410-1425), count_total: 2, num_trees: 2, samples: 249\n",
      "feat_name: (1485-1500,555-570), count_total: 2, num_trees: 2, samples: 249\n",
      "feat_name: (840-855,1410-1425), count_total: 2, num_trees: 2, samples: 248\n",
      "feat_name: (45-60,945-960), count_total: 2, num_trees: 2, samples: 247\n",
      "feat_name: (1080-1095,165-180), count_total: 2, num_trees: 2, samples: 247\n",
      "feat_name: (1320-1335,1410-1425), count_total: 2, num_trees: 2, samples: 246\n",
      "feat_name: (45-60,900-915), count_total: 2, num_trees: 2, samples: 245\n",
      "feat_name: (1365-1380,1380-1395), count_total: 2, num_trees: 2, samples: 243\n",
      "feat_name: (30-45,285-300), count_total: 2, num_trees: 2, samples: 242\n",
      "feat_name: (990-1005,1410-1425), count_total: 2, num_trees: 2, samples: 239\n",
      "feat_name: (180-195,1305-1320), count_total: 2, num_trees: 2, samples: 239\n",
      "feat_name: (390-405,930-945), count_total: 2, num_trees: 2, samples: 239\n",
      "feat_name: (300-315,510-525), count_total: 2, num_trees: 2, samples: 239\n",
      "feat_name: (420-435,195-210), count_total: 2, num_trees: 2, samples: 238\n",
      "feat_name: (390-405,135-150), count_total: 2, num_trees: 2, samples: 236\n",
      "feat_name: (0-15,405-420), count_total: 2, num_trees: 2, samples: 236\n",
      "feat_name: (285-300,240-255), count_total: 2, num_trees: 2, samples: 233\n",
      "feat_name: (1095-1110,1050-1065), count_total: 2, num_trees: 2, samples: 231\n",
      "feat_name: (600-615,120-135), count_total: 2, num_trees: 2, samples: 231\n",
      "feat_name: (480-495,1380-1395), count_total: 2, num_trees: 2, samples: 228\n",
      "feat_name: (1485-1500,795-810), count_total: 2, num_trees: 2, samples: 227\n",
      "feat_name: (270-285,105-120), count_total: 2, num_trees: 2, samples: 223\n",
      "feat_name: (615-630,135-150), count_total: 2, num_trees: 2, samples: 222\n",
      "feat_name: (1410-1425,390-405), count_total: 2, num_trees: 2, samples: 219\n",
      "feat_name: (1395-1410,480-495), count_total: 2, num_trees: 2, samples: 218\n",
      "feat_name: (150-165,120-135), count_total: 2, num_trees: 2, samples: 216\n",
      "feat_name: (1470-1485,435-450), count_total: 2, num_trees: 2, samples: 215\n",
      "feat_name: (180-195,135-150), count_total: 2, num_trees: 2, samples: 214\n",
      "feat_name: (285-300,60-75), count_total: 2, num_trees: 2, samples: 213\n",
      "feat_name: (1410-1425,135-150), count_total: 2, num_trees: 2, samples: 211\n",
      "feat_name: (870-885,450-465), count_total: 2, num_trees: 2, samples: 211\n",
      "feat_name: (135-150,885-900), count_total: 2, num_trees: 2, samples: 211\n",
      "feat_name: (495-510,105-120), count_total: 2, num_trees: 2, samples: 209\n",
      "feat_name: (990-1005,135-150), count_total: 2, num_trees: 2, samples: 208\n",
      "feat_name: (825-840,735-750), count_total: 2, num_trees: 2, samples: 208\n",
      "feat_name: (1380-1395,495-510), count_total: 2, num_trees: 2, samples: 207\n",
      "feat_name: (90-105,885-900), count_total: 2, num_trees: 2, samples: 206\n",
      "feat_name: (1455-1470,435-450), count_total: 2, num_trees: 2, samples: 202\n",
      "feat_name: (735-750,270-285), count_total: 2, num_trees: 2, samples: 202\n",
      "feat_name: (705-720,90-105), count_total: 2, num_trees: 2, samples: 202\n",
      "feat_name: (45-60,720-735), count_total: 2, num_trees: 2, samples: 201\n",
      "feat_name: (1230-1245,105-120), count_total: 2, num_trees: 2, samples: 201\n",
      "feat_name: (0-15,900-915), count_total: 2, num_trees: 2, samples: 201\n",
      "feat_name: (195-210,1410-1425), count_total: 2, num_trees: 2, samples: 200\n",
      "feat_name: (1440-1455,135-150), count_total: 2, num_trees: 2, samples: 199\n",
      "feat_name: (0-15,945-960), count_total: 2, num_trees: 2, samples: 196\n",
      "feat_name: (975-990,135-150), count_total: 2, num_trees: 2, samples: 196\n",
      "feat_name: (675-690,135-150), count_total: 2, num_trees: 2, samples: 193\n",
      "feat_name: (45-60,675-690), count_total: 2, num_trees: 2, samples: 193\n",
      "feat_name: (60-75,1155-1170), count_total: 2, num_trees: 2, samples: 192\n",
      "feat_name: (615-630,105-120), count_total: 2, num_trees: 2, samples: 190\n",
      "feat_name: (1200-1215,120-135), count_total: 2, num_trees: 2, samples: 189\n",
      "feat_name: (660-675,720-735), count_total: 2, num_trees: 2, samples: 188\n",
      "feat_name: (405-420,75-90), count_total: 2, num_trees: 2, samples: 188\n",
      "feat_name: (375-390,90-105), count_total: 2, num_trees: 2, samples: 188\n",
      "feat_name: (585-600,750-765), count_total: 2, num_trees: 2, samples: 188\n",
      "feat_name: (1425-1440,1305-1320), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (1470-1485,525-540), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (1485-1500,510-525), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (450-465,60-75), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (645-660,1095-1110), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (1485-1500,315-330), count_total: 2, num_trees: 2, samples: 186\n",
      "feat_name: (75-90,735-750), count_total: 2, num_trees: 2, samples: 185\n",
      "feat_name: (300-315,105-120), count_total: 2, num_trees: 2, samples: 185\n",
      "feat_name: (1485-1500,1350-1365), count_total: 2, num_trees: 2, samples: 182\n",
      "feat_name: (885-900,60-75), count_total: 2, num_trees: 2, samples: 180\n",
      "feat_name: (165-180,75-90), count_total: 2, num_trees: 2, samples: 179\n",
      "feat_name: (210-225,135-150), count_total: 2, num_trees: 2, samples: 176\n",
      "feat_name: (360-375,75-90), count_total: 2, num_trees: 2, samples: 172\n",
      "feat_name: (1005-1020,1425-1440), count_total: 2, num_trees: 2, samples: 170\n",
      "feat_name: (15-30,75-90), count_total: 2, num_trees: 2, samples: 168\n",
      "feat_name: (15-30,1275-1290), count_total: 2, num_trees: 2, samples: 152\n",
      "feat_name: (585-600,960-975), count_total: 2, num_trees: 2, samples: 143\n",
      "feat_name: (510-525,60-75), count_total: 2, num_trees: 2, samples: 141\n",
      "feat_name: (255-270,1410-1425), count_total: 2, num_trees: 2, samples: 138\n",
      "feat_name: (90-105,705-720), count_total: 2, num_trees: 2, samples: 138\n",
      "feat_name: (75-90,900-915), count_total: 2, num_trees: 2, samples: 138\n",
      "feat_name: (660-675,1410-1425), count_total: 2, num_trees: 2, samples: 137\n",
      "feat_name: (105-120,720-735), count_total: 2, num_trees: 2, samples: 137\n",
      "feat_name: (75-90,480-495), count_total: 2, num_trees: 2, samples: 137\n",
      "feat_name: (255-270,90-105), count_total: 2, num_trees: 2, samples: 135\n",
      "feat_name: (90-105,75-90), count_total: 2, num_trees: 2, samples: 133\n",
      "feat_name: (0-15,660-675), count_total: 2, num_trees: 2, samples: 132\n",
      "feat_name: (30-45,900-915), count_total: 2, num_trees: 2, samples: 132\n",
      "feat_name: (420-435,105-120), count_total: 2, num_trees: 2, samples: 132\n",
      "feat_name: (150-165,75-90), count_total: 2, num_trees: 2, samples: 131\n",
      "feat_name: (870-885,90-105), count_total: 2, num_trees: 2, samples: 131\n",
      "feat_name: (1005-1020,120-135), count_total: 2, num_trees: 2, samples: 130\n",
      "feat_name: (375-390,135-150), count_total: 2, num_trees: 2, samples: 129\n",
      "feat_name: (810-825,1410-1425), count_total: 2, num_trees: 2, samples: 127\n",
      "feat_name: (210-225,540-555), count_total: 2, num_trees: 2, samples: 127\n",
      "feat_name: (195-210,1380-1395), count_total: 2, num_trees: 2, samples: 126\n",
      "feat_name: (525-540,1410-1425), count_total: 2, num_trees: 2, samples: 125\n",
      "feat_name: (1485-1500,390-405), count_total: 2, num_trees: 2, samples: 123\n",
      "feat_name: (105-120,1380-1395), count_total: 2, num_trees: 2, samples: 119\n",
      "feat_name: (270-285,240-255), count_total: 2, num_trees: 2, samples: 119\n",
      "feat_name: (1350-1365,270-285), count_total: 2, num_trees: 2, samples: 118\n",
      "feat_name: (1455-1470,270-285), count_total: 2, num_trees: 2, samples: 118\n",
      "feat_name: (15-30,195-210), count_total: 2, num_trees: 2, samples: 116\n",
      "feat_name: (1065-1080,75-90), count_total: 2, num_trees: 2, samples: 115\n",
      "feat_name: (60-75,105-120), count_total: 2, num_trees: 2, samples: 114\n",
      "feat_name: (1155-1170,105-120), count_total: 2, num_trees: 2, samples: 114\n",
      "feat_name: (1440-1455,1350-1365), count_total: 2, num_trees: 2, samples: 114\n",
      "feat_name: (1485-1500,735-750), count_total: 2, num_trees: 2, samples: 114\n",
      "feat_name: (30-45,1185-1200), count_total: 2, num_trees: 2, samples: 113\n",
      "feat_name: (645-660,1335-1350), count_total: 2, num_trees: 2, samples: 113\n",
      "feat_name: (645-660,720-735), count_total: 2, num_trees: 2, samples: 113\n",
      "feat_name: (1425-1440,945-960), count_total: 2, num_trees: 2, samples: 113\n",
      "feat_name: (60-75,60-75), count_total: 2, num_trees: 2, samples: 113\n",
      "feat_name: (780-795,1410-1425), count_total: 2, num_trees: 2, samples: 112\n",
      "feat_name: (900-915,1410-1425), count_total: 2, num_trees: 2, samples: 112\n",
      "feat_name: (750-765,75-90), count_total: 2, num_trees: 2, samples: 112\n",
      "feat_name: (1290-1305,120-135), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (1080-1095,105-120), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (1440-1455,720-735), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (750-765,1410-1425), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (600-615,60-75), count_total: 2, num_trees: 2, samples: 108\n",
      "feat_name: (150-165,1380-1395), count_total: 2, num_trees: 2, samples: 107\n",
      "feat_name: (1380-1395,945-960), count_total: 2, num_trees: 2, samples: 107\n",
      "feat_name: (1455-1470,495-510), count_total: 2, num_trees: 2, samples: 106\n",
      "feat_name: (495-510,60-75), count_total: 2, num_trees: 2, samples: 104\n",
      "feat_name: (180-195,105-120), count_total: 2, num_trees: 2, samples: 103\n",
      "feat_name: (1350-1365,930-945), count_total: 2, num_trees: 2, samples: 103\n",
      "feat_name: (330-345,60-75), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (210-225,945-960), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (30-45,90-105), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (285-300,1380-1395), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (720-735,210-225), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (90-105,465-480), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (1215-1230,90-105), count_total: 2, num_trees: 2, samples: 99\n",
      "feat_name: (1305-1320,255-270), count_total: 2, num_trees: 2, samples: 99\n",
      "feat_name: (1215-1230,195-210), count_total: 2, num_trees: 2, samples: 98\n",
      "feat_name: (1365-1380,480-495), count_total: 2, num_trees: 2, samples: 98\n",
      "feat_name: (435-450,120-135), count_total: 2, num_trees: 2, samples: 98\n",
      "feat_name: (1485-1500,1050-1065), count_total: 2, num_trees: 2, samples: 98\n",
      "feat_name: (930-945,195-210), count_total: 2, num_trees: 2, samples: 98\n",
      "feat_name: (1470-1485,255-270), count_total: 2, num_trees: 2, samples: 95\n",
      "feat_name: (1455-1470,120-135), count_total: 2, num_trees: 2, samples: 94\n",
      "feat_name: (885-900,300-315), count_total: 2, num_trees: 2, samples: 90\n",
      "feat_name: (105-120,105-120), count_total: 2, num_trees: 2, samples: 89\n",
      "feat_name: (300-315,90-105), count_total: 2, num_trees: 2, samples: 88\n",
      "feat_name: (330-345,1410-1425), count_total: 2, num_trees: 2, samples: 88\n",
      "feat_name: (1155-1170,480-495), count_total: 2, num_trees: 2, samples: 87\n",
      "feat_name: (1395-1410,225-240), count_total: 2, num_trees: 2, samples: 86\n",
      "feat_name: (240-255,135-150), count_total: 2, num_trees: 2, samples: 73\n",
      "feat_name: (75-90,60-75), count_total: 2, num_trees: 2, samples: 66\n",
      "feat_name: (1050-1065,60-75), count_total: 2, num_trees: 2, samples: 63\n",
      "feat_name: (1470-1485,270-285), count_total: 2, num_trees: 2, samples: 55\n",
      "feat_name: (1245-1260,270-285), count_total: 2, num_trees: 2, samples: 51\n",
      "feat_name: (870-885,1425-1440), count_total: 2, num_trees: 2, samples: 48\n",
      "feat_name: (30-45,165-180), count_total: 2, num_trees: 2, samples: 39\n",
      "feat_name: (1365-1380,270-285), count_total: 2, num_trees: 2, samples: 36\n",
      "feat_name: (660-675,495-510), count_total: 2, num_trees: 2, samples: 34\n",
      "feat_name: (1080-1095,1020-1035), count_total: 2, num_trees: 2, samples: 33\n",
      "feat_name: (915-930,360-375), count_total: 2, num_trees: 2, samples: 30\n",
      "feat_name: (165-180,405-420), count_total: 2, num_trees: 2, samples: 30\n",
      "feat_name: (660-675,90-105), count_total: 2, num_trees: 2, samples: 28\n",
      "feat_name: (1290-1305,1380-1395), count_total: 2, num_trees: 2, samples: 27\n",
      "feat_name: (450-465,975-990), count_total: 2, num_trees: 2, samples: 26\n",
      "feat_name: (1215-1230,75-90), count_total: 2, num_trees: 2, samples: 25\n",
      "feat_name: (1470-1485,120-135), count_total: 2, num_trees: 2, samples: 24\n",
      "feat_name: (345-360,1380-1395), count_total: 2, num_trees: 2, samples: 24\n",
      "feat_name: (945-960,555-570), count_total: 2, num_trees: 2, samples: 24\n",
      "feat_name: (1290-1305,90-105), count_total: 2, num_trees: 2, samples: 24\n",
      "feat_name: (1395-1410,120-135), count_total: 2, num_trees: 2, samples: 24\n",
      "feat_name: (1050-1065,240-255), count_total: 2, num_trees: 2, samples: 23\n",
      "feat_name: (945-960,615-630), count_total: 2, num_trees: 2, samples: 23\n",
      "feat_name: (1035-1050,1380-1395), count_total: 2, num_trees: 2, samples: 21\n",
      "feat_name: (1185-1200,75-90), count_total: 2, num_trees: 2, samples: 19\n",
      "feat_name: (90-105,90-105), count_total: 2, num_trees: 2, samples: 19\n",
      "feat_name: (30-45,1380-1395), count_total: 2, num_trees: 2, samples: 17\n",
      "feat_name: (1140-1155,105-120), count_total: 2, num_trees: 2, samples: 17\n",
      "feat_name: (1470-1485,825-840), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (150-165,885-900), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (1170-1185,75-90), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (885-900,945-960), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (585-600,60-75), count_total: 2, num_trees: 2, samples: 15\n",
      "feat_name: (105-120,330-345), count_total: 2, num_trees: 2, samples: 15\n",
      "feat_name: (750-765,90-105), count_total: 2, num_trees: 2, samples: 14\n",
      "feat_name: (1230-1245,1050-1065), count_total: 2, num_trees: 2, samples: 14\n",
      "feat_name: (1095-1110,75-90), count_total: 2, num_trees: 2, samples: 13\n",
      "feat_name: (1020-1035,270-285), count_total: 2, num_trees: 2, samples: 13\n",
      "feat_name: (1485-1500,435-450), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (1155-1170,75-90), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (900-915,1425-1440), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (795-810,1410-1425), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (750-765,120-135), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (225-240,75-90), count_total: 2, num_trees: 2, samples: 11\n",
      "feat_name: (75-90,1080-1095), count_total: 2, num_trees: 2, samples: 11\n",
      "feat_name: (195-210,90-105), count_total: 2, num_trees: 2, samples: 10\n",
      "feat_name: (1215-1230,360-375), count_total: 2, num_trees: 2, samples: 10\n",
      "feat_name: (825-840,105-120), count_total: 2, num_trees: 2, samples: 9\n",
      "feat_name: (1425-1440,1380-1395), count_total: 2, num_trees: 2, samples: 9\n",
      "feat_name: (15-30,720-735), count_total: 2, num_trees: 2, samples: 8\n",
      "feat_name: (480-495,945-960), count_total: 2, num_trees: 2, samples: 8\n",
      "feat_name: (585-600,975-990), count_total: 2, num_trees: 2, samples: 8\n",
      "feat_name: (1350-1365,240-255), count_total: 2, num_trees: 2, samples: 8\n",
      "feat_name: (735-750,150-165), count_total: 2, num_trees: 2, samples: 8\n",
      "feat_name: (1350-1365,1380-1395), count_total: 2, num_trees: 2, samples: 8\n",
      "feat_name: (90-105,1125-1140), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (1455-1470,960-975), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (435-450,495-510), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (30-45,105-120), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (1065-1080,105-120), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (105-120,915-930), count_total: 2, num_trees: 2, samples: 6\n",
      "feat_name: (900-915,90-105), count_total: 2, num_trees: 2, samples: 6\n",
      "feat_name: (120-135,210-225), count_total: 2, num_trees: 2, samples: 6\n",
      "feat_name: (1305-1320,105-120), count_total: 2, num_trees: 2, samples: 5\n",
      "feat_name: (1215-1230,1425-1440), count_total: 1, num_trees: 1, samples: 153\n",
      "feat_name: (1125-1140,1425-1440), count_total: 1, num_trees: 1, samples: 149\n",
      "feat_name: (1260-1275,885-900), count_total: 1, num_trees: 1, samples: 147\n",
      "feat_name: (825-840,60-75), count_total: 1, num_trees: 1, samples: 146\n",
      "feat_name: (1140-1155,765-780), count_total: 1, num_trees: 1, samples: 145\n",
      "feat_name: (420-435,450-465), count_total: 1, num_trees: 1, samples: 144\n",
      "feat_name: (315-330,930-945), count_total: 1, num_trees: 1, samples: 144\n",
      "feat_name: (0-15,180-195), count_total: 1, num_trees: 1, samples: 143\n",
      "feat_name: (555-570,120-135), count_total: 1, num_trees: 1, samples: 141\n",
      "feat_name: (315-330,120-135), count_total: 1, num_trees: 1, samples: 139\n",
      "feat_name: (645-660,1410-1425), count_total: 1, num_trees: 1, samples: 139\n",
      "feat_name: (15-30,285-300), count_total: 1, num_trees: 1, samples: 138\n",
      "feat_name: (1410-1425,1290-1305), count_total: 1, num_trees: 1, samples: 138\n",
      "feat_name: (120-135,900-915), count_total: 1, num_trees: 1, samples: 133\n",
      "feat_name: (585-600,480-495), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (1005-1020,330-345), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (285-300,1065-1080), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (90-105,1095-1110), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (90-105,1140-1155), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (810-825,345-360), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (420-435,360-375), count_total: 1, num_trees: 1, samples: 130\n",
      "feat_name: (1440-1455,675-690), count_total: 1, num_trees: 1, samples: 130\n",
      "feat_name: (1125-1140,1065-1080), count_total: 1, num_trees: 1, samples: 130\n",
      "feat_name: (900-915,1290-1305), count_total: 1, num_trees: 1, samples: 130\n",
      "feat_name: (720-735,735-750), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (1260-1275,990-1005), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (375-390,735-750), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (270-285,135-150), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (1260-1275,225-240), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (450-465,330-345), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (735-750,180-195), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (390-405,750-765), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (150-165,45-60), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (345-360,1410-1425), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (975-990,225-240), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (300-315,1485-1500), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (570-585,135-150), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (585-600,90-105), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (705-720,1050-1065), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (210-225,900-915), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (390-405,1290-1305), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (390-405,345-360), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (180-195,900-915), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (450-465,255-270), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (240-255,1290-1305), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (930-945,150-165), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (120-135,90-105), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (420-435,405-420), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (1485-1500,960-975), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (15-30,1095-1110), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (705-720,465-480), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (45-60,930-945), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (1395-1410,870-885), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (15-30,705-720), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (30-45,150-165), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (30-45,1485-1500), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (15-30,330-345), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (885-900,1410-1425), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (30-45,735-750), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (210-225,1065-1080), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (510-525,1410-1425), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (1125-1140,660-675), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (1470-1485,420-435), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (345-360,105-120), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (330-345,1200-1215), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (135-150,930-945), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (90-105,1170-1185), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (885-900,1335-1350), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (1455-1470,675-690), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (465-480,1365-1380), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (1470-1485,465-480), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (0-15,720-735), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (375-390,1485-1500), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (75-90,1485-1500), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (1395-1410,1260-1275), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (135-150,1245-1260), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (1215-1230,255-270), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (1410-1425,420-435), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (780-795,285-300), count_total: 1, num_trees: 1, samples: 121\n",
      "feat_name: (210-225,960-975), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (45-60,585-600), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (1110-1125,345-360), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (330-345,255-270), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (1260-1275,660-675), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (720-735,165-180), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (330-345,105-120), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (15-30,495-510), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (150-165,645-660), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (120-135,945-960), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (90-105,690-705), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (975-990,165-180), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (1275-1290,930-945), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (225-240,1410-1425), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (915-930,210-225), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (615-630,435-450), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (360-375,390-405), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (195-210,435-450), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (1065-1080,210-225), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (645-660,465-480), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (1290-1305,270-285), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (1485-1500,975-990), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (390-405,1305-1320), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (405-420,540-555), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (1455-1470,705-720), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (225-240,735-750), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (360-375,930-945), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (450-465,120-135), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (660-675,105-120), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (0-15,570-585), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1470-1485,915-930), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1290-1305,495-510), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (780-795,1245-1260), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (450-465,1425-1440), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (720-735,780-795), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (285-300,1485-1500), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1395-1410,270-285), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1110-1125,990-1005), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1125-1140,540-555), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1020-1035,315-330), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (210-225,915-930), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (765-780,375-390), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (195-210,915-930), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (255-270,510-525), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (1050-1065,1290-1305), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (645-660,105-120), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (15-30,945-960), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (165-180,780-795), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (105-120,1305-1320), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (1020-1035,1020-1035), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (195-210,120-135), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (270-285,1485-1500), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (510-525,270-285), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (90-105,450-465), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (1275-1290,105-120), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (405-420,1155-1170), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (375-390,45-60), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (180-195,885-900), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (375-390,120-135), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (300-315,930-945), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (30-45,885-900), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (30-45,930-945), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (180-195,945-960), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (285-300,1410-1425), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (1455-1470,915-930), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (465-480,75-90), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (690-705,105-120), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (885-900,285-300), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (1440-1455,705-720), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (390-405,285-300), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (105-120,225-240), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (1440-1455,945-960), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (765-780,150-165), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (1425-1440,360-375), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (975-990,270-285), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (765-780,165-180), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (810-825,1290-1305), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (360-375,1290-1305), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (690-705,90-105), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (315-330,990-1005), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (255-270,720-735), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1350-1365,135-150), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1125-1140,210-225), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (390-405,540-555), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (930-945,360-375), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (960-975,420-435), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1185-1200,105-120), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (225-240,1080-1095), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1470-1485,960-975), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (885-900,1380-1395), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (1005-1020,930-945), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (765-780,1410-1425), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (210-225,210-225), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (450-465,915-930), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (330-345,930-945), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (825-840,375-390), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (1215-1230,315-330), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (75-90,675-690), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (1125-1140,900-915), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (900-915,615-630), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (165-180,1260-1275), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (1395-1410,240-255), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (675-690,495-510), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (1365-1380,465-480), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (1380-1395,960-975), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (120-135,930-945), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (1470-1485,390-405), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (840-855,1425-1440), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (960-975,960-975), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (1335-1350,240-255), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (60-75,915-930), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (420-435,1290-1305), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (855-870,435-450), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (180-195,1380-1395), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (15-30,405-420), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (210-225,1050-1065), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (1410-1425,1395-1410), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (1050-1065,255-270), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (1125-1140,615-630), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (105-120,885-900), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (1470-1485,1365-1380), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (420-435,90-105), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (75-90,1275-1290), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (1395-1410,465-480), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (900-915,60-75), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (1335-1350,300-315), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (1365-1380,195-210), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (840-855,105-120), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (1335-1350,1320-1335), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1410-1425,945-960), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (795-810,1425-1440), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (900-915,495-510), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1080-1095,255-270), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (630-645,180-195), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (405-420,420-435), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (930-945,90-105), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1440-1455,930-945), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (45-60,690-705), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1470-1485,615-630), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (165-180,840-855), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (90-105,720-735), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (930-945,270-285), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (225-240,720-735), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (675-690,1290-1305), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (195-210,480-495), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (1395-1410,1320-1335), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (1485-1500,1275-1290), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1200-1215,105-120), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1200-1215,165-180), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (975-990,1425-1440), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (915-930,255-270), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (960-975,60-75), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1245-1260,330-345), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (660-675,330-345), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1365-1380,945-960), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (825-840,75-90), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1455-1470,1335-1350), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (345-360,945-960), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (435-450,255-270), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (885-900,120-135), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (240-255,75-90), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1275-1290,1320-1335), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1095-1110,240-255), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (900-915,390-405), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (465-480,450-465), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1425-1440,1395-1410), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (240-255,315-330), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (105-120,150-165), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (405-420,150-165), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1440-1455,360-375), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (450-465,735-750), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (615-630,420-435), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1380-1395,225-240), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1110-1125,1110-1125), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (345-360,90-105), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1290-1305,225-240), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (1485-1500,1365-1380), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (765-780,105-120), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (285-300,585-600), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (210-225,1410-1425), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (1275-1290,795-810), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (90-105,735-750), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (1170-1185,255-270), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (705-720,75-90), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (1110-1125,1005-1020), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (1065-1080,375-390), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (60-75,45-60), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (450-465,135-150), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (270-285,1245-1260), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (225-240,285-300), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (1035-1050,255-270), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (1395-1410,1350-1365), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (825-840,360-375), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (870-885,315-330), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (90-105,300-315), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (960-975,105-120), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (585-600,930-945), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (1425-1440,330-345), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (900-915,285-300), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (1275-1290,600-615), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (240-255,90-105), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (630-645,585-600), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (195-210,945-960), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (390-405,60-75), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (720-735,1185-1200), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (285-300,435-450), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (1305-1320,885-900), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (1110-1125,135-150), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (240-255,105-120), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (960-975,135-150), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (750-765,960-975), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (75-90,225-240), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (1470-1485,840-855), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (810-825,315-330), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (1380-1395,480-495), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (75-90,645-660), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (1455-1470,480-495), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (315-330,75-90), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (1050-1065,840-855), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (1395-1410,75-90), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (30-45,1065-1080), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (345-360,285-300), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (225-240,270-285), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (0-15,300-315), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (1005-1020,90-105), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (780-795,90-105), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (735-750,165-180), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (30-45,420-435), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (315-330,690-705), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1365-1380,795-810), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1155-1170,540-555), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1410-1425,885-900), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (675-690,105-120), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (330-345,660-675), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1395-1410,420-435), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (255-270,900-915), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1425-1440,960-975), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (660-675,735-750), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1425-1440,270-285), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (375-390,60-75), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (495-510,900-915), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (420-435,120-135), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1080-1095,150-165), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (60-75,510-525), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (435-450,300-315), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (180-195,90-105), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (390-405,150-165), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (30-45,510-525), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (1080-1095,1050-1065), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (690-705,975-990), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (735-750,915-930), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (990-1005,465-480), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (150-165,705-720), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (30-45,240-255), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (1395-1410,900-915), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (780-795,105-120), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1095-1110,330-345), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (300-315,1410-1425), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (165-180,120-135), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (855-870,915-930), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (525-540,120-135), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1065-1080,660-675), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (780-795,675-690), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1425-1440,1350-1365), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (705-720,330-345), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1275-1290,555-570), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (90-105,660-675), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (45-60,630-645), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (165-180,1110-1125), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1305-1320,360-375), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (570-585,105-120), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (690-705,135-150), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (825-840,225-240), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (90-105,1080-1095), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1230-1245,375-390), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (240-255,360-375), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1035-1050,645-660), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (465-480,165-180), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (135-150,375-390), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (495-510,915-930), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (795-810,345-360), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (135-150,525-540), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1395-1410,255-270), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1335-1350,135-150), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1365-1380,120-135), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1470-1485,1320-1335), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1185-1200,675-690), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (645-660,1185-1200), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (405-420,435-450), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (885-900,105-120), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1425-1440,705-720), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1200-1215,315-330), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1485-1500,195-210), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (945-960,660-675), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (975-990,150-165), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (45-60,855-870), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (375-390,150-165), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (855-870,1380-1395), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (315-330,255-270), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (405-420,330-345), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (270-285,990-1005), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1095-1110,210-225), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (585-600,900-915), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1425-1440,885-900), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (855-870,930-945), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (615-630,720-735), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1230-1245,390-405), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1410-1425,225-240), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1440-1455,450-465), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1380-1395,435-450), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1140-1155,210-225), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (90-105,435-450), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1350-1365,465-480), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (960-975,285-300), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1455-1470,360-375), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (165-180,1125-1140), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (645-660,180-195), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (435-450,1395-1410), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1455-1470,1050-1065), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1425-1440,870-885), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (165-180,675-690), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (60-75,675-690), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (960-975,975-990), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1170-1185,1035-1050), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (975-990,345-360), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (225-240,465-480), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (15-30,1230-1245), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (195-210,135-150), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (660-675,1290-1305), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (525-540,840-855), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (135-150,90-105), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (360-375,1365-1380), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (990-1005,270-285), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1050-1065,795-810), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1380-1395,615-630), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (75-90,720-735), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (0-15,630-645), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (345-360,75-90), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (855-870,705-720), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (990-1005,930-945), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (990-1005,450-465), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (1050-1065,270-285), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (120-135,495-510), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (990-1005,120-135), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (840-855,330-345), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (1185-1200,255-270), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (1440-1455,495-510), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (105-120,480-495), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (210-225,480-495), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (105-120,750-765), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (1470-1485,330-345), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (915-930,225-240), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (180-195,465-480), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (75-90,750-765), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (105-120,1065-1080), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (105-120,285-300), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (60-75,1230-1245), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (255-270,60-75), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (1425-1440,1335-1350), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (1425-1440,465-480), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (270-285,195-210), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (420-435,1065-1080), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (915-930,840-855), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (750-765,105-120), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (615-630,75-90), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (105-120,210-225), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (1005-1020,825-840), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (255-270,45-60), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (420-435,1410-1425), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (225-240,480-495), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (1260-1275,330-345), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (1455-1470,390-405), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (615-630,120-135), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (30-45,780-795), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (915-930,300-315), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (135-150,1170-1185), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (60-75,795-810), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (15-30,690-705), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (435-450,1140-1155), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (90-105,135-150), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (675-690,75-90), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1275-1290,1005-1020), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (75-90,165-180), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1335-1350,225-240), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (555-570,930-945), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1410-1425,270-285), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (45-60,435-450), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (375-390,105-120), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1200-1215,135-150), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (165-180,300-315), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1065-1080,285-300), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1395-1410,975-990), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (1380-1395,870-885), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (630-645,75-90), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (1005-1020,270-285), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (465-480,720-735), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (660-675,615-630), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (15-30,810-825), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (915-930,60-75), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (165-180,1080-1095), count_total: 1, num_trees: 1, samples: 79\n",
      "feat_name: (315-330,1035-1050), count_total: 1, num_trees: 1, samples: 78\n",
      "feat_name: (885-900,645-660), count_total: 1, num_trees: 1, samples: 77\n",
      "feat_name: (135-150,150-165), count_total: 1, num_trees: 1, samples: 76\n",
      "feat_name: (150-165,600-615), count_total: 1, num_trees: 1, samples: 75\n",
      "feat_name: (540-555,120-135), count_total: 1, num_trees: 1, samples: 74\n",
      "feat_name: (165-180,1305-1320), count_total: 1, num_trees: 1, samples: 73\n",
      "feat_name: (780-795,1320-1335), count_total: 1, num_trees: 1, samples: 72\n",
      "feat_name: (795-810,150-165), count_total: 1, num_trees: 1, samples: 70\n",
      "feat_name: (405-420,1410-1425), count_total: 1, num_trees: 1, samples: 69\n",
      "feat_name: (1170-1185,360-375), count_total: 1, num_trees: 1, samples: 43\n",
      "feat_name: (270-285,60-75), count_total: 1, num_trees: 1, samples: 37\n",
      "feat_name: (600-615,225-240), count_total: 1, num_trees: 1, samples: 36\n",
      "feat_name: (705-720,810-825), count_total: 1, num_trees: 1, samples: 35\n",
      "feat_name: (1320-1335,120-135), count_total: 1, num_trees: 1, samples: 35\n",
      "feat_name: (930-945,1425-1440), count_total: 1, num_trees: 1, samples: 34\n",
      "feat_name: (45-60,1290-1305), count_total: 1, num_trees: 1, samples: 31\n",
      "feat_name: (30-45,225-240), count_total: 1, num_trees: 1, samples: 31\n",
      "feat_name: (1215-1230,120-135), count_total: 1, num_trees: 1, samples: 31\n",
      "feat_name: (90-105,1215-1230), count_total: 1, num_trees: 1, samples: 31\n",
      "feat_name: (1020-1035,660-675), count_total: 1, num_trees: 1, samples: 31\n",
      "feat_name: (420-435,1425-1440), count_total: 1, num_trees: 1, samples: 30\n",
      "feat_name: (1260-1275,270-285), count_total: 1, num_trees: 1, samples: 30\n",
      "feat_name: (660-675,1305-1320), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (45-60,345-360), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (285-300,360-375), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (1305-1320,210-225), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (660-675,60-75), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (1245-1260,225-240), count_total: 1, num_trees: 1, samples: 28\n",
      "feat_name: (15-30,390-405), count_total: 1, num_trees: 1, samples: 28\n",
      "feat_name: (1440-1455,210-225), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (885-900,1425-1440), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (825-840,1005-1020), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (705-720,210-225), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (180-195,450-465), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (150-165,930-945), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (165-180,1095-1110), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (315-330,1290-1305), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (1140-1155,270-285), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (210-225,225-240), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (60-75,1260-1275), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (165-180,1335-1350), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (180-195,75-90), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (630-645,420-435), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (675-690,660-675), count_total: 1, num_trees: 1, samples: 25\n",
      "feat_name: (180-195,1065-1080), count_total: 1, num_trees: 1, samples: 25\n",
      "feat_name: (1095-1110,345-360), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (1095-1110,1335-1350), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (300-315,975-990), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (705-720,105-120), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (75-90,270-285), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (945-960,885-900), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (1485-1500,240-255), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (240-255,195-210), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (930-945,660-675), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (1380-1395,750-765), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (1275-1290,270-285), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (915-930,495-510), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (1050-1065,945-960), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (1230-1245,210-225), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (1275-1290,975-990), count_total: 1, num_trees: 1, samples: 20\n",
      "feat_name: (135-150,1080-1095), count_total: 1, num_trees: 1, samples: 20\n",
      "feat_name: (165-180,1020-1035), count_total: 1, num_trees: 1, samples: 20\n",
      "feat_name: (525-540,60-75), count_total: 1, num_trees: 1, samples: 20\n",
      "feat_name: (555-570,210-225), count_total: 1, num_trees: 1, samples: 19\n",
      "feat_name: (105-120,345-360), count_total: 1, num_trees: 1, samples: 19\n",
      "feat_name: (315-330,165-180), count_total: 1, num_trees: 1, samples: 19\n",
      "feat_name: (1005-1020,1395-1410), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (105-120,1080-1095), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (675-690,300-315), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (795-810,270-285), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (1035-1050,75-90), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (1440-1455,1020-1035), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (330-345,1290-1305), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (600-615,525-540), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (945-960,495-510), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (1230-1245,180-195), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (1155-1170,270-285), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (150-165,840-855), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (1230-1245,360-375), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (390-405,75-90), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (885-900,630-645), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (795-810,60-75), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (585-600,1380-1395), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (195-210,225-240), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (360-375,1260-1275), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (1470-1485,75-90), count_total: 1, num_trees: 1, samples: 14\n",
      "feat_name: (540-555,945-960), count_total: 1, num_trees: 1, samples: 14\n",
      "feat_name: (585-600,735-750), count_total: 1, num_trees: 1, samples: 14\n",
      "feat_name: (870-885,75-90), count_total: 1, num_trees: 1, samples: 14\n",
      "feat_name: (15-30,555-570), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (315-330,150-165), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (1050-1065,300-315), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (210-225,1380-1395), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (45-60,1185-1200), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (330-345,165-180), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (45-60,180-195), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (1035-1050,480-495), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (1080-1095,1335-1350), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (90-105,270-285), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (1140-1155,1290-1305), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (990-1005,375-390), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (540-555,1425-1440), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (105-120,165-180), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (900-915,1035-1050), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (615-630,60-75), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (1425-1440,90-105), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (420-435,1380-1395), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (150-165,285-300), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1215-1230,735-750), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (420-435,585-600), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (600-615,540-555), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (990-1005,690-705), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1005-1020,405-420), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (765-780,690-705), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1485-1500,1380-1395), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (480-495,420-435), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1005-1020,300-315), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (270-285,75-90), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (390-405,465-480), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1005-1020,420-435), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1185-1200,315-330), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1245-1260,120-135), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (135-150,1380-1395), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1155-1170,90-105), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1200-1215,240-255), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (645-660,1290-1305), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (315-330,1365-1380), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (840-855,75-90), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (480-495,90-105), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (945-960,1290-1305), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1275-1290,1410-1425), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (0-15,1155-1170), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (315-330,450-465), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (495-510,450-465), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (480-495,1125-1140), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (600-615,450-465), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (30-45,75-90), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (195-210,255-270), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (15-30,570-585), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (120-135,180-195), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1440-1455,1140-1155), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1050-1065,105-120), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (915-930,120-135), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (975-990,945-960), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (0-15,1425-1440), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (135-150,780-795), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (210-225,165-180), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (825-840,510-525), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (315-330,1380-1395), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (270-285,540-555), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (810-825,810-825), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1245-1260,375-390), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1170-1185,900-915), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (120-135,375-390), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1440-1455,255-270), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1440-1455,615-630), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (45-60,1170-1185), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1485-1500,1245-1260), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (720-735,105-120), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1245-1260,75-90), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (15-30,150-165), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (465-480,135-150), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (330-345,390-405), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (825-840,435-450), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (210-225,885-900), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (975-990,75-90), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (780-795,240-255), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1095-1110,150-165), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (495-510,1065-1080), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (435-450,60-75), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (405-420,1290-1305), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (720-735,60-75), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (120-135,1095-1110), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (570-585,990-1005), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (75-90,360-375), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1485-1500,855-870), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1485-1500,1335-1350), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (15-30,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (585-600,75-90), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (345-360,165-180), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1395-1410,930-945), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (675-690,165-180), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (315-330,90-105), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (960-975,270-285), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (315-330,840-855), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1470-1485,495-510), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (915-930,1380-1395), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1245-1260,105-120), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (945-960,1185-1200), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (735-750,780-795), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (15-30,960-975), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (120-135,135-150), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1365-1380,225-240), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (390-405,165-180), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1110-1125,690-705), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (330-345,120-135), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (855-870,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (900-915,480-495), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1005-1020,75-90), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (810-825,495-510), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1215-1230,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (600-615,1425-1440), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (780-795,1290-1305), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (825-840,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1335-1350,465-480), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1095-1110,1095-1110), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (720-735,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (885-900,825-840), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (495-510,930-945), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1395-1410,390-405), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (240-255,1380-1395), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (840-855,510-525), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (450-465,1110-1125), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (15-30,1185-1200), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (0-15,315-330), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (765-780,465-480), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1320-1335,225-240), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1380-1395,315-330), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (375-390,1065-1080), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (450-465,225-240), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (390-405,1410-1425), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1155-1170,255-270), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1275-1290,240-255), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1155-1170,210-225), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (120-135,1110-1125), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (435-450,375-390), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1425-1440,1320-1335), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (30-45,675-690), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1245-1260,1410-1425), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (345-360,240-255), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (960-975,450-465), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1215-1230,135-150), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (915-930,105-120), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1260-1275,540-555), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (735-750,240-255), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (780-795,1050-1065), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1140-1155,90-105), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1320-1335,105-120), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (570-585,330-345), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (435-450,750-765), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1095-1110,420-435), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1005-1020,105-120), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1470-1485,945-960), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (720-735,195-210), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1365-1380,390-405), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1110-1125,300-315), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (30-45,1035-1050), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (600-615,435-450), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (270-285,120-135), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (840-855,195-210), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (195-210,165-180), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (75-90,1170-1185), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (975-990,105-120), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (765-780,1290-1305), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (735-750,135-150), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (600-615,330-345), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (930-945,135-150), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1110-1125,105-120), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (645-660,1320-1335), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (210-225,1335-1350), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (405-420,900-915), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (150-165,1095-1110), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1350-1365,390-405), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1455-1470,105-120), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (735-750,930-945), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (960-975,1260-1275), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (825-840,90-105), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (600-615,75-90), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1155-1170,1290-1305), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (480-495,75-90), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (165-180,945-960), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1425-1440,975-990), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (900-915,315-330), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1050-1065,480-495), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (330-345,90-105), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (630-645,480-495), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (885-900,510-525), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (420-435,1125-1140), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (660-675,570-585), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (120-135,1155-1170), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (435-450,345-360), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (720-735,720-735), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (795-810,390-405), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (435-450,270-285), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (75-90,690-705), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1170-1185,390-405), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (900-915,1245-1260), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (480-495,735-750), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (360-375,105-120), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (915-930,690-705), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (765-780,120-135), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (315-330,780-795), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (975-990,915-930), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (435-450,75-90), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1470-1485,555-570), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1440-1455,600-615), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (300-315,1245-1260), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (675-690,1410-1425), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (975-990,1110-1125), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1140-1155,75-90), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1305-1320,990-1005), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1335-1350,315-330), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1245-1260,465-480), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (150-165,690-705), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1440-1455,1065-1080), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (30-45,690-705), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (240-255,540-555), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1020-1035,210-225), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (780-795,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (375-390,1410-1425), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (360-375,1245-1260), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (30-45,195-210), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (870-885,930-945), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (30-45,915-930), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (630-645,1410-1425), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (915-930,90-105), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (45-60,555-570), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (105-120,1050-1065), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1140-1155,225-240), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (315-330,1410-1425), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1050-1065,1380-1395), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1035-1050,210-225), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (645-660,810-825), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1485-1500,600-615), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (165-180,135-150), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1485-1500,570-585), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (165-180,990-1005), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1440-1455,390-405), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (690-705,240-255), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (15-30,210-225), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (300-315,150-165), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (120-135,150-165), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (615-630,390-405), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (135-150,75-90), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (975-990,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1185-1200,270-285), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (0-15,210-225), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (465-480,210-225), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (915-930,315-330), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (615-630,900-915), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (90-105,915-930), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (15-30,825-840), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (645-660,90-105), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (945-960,1425-1440), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (0-15,420-435), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1320-1335,270-285), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (45-60,915-930), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1110-1125,1050-1065), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (225-240,300-315), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (660-675,465-480), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (60-75,90-105), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (390-405,660-675), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1140-1155,150-165), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (990-1005,1380-1395), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1290-1305,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1275-1290,1350-1365), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (225-240,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1440-1455,375-390), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1275-1290,480-495), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (645-660,945-960), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1125-1140,135-150), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1125-1140,90-105), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (195-210,1305-1320), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (645-660,75-90), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (180-195,255-270), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (795-810,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1260-1275,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (345-360,135-150), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (450-465,90-105), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1470-1485,450-465), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (255-270,75-90), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (540-555,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (885-900,435-450), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (630-645,735-750), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1185-1200,1110-1125), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (825-840,1380-1395), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (210-225,90-105), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (210-225,60-75), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (15-30,345-360), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (975-990,1020-1035), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (135-150,1425-1440), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (30-45,255-270), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (885-900,270-285), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (330-345,480-495), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (15-30,1065-1080), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (60-75,240-255), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (735-750,1155-1170), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (585-600,225-240), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1185-1200,1290-1305), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1035-1050,225-240), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1485-1500,300-315), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (645-660,135-150), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (30-45,1020-1035), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1065-1080,480-495), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (975-990,975-990), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (450-465,1410-1425), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (525-540,90-105), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (450-465,840-855), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (45-60,255-270), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (660-675,1320-1335), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (45-60,1350-1365), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (450-465,810-825), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1305-1320,225-240), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1230-1245,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1005-1020,600-615), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (360-375,1335-1350), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (345-360,390-405), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1200-1215,825-840), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (135-150,900-915), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (705-720,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1065-1080,390-405), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (195-210,285-300), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (510-525,1290-1305), count_total: 1, num_trees: 1, samples: 2\n"
     ]
    }
   ],
   "source": [
    "#num_iter=50\n",
    "#num_stability_iter=10\n",
    "#all_trees = trustee.get_all_students()\n",
    "\n",
    "all_features = {}\n",
    "i=0\n",
    "for j in range(num_stability_iter):\n",
    "    for dt, rev in all_trees[j]:\n",
    "        dot_data = tree.export_graphviz(\n",
    "            dt,\n",
    "            class_names=classes,\n",
    "            feature_names=features,\n",
    "            filled=True,\n",
    "            rounded=True,\n",
    "            special_characters=True,)\n",
    "        graph = graphviz.Source(dot_data)\n",
    "        graph.render(f'svm_pool tree x,y {i}')    \n",
    "\n",
    "        features_used, splits, branches = get_dt_info(dt)\n",
    "\n",
    "        for feat in features_used:\n",
    "            if feat not in all_features:\n",
    "                all_features[feat] = {\"feat_name\": MyFeature(feat+1), \"count_total\": 0, \"num_trees\": 0, \"samples\": 0}\n",
    "\n",
    "            all_features[feat][\"count_total\"] += features_used[feat][\"count\"]\n",
    "            all_features[feat][\"num_trees\"] += 1\n",
    "            all_features[feat][\"samples\"] += features_used[feat][\"samples\"]\n",
    "\n",
    "        \"\"\"\n",
    "        print(f'tree {i}:')\n",
    "        for feat in features_used:   \n",
    "            print(f'feat: {feat+1}, count: {features_used[feat][\"count\"]}, samples: {features_used[feat][\"samples\"]}')\n",
    "        \"\"\"\n",
    "        i+=1\n",
    "\n",
    "print()\n",
    "print(\"all tree:\")    \n",
    "for feat in all_features:   \n",
    "     print(f'feat_name: ({all_features[feat][\"feat_name\"]}), count_total: {all_features[feat][\"count_total\"]}, num_trees: {all_features[feat][\"num_trees\"]}, samples: {all_features[feat][\"samples\"]}')\n",
    "\n",
    "\n",
    "print()\n",
    "sorted_features = sorted(all_features.items(), key=lambda x: (x[1][\"num_trees\"], x[1][\"samples\"]), reverse=True)\n",
    "print(\"sorted features:\")\n",
    "for feat, data in sorted_features:\n",
    "    print(f'feat_name: ({all_features[feat][\"feat_name\"]}), count_total: {data[\"count_total\"]}, num_trees: {data[\"num_trees\"]}, samples: {data[\"samples\"]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea3869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
