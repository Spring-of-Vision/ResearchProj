{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ce332",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install furo\n",
    "#!pip install graphviz\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install prettytable\n",
    "!pip install scikit-learn\n",
    "!pip install scipy\n",
    "!pip install setuptools\n",
    "!pip install sphinx-gallery\n",
    "!pip install sphinxemoji\n",
    "!pip install termcolor\n",
    "#!winget install -e --id Graphviz.Graphviz\n",
    "\n",
    "!pip install trustee --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cb41ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import joblib\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from trustee import ClassificationTrustee\n",
    "from trustee.utils.tree import get_dt_info, top_k_prune\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe872f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAXP POOLING\n",
    "\n",
    "def max_pooling(input_array, pool_size, stride):\n",
    "    output_shape = (\n",
    "        (input_array.shape[0] - pool_size) // stride + 1,\n",
    "        (input_array.shape[1] - pool_size) // stride + 1\n",
    "    )\n",
    "    pooled_array = np.zeros(output_shape)\n",
    "    \n",
    "    for i in range(0, output_shape[0]):\n",
    "        for j in range(0, output_shape[1]):\n",
    "            pooled_array[i, j] = np.max(\n",
    "                input_array[\n",
    "                    i * stride : i * stride + pool_size,\n",
    "                    j * stride : j * stride + pool_size\n",
    "                ]\n",
    "            )\n",
    "    \n",
    "    return pooled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06ad2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyFeature(feature_index):\n",
    "    \n",
    "    if feature_index==0:\n",
    "        return 0\n",
    "\n",
    "    pooled_array_size = 100  # cnn 1500  \n",
    "    \n",
    "    # חישוב ערכי ה-x וה-y\n",
    "    y = feature_index // pooled_array_size\n",
    "    y = y*15 # cnn להוריד\n",
    "    x = feature_index-1\n",
    "    x = x % pooled_array_size\n",
    "    x = x*15 # cnn להוריד\n",
    "    \n",
    "    return f'{x}-{x+15},{y}-{y+15}'  # x,y להחליף ל"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8aff938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATASET\n",
    "\n",
    "labels = ['Youtube', 'GoogleDoc', 'GoogleDrive']\n",
    "\n",
    "features_path = \"features\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for label in labels:\n",
    "    folder_path = os.path.join(features_path, label)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('0.npy'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Load the .npy file and sum\n",
    "            temp = np.load(file_path)\n",
    "            trans = np.transpose(temp)\n",
    "            \n",
    "            pooled = max_pooling(trans, 15, 15)\n",
    "\n",
    "            # Apply Singular Value Decomposition (SVD) for dimensionality reduction\n",
    "            new_row = pd.DataFrame([np.append(label, pooled.flatten())] , columns=[f'feature_{MyFeature(i)}' for i in range(10001)])\n",
    "            # Append the new row to the DataFrame\n",
    "            df = pd.concat([df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b595ea6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_0-15,0-15</th>\n",
       "      <th>feature_15-30,0-15</th>\n",
       "      <th>feature_30-45,0-15</th>\n",
       "      <th>feature_45-60,0-15</th>\n",
       "      <th>feature_60-75,0-15</th>\n",
       "      <th>feature_75-90,0-15</th>\n",
       "      <th>feature_90-105,0-15</th>\n",
       "      <th>feature_105-120,0-15</th>\n",
       "      <th>feature_120-135,0-15</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1350-1365,1485-1500</th>\n",
       "      <th>feature_1365-1380,1485-1500</th>\n",
       "      <th>feature_1380-1395,1485-1500</th>\n",
       "      <th>feature_1395-1410,1485-1500</th>\n",
       "      <th>feature_1410-1425,1485-1500</th>\n",
       "      <th>feature_1425-1440,1485-1500</th>\n",
       "      <th>feature_1440-1455,1485-1500</th>\n",
       "      <th>feature_1455-1470,1485-1500</th>\n",
       "      <th>feature_1470-1485,1485-1500</th>\n",
       "      <th>feature_1485-1500,1500-1515</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3384</th>\n",
       "      <td>GoogleDrive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>GoogleDrive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>GoogleDrive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>GoogleDrive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>GoogleDrive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3389 rows × 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_0 feature_0-15,0-15 feature_15-30,0-15 feature_30-45,0-15  \\\n",
       "0         Youtube               0.0                0.0                0.0   \n",
       "1         Youtube               0.0                0.0                0.0   \n",
       "2         Youtube               0.0                0.0                0.0   \n",
       "3         Youtube               0.0                0.0                0.0   \n",
       "4         Youtube               0.0                0.0                0.0   \n",
       "...           ...               ...                ...                ...   \n",
       "3384  GoogleDrive               0.0                0.0                0.0   \n",
       "3385  GoogleDrive               0.0                0.0                0.0   \n",
       "3386  GoogleDrive               0.0                0.0                0.0   \n",
       "3387  GoogleDrive               0.0                0.0                0.0   \n",
       "3388  GoogleDrive               0.0                0.0                0.0   \n",
       "\n",
       "     feature_45-60,0-15 feature_60-75,0-15 feature_75-90,0-15  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "3384                0.0                0.0                0.0   \n",
       "3385                0.0                0.0                0.0   \n",
       "3386                0.0                0.0                0.0   \n",
       "3387                0.0                0.0                0.0   \n",
       "3388                0.0                0.0                0.0   \n",
       "\n",
       "     feature_90-105,0-15 feature_105-120,0-15 feature_120-135,0-15  ...  \\\n",
       "0                    0.0                  0.0                  0.0  ...   \n",
       "1                    0.0                  0.0                  0.0  ...   \n",
       "2                    0.0                  0.0                  0.0  ...   \n",
       "3                    0.0                  0.0                  0.0  ...   \n",
       "4                    0.0                  0.0                  0.0  ...   \n",
       "...                  ...                  ...                  ...  ...   \n",
       "3384                 0.0                  0.0                  0.0  ...   \n",
       "3385                 0.0                  0.0                  0.0  ...   \n",
       "3386                 0.0                  0.0                  0.0  ...   \n",
       "3387                 0.0                  0.0                  0.0  ...   \n",
       "3388                 0.0                  0.0                  0.0  ...   \n",
       "\n",
       "     feature_1350-1365,1485-1500 feature_1365-1380,1485-1500  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         0.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         0.0   \n",
       "...                          ...                         ...   \n",
       "3384                         0.0                         0.0   \n",
       "3385                         0.0                         0.0   \n",
       "3386                         0.0                         0.0   \n",
       "3387                         0.0                         0.0   \n",
       "3388                         0.0                         0.0   \n",
       "\n",
       "     feature_1380-1395,1485-1500 feature_1395-1410,1485-1500  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         0.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         0.0   \n",
       "...                          ...                         ...   \n",
       "3384                         0.0                         0.0   \n",
       "3385                         0.0                         0.0   \n",
       "3386                         0.0                         0.0   \n",
       "3387                         0.0                         0.0   \n",
       "3388                         0.0                         0.0   \n",
       "\n",
       "     feature_1410-1425,1485-1500 feature_1425-1440,1485-1500  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         0.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         0.0   \n",
       "...                          ...                         ...   \n",
       "3384                         0.0                         0.0   \n",
       "3385                         0.0                         0.0   \n",
       "3386                         0.0                         0.0   \n",
       "3387                         0.0                         0.0   \n",
       "3388                         0.0                         0.0   \n",
       "\n",
       "     feature_1440-1455,1485-1500 feature_1455-1470,1485-1500  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         0.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         0.0   \n",
       "...                          ...                         ...   \n",
       "3384                         0.0                         0.0   \n",
       "3385                         0.0                         0.0   \n",
       "3386                         0.0                         0.0   \n",
       "3387                         0.0                         0.0   \n",
       "3388                         0.0                         0.0   \n",
       "\n",
       "     feature_1470-1485,1485-1500 feature_1485-1500,1500-1515  \n",
       "0                            0.0                         0.0  \n",
       "1                            0.0                         0.0  \n",
       "2                            0.0                         0.0  \n",
       "3                            0.0                         0.0  \n",
       "4                            0.0                         0.0  \n",
       "...                          ...                         ...  \n",
       "3384                         0.0                         0.0  \n",
       "3385                         0.0                         0.0  \n",
       "3386                         0.0                         0.0  \n",
       "3387                         0.0                         0.0  \n",
       "3388                         0.0                         0.0  \n",
       "\n",
       "[3389 rows x 10001 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d3d4c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_x,y_pooling.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8dd4e873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.9901671583087512\n"
     ]
    }
   ],
   "source": [
    "# Load the df\n",
    "df = pd.read_csv(\"df_x,y_pooling.csv\")\n",
    "\n",
    "y = df['feature_0']\n",
    "X = df.drop(columns = ['feature_0'], inplace = False)\n",
    "\n",
    "# Split the data into 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the Random Forest classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "test_score = classifier.score(X_test, y_test)\n",
    "print(\"Test set accuracy:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56fa5dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e4a3c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIhCAYAAAAimCCiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABkcUlEQVR4nO3deZyN5f/H8feZ3TIzjGXGMBj7GiKiZBlrsrYovmVLG7KFqCwtJlpUtkpqkCXfQinJTqJCSjRIRraZMJixjDHL9fvDz/l2uskcZtzDeT17nMfXue7rvu7POZ36fvrc13XdDmOMEQAAAPA3XnYHAAAAgNyHJBEAAAAWJIkAAACwIEkEAACABUkiAAAALEgSAQAAYEGSCAAAAAuSRAAAAFiQJAIAAMCCJBG4AWzbtk09evRQZGSkAgIClD9/ft16660aP368jh8/nqPX3rp1qxo1aqTg4GA5HA699dZb2X4Nh8Oh0aNHZ/u4VxITEyOHwyGHw6E1a9ZYjhtjVK5cOTkcDjVu3PiqrjFlyhTFxMS4dc6aNWsuGxMAXC8+dgcA4N9NmzZNTz31lCpWrKghQ4aoSpUqSktL0+bNm/Xuu+9q48aNWrhwYY5dv2fPnjpz5ozmzZunggULqnTp0tl+jY0bN6pEiRLZPm5WBQYGavr06ZZEcO3atfrjjz8UGBh41WNPmTJFhQsXVvfu3bN8zq233qqNGzeqSpUqV31dALhWJIlALrZx40Y9+eSTat68uRYtWiR/f3/nsebNm2vw4MFaunRpjsawfft29e7dW61bt86xa9x+++05NnZWdO7cWbNnz9bkyZMVFBTkbJ8+fbrq16+v5OTk6xJHWlqaHA6HgoKCbP9OAIDbzUAuNnbsWDkcDr3//vsuCeJFfn5+ateunfN9Zmamxo8fr0qVKsnf319FixbVI488ooMHD7qc17hxY1WrVk2bNm1Sw4YNlTdvXpUpU0avvvqqMjMzJf3vVmx6erqmTp3qvC0rSaNHj3b++e8unrNv3z5n26pVq9S4cWMVKlRIefLkUcmSJXXvvffq7Nmzzj6Xut28fft2tW/fXgULFlRAQIBq1qypGTNmuPS5eFt27ty5eu655xQeHq6goCA1a9ZMu3btytqXLOmhhx6SJM2dO9fZlpSUpM8++0w9e/a85DljxoxRvXr1FBISoqCgIN16662aPn26jDHOPqVLl9aOHTu0du1a5/d3sRJ7MfZZs2Zp8ODBKl68uPz9/bVnzx7L7eZjx44pIiJCDRo0UFpamnP83377Tfny5dPDDz+c5c8KAFlFkgjkUhkZGVq1apVq166tiIiILJ3z5JNPatiwYWrevLm++OILvfTSS1q6dKkaNGigY8eOufRNSEhQ165d9Z///EdffPGFWrdureHDh+vjjz+WJLVp00YbN26UJN13333auHGj831W7du3T23atJGfn58+/PBDLV26VK+++qry5cun8+fPX/a8Xbt2qUGDBtqxY4feeecdLViwQFWqVFH37t01fvx4S/8RI0bozz//1AcffKD3339fv//+u9q2bauMjIwsxRkUFKT77rtPH374obNt7ty58vLyUufOnS/72R5//HHNnz9fCxYsUKdOndSvXz+99NJLzj4LFy5UmTJlVKtWLef398+pAcOHD9f+/fv17rvvavHixSpatKjlWoULF9a8efO0adMmDRs2TJJ09uxZ3X///SpZsqTefffdLH1OAHCLAZArJSQkGEnmwQcfzFL/2NhYI8k89dRTLu0//PCDkWRGjBjhbGvUqJGRZH744QeXvlWqVDEtW7Z0aZNk+vTp49I2atQoc6l/fXz00UdGkomLizPGGPPpp58aSebnn3/+19glmVGjRjnfP/jgg8bf39/s37/fpV/r1q1N3rx5zcmTJ40xxqxevdpIMnfffbdLv/nz5xtJZuPGjf963Yvxbtq0yTnW9u3bjTHG3HbbbaZ79+7GGGOqVq1qGjVqdNlxMjIyTFpamnnxxRdNoUKFTGZmpvPY5c69eL277rrrssdWr17t0j5u3DgjySxcuNB069bN5MmTx2zbtu1fPyMAXC0qicBNYvXq1ZJkWSBRt25dVa5cWStXrnRpDwsLU926dV3abrnlFv3555/ZFlPNmjXl5+enxx57TDNmzNDevXuzdN6qVasUFRVlqaB2795dZ8+etVQ0/37LXbrwOSS59VkaNWqksmXL6sMPP9Svv/6qTZs2XfZW88UYmzVrpuDgYHl7e8vX11cjR45UYmKijhw5kuXr3nvvvVnuO2TIELVp00YPPfSQZsyYoYkTJ6p69epZPh8A3EGSCORShQsXVt68eRUXF5el/omJiZKkYsWKWY6Fh4c7j19UqFAhSz9/f3+lpKRcRbSXVrZsWa1YsUJFixZVnz59VLZsWZUtW1Zvv/32v56XmJh42c9x8fjf/fOzXJy/6c5ncTgc6tGjhz7++GO9++67qlChgho2bHjJvj/++KNatGgh6cLq8++++06bNm3Sc8895/Z1L/U5/y3G7t2769y5cwoLC2MuIoAcRZII5FLe3t6KiorSli1bLAtPLuViohQfH285dvjwYRUuXDjbYgsICJAkpaamurT/c96jJDVs2FCLFy9WUlKSvv/+e9WvX18DBgzQvHnzLjt+oUKFLvs5JGXrZ/m77t2769ixY3r33XfVo0ePy/abN2+efH199eWXX+qBBx5QgwYNVKdOnau65qUWAF1OfHy8+vTpo5o1ayoxMVHPPPPMVV0TALKCJBHIxYYPHy5jjHr37n3JhR5paWlavHixJKlp06aS5Fx4ctGmTZsUGxurqKiobIvr4grdbdu2ubRfjOVSvL29Va9ePU2ePFmS9NNPP122b1RUlFatWuVMCi+aOXOm8ubNm2PbwxQvXlxDhgxR27Zt1a1bt8v2czgc8vHxkbe3t7MtJSVFs2bNsvTNrupsRkaGHnroITkcDn399deKjo7WxIkTtWDBgmseGwAuhX0SgVysfv36mjp1qp566inVrl1bTz75pKpWraq0tDRt3bpV77//vqpVq6a2bduqYsWKeuyxxzRx4kR5eXmpdevW2rdvn1544QVFRERo4MCB2RbX3XffrZCQEPXq1UsvvviifHx8FBMTowMHDrj0e/fdd7Vq1Sq1adNGJUuW1Llz55wriJs1a3bZ8UeNGqUvv/xSTZo00ciRIxUSEqLZs2frq6++0vjx4xUcHJxtn+WfXn311Sv2adOmjd5880116dJFjz32mBITE/X6669fcpui6tWra968efrkk09UpkwZBQQEXNU8wlGjRunbb7/VsmXLFBYWpsGDB2vt2rXq1auXatWqpcjISLfHBIB/Q5II5HK9e/dW3bp1NWHCBI0bN04JCQny9fVVhQoV1KVLF/Xt29fZd+rUqSpbtqymT5+uyZMnKzg4WK1atVJ0dPQl5yBeraCgIC1dulQDBgzQf/7zHxUoUECPPvqoWrdurUcffdTZr2bNmlq2bJlGjRqlhIQE5c+fX9WqVdMXX3zhnNN3KRUrVtSGDRs0YsQI9enTRykpKapcubI++ugjt55cklOaNm2qDz/8UOPGjVPbtm1VvHhx9e7dW0WLFlWvXr1c+o4ZM0bx8fHq3bu3Tp06pVKlSrnsI5kVy5cvV3R0tF544QWXinBMTIxq1aqlzp07a/369fLz88uOjwcAkiSHMX/b+RUAAAAQcxIBAABwCSSJAAAAsCBJBAAAgAVJIgAAACxIEgEAAGBBkggAAAALkkQAAABY3JSbaeep1ffKnYDr7MSmSXaHALhgl1zkNnl8bbx2DuYOKVtvzH//U0kEAACAxU1ZSQQAAHCLg7rZP5EkAgAAOBx2R5DrkDYDAADAgkoiAAAAt5st+EYAAABgQSURAACAOYkWVBIBAABgQSURAACAOYkWfCMAAACwoJIIAADAnEQLkkQAAABuN1vwjQAAAMCCSiIAAAC3my2oJAIAAMCCSiIAAABzEi34RgAAAGBBJREAAIA5iRZUEgEAAGBBJREAAIA5iRYkiQAAANxutiBtBgAAgAWVRAAAAG43W/CNAAAAwIJKIgAAAJVEC74RAAAAWFBJBAAA8GJ18z9RSQQAAIAFlUQAAADmJFqQJAIAALCZtgVpMwAAACyoJAIAAHC72YJvBAAAABZUEgEAAJiTaEElEQAAABZUEgEAAJiTaME3AgAAAAsqiQAAAMxJtCBJBAAA4HazBd8IAAAALKgkAgAAcLvZwvZK4n333adXX33V0v7aa6/p/vvvtyEiAAAA2J4krl27Vm3atLG0t2rVSuvWrbMhIgAA4HEcXjn3ukHZHvnp06fl5+dnaff19VVycrINEQEAAMD2JLFatWr65JNPLO3z5s1TlSpVbIgIAAB4HIcj5143KNsXrrzwwgu699579ccff6hp06aSpJUrV2ru3Ln673//a3N0AAAAnsn2JLFdu3ZatGiRxo4dq08//VR58uTRLbfcohUrVqhRo0Z2hwcAADzBDTx3MKfYniRKUps2bS65eAUAAOC6IEm0yBVJoiRt2bJFsbGxcjgcqlKlimrVqmV3SAAAAB7L9iTxyJEjevDBB7VmzRoVKFBAxhglJSWpSZMmmjdvnooUKWJ3iAAA4GZ3Ay8wySm211b79eun5ORk7dixQ8ePH9eJEye0fft2JScn6+mnn7Y7PAAAAI9keyVx6dKlWrFihSpXruxsq1KliiZPnqwWLVrYGBkAAPAYzEm0sP0byczMlK+vr6Xd19dXmZmZNkQEAAAA25PEpk2bqn///jp8+LCz7dChQxo4cKCioqJsjAwAAHgMNtO2sD1JnDRpkk6dOqXSpUurbNmyKleunCIjI3Xq1ClNnDjR7vAAAACum6lTp+qWW25RUFCQgoKCVL9+fX399dfO48YYjR49WuHh4cqTJ48aN26sHTt2uIyRmpqqfv36qXDhwsqXL5/atWungwcPuh2L7XMSIyIi9NNPP2n58uXauXOnjDGqUqWKmjVrZndoAADAU+SSOYklSpTQq6++qnLlykmSZsyYofbt22vr1q2qWrWqxo8frzfffFMxMTGqUKGCXn75ZTVv3ly7du1SYGCgJGnAgAFavHix5s2bp0KFCmnw4MG65557tGXLFnl7e2c5FocxxuTIp7RRnlp97Q4BsDixaZLdIQAubr5/++NGl8e6ROH6XbvT9BwbO2VBr2s6PyQkRK+99pp69uyp8PBwDRgwQMOGDZN0oWoYGhqqcePG6fHHH1dSUpKKFCmiWbNmqXPnzpKkw4cPKyIiQkuWLFHLli2zfF1b0+bMzEx9+OGHuueee1StWjVVr15d7dq108yZM3UT5q4AAMADpaamKjk52eWVmpp6xfMyMjI0b948nTlzRvXr11dcXJwSEhJcdn/x9/dXo0aNtGHDBkkXHk6Slpbm0ic8PFzVqlVz9skq25JEY4zatWunRx99VIcOHVL16tVVtWpV/fnnn+revbs6duxoV2gAAMDDOByOHHtFR0crODjY5RUdHX3ZWH799Vflz59f/v7+euKJJ7Rw4UJVqVJFCQkJkqTQ0FCX/qGhoc5jCQkJ8vPzU8GCBS/bJ6tsm5MYExOjdevWaeXKlWrSpInLsVWrVqlDhw6aOXOmHnnkEZsiBAAAuHbDhw/XoEGDXNr8/f0v279ixYr6+eefdfLkSX322Wfq1q2b1q5d6zzu+MeKaWOMpe2fstLnn2yrJM6dO1cjRoywJIjShW1xnn32Wc2ePduGyAAAgKfJyUqiv7+/c7Xyxde/JYl+fn4qV66c6tSpo+joaNWoUUNvv/22wsLCJMlSETxy5IizuhgWFqbz58/rxIkTl+2TVbYlidu2bVOrVq0ue7x169b65ZdfrmNEAAAAuY8xRqmpqYqMjFRYWJiWL1/uPHb+/HmtXbtWDRo0kCTVrl1bvr6+Ln3i4+O1fft2Z5+ssu128/Hjx/81ow0NDbVkwQAAADkil+x5PWLECLVu3VoRERE6deqU5s2bpzVr1mjp0qVyOBwaMGCAxo4dq/Lly6t8+fIaO3as8ubNqy5dukiSgoOD1atXLw0ePFiFChVSSEiInnnmGVWvXt3t7QVtSxIzMjLk43P5y3t7eys9Pf06RgQAAGCvv/76Sw8//LDi4+MVHBysW265RUuXLlXz5s0lSUOHDlVKSoqeeuopnThxQvXq1dOyZcuceyRK0oQJE+Tj46MHHnhAKSkpioqKUkxMjFt7JEo27pPo5eWl1q1bX/aefGpqqpYuXaqMjAy3x2afRORG7JOI3IadxpDb2LlPYv4HYnJs7NPzu+fY2DnJtkpit27drtiHlc0AAOB6cHflryewLUn86KOP7Lo0AAAAriB3PKhQ0p49e/TNN98oJSVFknjiCgAAuG5ycgucG5XtSWJiYqKioqJUoUIF3X333YqPj5ckPfrooxo8eLDN0QEAAHgm25PEgQMHytfXV/v371fevHmd7Z07d9bSpUttjAwAAHgKKolWtieJy5Yt07hx41SiRAmX9vLly+vPP/+0KaqbV+/779SPnwzXX9++pr++fU1rZgxWizuqXLLvxOceVMrWSerbpfFlx1s06UmlbJ2kto1vyaGIgf/5ZO5stW7RVLfVqq4H7++kn7ZstjskeKjp095Tl873qkHdWmpyV30NePop7Yvba3dYQLayPUk8c+aMSwXxomPHjv3rI2twdQ79dVIvTPxcd3R9TXd0fU1rftyt/054TJXLhLn0a9v4Ft1WvbQOHzl52bH6dW3CFhq4bpZ+vUTjX41W78ee1CefLtKtt9bWU4/3Vvzhw3aHBg+0ZfOP6vxQV82cM1/vvv+RMtIz9ORjvZRy9qzdoeFqOXLwdYOyPUm86667NHPmTOd7h8OhzMxMvfbaa5d8rjOuzZJ12/XN+t+0Z/8R7dl/RKMnL9bps6mqe0uks094kWBNePZ+9RgRo7T0S+9TWb1CcT39n6Z6YvTH1yt0eLhZMz5Sx3vvVaf77leZsmU1dPhzCisWpvmfzLU7NHigKe9NV/sOnVSuXHlVrFRJY16OVnz8Yf322w67QwOyjW1b4Fz02muvqXHjxtq8ebPOnz+voUOHaseOHTp+/Li+++47u8O7qXl5OXRv81uVL4+fftgWJ+lCkj795Uc0YcZKxe5NuOR5eQJ8NSO6uwaOm6+/Ek9dz5DhodLOn1fsbzvU89HHXNrrN7hDv/y81aaogP85ffrCvwuDg4NtjgRX60aeO5hTbE8Sq1Spom3btmnq1Kny9vbWmTNn1KlTJ/Xp00fFihWzO7ybUtVy4VozY7AC/Hx0OiVVnQdP087/TwgH92iu9IxMTZ675rLnjx98r77/JU5frvn1OkUMT3fi5AllZGSoUKFCLu2FChXWsWNHbYoKuMAYozfGR6vWrbVVrnwFu8MBso3tSaIkhYWFacyYMVd1bmpqqlJTU13aTGaGHF7uPZ/Qk+ze95fqPRitAoF51SGqpqa9+LBaPPq28vj7qs9DjdWgy7jLntumUXU1rltBtz/46nWMGLjgn/+lb4zhv/5hu+hXXtTu3bsVM3OO3aHgGvDvEitbksRt27Zlue8tt/z7qtno6GhLgukdept8i9W9qtg8QVp6hvYeOCZJ+um3/apdtaT6PNRYu+ISVDQkv3YvedHZ18fHW68O6qS+XZuoUptRanxbBZUpUVgJ615zGXPu64/qu61/qGXvt6/rZ4FnKFigoLy9vXXs2DGX9uPHE1WoUGGbogKkV8e+pLWrV+nDGR8rNCzsyicg1yJJtLIlSaxZs6YcDscVn6ricDiUkXHphRMXDR8+XIMGDXJpK9pw2DXH6Ekccsjfz0dzvtqkVT/scjm2eEofzfnqR838/HtJ0usfLdNHCze49Nny6XMa+sZn+mrt9usWMzyLr5+fKlepqu83fKeoZs2d7d9v2KDGTaNsjAyeyhijV8e+pFUrl+uDj2apeIkIu0MCsp0tSWJcXFy2jeXv72/ZKodbzZc3pm9bLfvuNx1IOKHAfAG6v2Vt3VWnvNr1maLjSWd0POmMS/+09Az9dSxZv/95RJL0V+KpSy5WORB/Qn8eTrwunwGe6eFuPfTcs0NVpVo11ahRS5/99xPFx8fr/s4P2h0aPNDYl8fo6yVf6q13pihfvnzOubH58wcqICDA5uhwNagkWtmSJJYqVcqOy0JS0UKBmv7yIworHKSk0+e0/fdDatdnilb9sNPu0IB/1ar13Uo6eULvT52io0ePqFz5Cpr87vsKDy9ud2jwQP/9/62XHu3xsEv7mJej1b5DJztCArKdw1zpnm8O++KLLy7Z7nA4FBAQoHLlyikyMvKSfS4nT62+2REakK1ObJpkdwiACzbDR26Tx9e+axfqlnN7ribOeCjHxs5Jtq9u7tChwyXnJ15sczgcuvPOO7Vo0SIVLFjQpigBAAA8i+1PXFm+fLluu+02LV++XElJSUpKStLy5ctVt25dffnll1q3bp0SExP1zDPP2B0qAAC4STkcjhx73ahsryT2799f77//vho0aOBsi4qKUkBAgB577DHt2LFDb731lnr27GljlAAAAJ7F9iTxjz/+UFBQkKU9KChIe/fulSSVL1/esj8aAABAdrmRK345xfbbzbVr19aQIUN09Oj/Hq119OhRDR06VLfddpsk6ffff1eJEiXsChEAANzkuN1sZXslcfr06Wrfvr1KlCihiIgIORwO7d+/X2XKlNHnn38uSTp9+rReeOEFmyMFAADwHLYniRUrVlRsbKy++eYb7d69W8YYVapUSc2bN5eX14VCZ4cOHewNEgAA3Nxu3IJfjrE9SZQulHhbtWqlVq1a2R0KAAAAlAvmJErS2rVr1bZtW5UrV07ly5dXu3bt9O2339odFgAA8BDMSbSyPUn8+OOP1axZM+XNm1dPP/20+vbtqzx58igqKkpz5syxOzwAAACPZPtj+SpXrqzHHntMAwcOdGl/8803NW3aNMXGxro9Jo/lQ27EY/mQ2/BYPuQ2dj6WL6z3pzk2dsK0+3Js7JxkeyVx7969atu2raW9Xbt2iouLsyEiAAAA2J4kRkREaOXKlZb2lStXKiIiwoaIAACAp2FOopXtq5sHDx6sp59+Wj///LMaNGggh8Oh9evXKyYmRm+//bbd4QEAAA9wIydzOcX2JPHJJ59UWFiY3njjDc2fP1/ShXmKn3zyidq3b29zdAAAAJ7J9iRRkjp27KiOHTvaHQYAAPBUFBItckWSKElbtmxRbGysHA6HqlSpolq1atkdEgAAgMeyPUk8cuSIHnzwQa1Zs0YFChSQMUZJSUlq0qSJ5s2bpyJFitgdIgAAuMkxJ9HK9tXN/fr1U3Jysnbs2KHjx4/rxIkT2r59u5KTk/X000/bHR4AAIBHsr2SuHTpUq1YsUKVK1d2tlWpUkWTJ09WixYtbIwMAAB4CiqJVrZXEjMzM+Xra91i3dfXV5mZmTZEBAAAANuTxKZNm6p///46fPiws+3QoUMaOHCgoqKibIwMAAB4CjbTtrI9SZw0aZJOnTql0qVLq2zZsipXrpxKly6tU6dOaeLEiXaHBwAAPIEjB183KNvnJEZEROinn37SihUrFBsbK2OMqlSpombNmtkdGgAAgMeyrZKYkpKiL7/80vl+5cqViouL0759+7RkyRINHTpU586dsys8AADgQbjdbGVbJXHmzJn68ssvdc8990i6cNu5atWqypMnjyRp586dKlasmAYOHGhXiAAAAB7Ltkri7Nmz1bNnT5e2OXPmaPXq1Vq9erVee+0157OcAQAAchKVRCvbksTdu3erQoUKzvcBAQHy8vpfOHXr1tVvv/1mR2gAAAAez7bbzUlJSfLx+d/ljx496nI8MzNTqamp1zssAADggW7kil9Osa2SWKJECW3fvv2yx7dt26YSJUpcx4gAAABwkW1J4t13362RI0decgVzSkqKxowZozZt2tgQGQAA8DTMSbSy7XbziBEjNH/+fFWsWFF9+/ZVhQoV5HA4tHPnTk2aNEnp6ekaMWKEXeEBAABPcuPmcjnGtiQxNDRUGzZs0JNPPqlnn31WxhhJFzL55s2ba8qUKQoNDbUrPAAAAI9m6xNXIiMjtXTpUh0/flx79uyRJJUrV04hISF2hgUAADzMjXxbOKfY/lg+SQoJCVHdunXtDgMAAAD/L1ckiQAAAHaikmhl2+pmAAAA5F5UEgEAgMejkGhFJREAAAAWVBIBAIDHY06iFZVEAADg8RyOnHu5Izo6WrfddpsCAwNVtGhRdejQQbt27XLp0717d8tTXW6//XaXPqmpqerXr58KFy6sfPnyqV27djp48KBbsZAkAgAA5BJr165Vnz599P3332v58uVKT09XixYtdObMGZd+rVq1Unx8vPO1ZMkSl+MDBgzQwoULNW/ePK1fv16nT5/WPffco4yMjCzHwu1mAADg8XLL7ealS5e6vP/oo49UtGhRbdmyRXfddZez3d/fX2FhYZccIykpSdOnT9esWbPUrFkzSdLHH3+siIgIrVixQi1btsxSLFQSAQAAclBqaqqSk5NdXqmpqVk6NykpSZIsT6Nbs2aNihYtqgoVKqh37946cuSI89iWLVuUlpamFi1aONvCw8NVrVo1bdiwIctxkyQCAACPl5NzEqOjoxUcHOzyio6OvmJMxhgNGjRId955p6pVq+Zsb926tWbPnq1Vq1bpjTfe0KZNm9S0aVNn4pmQkCA/Pz8VLFjQZbzQ0FAlJCRk+TvhdjMAAEAOGj58uAYNGuTS5u/vf8Xz+vbtq23btmn9+vUu7Z07d3b+uVq1aqpTp45KlSqlr776Sp06dbrseMYYt26rkyQCAACP5+WVc3MS/f39s5QU/l2/fv30xRdfaN26dSpRosS/9i1WrJhKlSql33//XZIUFham8+fP68SJEy7VxCNHjqhBgwZZjoHbzQAAALmEMUZ9+/bVggULtGrVKkVGRl7xnMTERB04cEDFihWTJNWuXVu+vr5avny5s098fLy2b9/uVpJIJREAAHi8XLK4WX369NGcOXP0+eefKzAw0DmHMDg4WHny5NHp06c1evRo3XvvvSpWrJj27dunESNGqHDhwurYsaOzb69evTR48GAVKlRIISEheuaZZ1S9enXnauesIEkEAAAeL7dsgTN16lRJUuPGjV3aP/roI3Xv3l3e3t769ddfNXPmTJ08eVLFihVTkyZN9MknnygwMNDZf8KECfLx8dEDDzyglJQURUVFKSYmRt7e3lmOxWGMMdnyqXKRPLX62h0CYHFi0yS7QwBc3Hz/9seNLo+vfdeu9vzyK3e6Sttfbp5jY+ckKokAAMDj5ZJCYq7CwhUAAABYUEkEAAAeL7fMScxNqCQCAADAgkoiAADweFQSragkAgAAwIJKIgAA8HgUEq1IEgEAgMfjdrMVt5sBAABgQSURAAB4PAqJVlQSAQAAYEElEQAAeDzmJFpRSQQAAIAFlUQAAODxKCRaUUkEAACABZVEAADg8ZiTaEUlEQAAABZUEgEAgMejkGhFkggAADwet5utuN0MAAAACyqJAADA41FItLopk8TEHyfaHQJgUbDlWLtDAFyc+GaE3SEAyMVuyiQRAADAHcxJtGJOIgAAACyoJAIAAI9HIdGKSiIAAAAsqCQCAACPx5xEK5JEAADg8cgRrbjdDAAAAAsqiQAAwONxu9mKSiIAAAAsqCQCAACPRyXRikoiAAAALKgkAgAAj0ch0YpKIgAAACyoJAIAAI/HnEQrkkQAAODxyBGtuN0MAAAACyqJAADA43G72YpKIgAAACyoJAIAAI9HIdGKSiIAAAAsqCQCAACP50Up0YJKIgAAACyoJAIAAI9HIdGKJBEAAHg8tsCx4nYzAAAALKgkAgAAj+dFIdGCSiIAAAAsqCQCAACPx5xEKyqJAAAAsKCSCAAAPB6FRCsqiQAAALCgkggAADyeQ5QS/4kkEQAAeDy2wLHidjMAAAAsSBIBAIDHczgcOfZyR3R0tG677TYFBgaqaNGi6tChg3bt2uXSxxij0aNHKzw8XHny5FHjxo21Y8cOlz6pqanq16+fChcurHz58qldu3Y6ePCgW7HkiiQxPT1dK1as0HvvvadTp05Jkg4fPqzTp0/bHBkAAMD1s3btWvXp00fff/+9li9frvT0dLVo0UJnzpxx9hk/frzefPNNTZo0SZs2bVJYWJiaN2/uzKEkacCAAVq4cKHmzZun9evX6/Tp07rnnnuUkZGR5VgcxhiTrZ/OTX/++adatWql/fv3KzU1Vbt371aZMmU0YMAAnTt3Tu+++67bY55Ns/UjAZdUqFW03SEALk58M8LuEAAXATaulOjwweYcG3vRo3Wu+tyjR4+qaNGiWrt2re666y4ZYxQeHq4BAwZo2LBhki5UDUNDQzVu3Dg9/vjjSkpKUpEiRTRr1ix17txZ0oXiW0REhJYsWaKWLVtm6dq2VxL79++vOnXq6MSJE8qTJ4+zvWPHjlq5cqWNkQEAAFy71NRUJScnu7xSU1OzdG5SUpIkKSQkRJIUFxenhIQEtWjRwtnH399fjRo10oYNGyRJW7ZsUVpamkuf8PBwVatWzdknK2xPEtevX6/nn39efn5+Lu2lSpXSoUOHbIoKAAB4Ei+HI8de0dHRCg4OdnlFR1/57pIxRoMGDdKdd96patWqSZISEhIkSaGhoS59Q0NDnccSEhLk5+enggULXrZPVti+BU5mZuYl748fPHhQgYGBNkQEAACQfYYPH65Bgwa5tPn7+1/xvL59+2rbtm1av3695dg/F8QYY664SCYrff7O9kpi8+bN9dZbbznfOxwOnT59WqNGjdLdd99tX2AAAMBjOBw59/L391dQUJDL60pJYr9+/fTFF19o9erVKlGihLM9LCxMkiwVwSNHjjiri2FhYTp//rxOnDhx2T5ZYXuSOGHCBK1du1ZVqlTRuXPn1KVLF5UuXVqHDh3SuHHj7A4PAAB4gNyyBY4xRn379tWCBQu0atUqRUZGuhyPjIxUWFiYli9f7mw7f/681q5dqwYNGkiSateuLV9fX5c+8fHx2r59u7NPVmTpdvMXX3yR5QHbtWuX5b7ShYmUP//8s+bOnauffvpJmZmZ6tWrl7p27eqykAUAAOBm16dPH82ZM0eff/65AgMDnRXD4OBg5cmTRw6HQwMGDNDYsWNVvnx5lS9fXmPHjlXevHnVpUsXZ99evXpp8ODBKlSokEJCQvTMM8+oevXqatasWZZjydIWOF5eWSs4OhwOt/bfkaSzZ88qb968bp1zxTHZAge5EFvgILdhCxzkNnZugXN/zE85NvZ/u9+a5b6Xqzx+9NFH6t69u6QL1cYxY8bovffe04kTJ1SvXj1NnjzZubhFks6dO6chQ4Zozpw5SklJUVRUlKZMmaKIiIisx2L3Pon58+dXhw4d9PDDD6t58+ZZTkj/DUkiciOSROQ2JInIbUgSc5drysjOnTt3zQHMnDlTqamp6tixo8LDw9W/f39t2rTpmscFAADIqpzcAudG5XaSmJGRoZdeeknFixdX/vz5tXfvXknSCy+8oOnTp7sdQKdOnfTf//5Xf/31l6KjoxUbG6sGDRqoQoUKevHFF90eDwAAANfO7STxlVdeUUxMjMaPH++yAXb16tX1wQcfXHUggYGB6tGjh5YtW6ZffvlF+fLl05gxY656PAAAgKxy5ODrRuV2kjhz5ky9//776tq1q7y9vZ3tt9xyi3bu3HnVgZw7d07z589Xhw4ddOuttyoxMVHPPPPMVY8HAACAq+f2FNFDhw6pXLlylvbMzEylpaW5HcCyZcs0e/ZsLVq0SN7e3rrvvvv0zTffqFGjRm6PBQAAcDXc3c/QE7idJFatWlXffvutSpUq5dL+3//+V7Vq1XI7gA4dOqhNmzaaMWOG2rRpI19fX7fHAAAAuBZe5IgWbieJo0aN0sMPP6xDhw4pMzNTCxYs0K5duzRz5kx9+eWXbgeQkJCgoKAgt88DAABAznE7SWzbtq0++eQTjR07Vg6HQyNHjtStt96qxYsXq3nz5lkaIzk52SUxTE5OvmxfEkgAAJDTuN1sdVXbVrZs2VItW7a86osWLFhQ8fHxKlq0qAoUKHDJvzHGmKt6ggsAAACu3VXvbb5582bFxsbK4XCocuXKql27dpbPXbVqlUJCQiRJq1evvtoQAAAAsgWFRCu3k8SDBw/qoYce0nfffacCBQpIkk6ePKkGDRpo7ty5WXom4MWVy+np6VqzZo169uzp1rMEAQAAkLPc3iexZ8+eSktLU2xsrI4fP67jx48rNjZWxhj16tXLrbF8fHz0+uuvc0sZAADYyuFw5NjrRuV2kvjtt99q6tSpqlixorOtYsWKmjhxor799lu3A4iKitKaNWvcPg8AAAA5x+3bzSVLlrzkptnp6ekqXry42wG0bt1aw4cP1/bt21W7dm3ly5fP5Xi7du3cHhMAAMAd7JNo5XaSOH78ePXr10+TJ09W7dq15XA4tHnzZvXv31+vv/662wE8+eSTkqQ333zTcozVzQAA4Hq4kW8L55QsJYkFCxZ0+fLOnDmjevXqycfnwunp6eny8fFRz5491aFDB7cCyMzMdKs/AAAAcl6WksS33norh8MAAACwD3VEqywlid26dcuRi2dmZiomJkYLFizQvn375HA4FBkZqfvuu08PP/wwpV8AAACbXPVm2pKUkpJiWcSS1cfoGWPUrl07LVmyRDVq1FD16tVljFFsbKy6d++uBQsWaNGiRdcSHgAAQJZ4UZiycDtJPHPmjIYNG6b58+crMTHRcjyrC01iYmK0bt06rVy5Uk2aNHE5tmrVKnXo0EEzZ87UI4884m6IAAAAuEZu75M4dOhQrVq1SlOmTJG/v78++OADjRkzRuHh4Zo5c2aWx5k7d65GjBhhSRAlqWnTpnr22Wc1e/Zsd8MDAABwm8ORc68bldtJ4uLFizVlyhTdd9998vHxUcOGDfX8889r7NixbiV127ZtU6tWrS57vHXr1vrll1/cDQ8AAADZwO0k8fjx44qMjJR0Yf7h8ePHJUl33nmn1q1b59Y4oaGhlz0eGhqqEydOuBseAACA23gsn5XbSWKZMmW0b98+SVKVKlU0f/58SRcqjAUKFMjyOBkZGc59Fi/F29tb6enp7oYHAACAbOD2wpUePXrol19+UaNGjTR8+HC1adNGEydOVHp6+iWfmnI5xhh1795d/v7+lzyemprqbmgAAABX5QYu+OUYt5PEgQMHOv/cpEkT7dy5U5s3b1bZsmVVo0aNLI+Tlb0XWdlsj/nz5urTT+bq8OFDkqQy5crpsSf66M6Gd9kcGW5Gvdveqt7tblWp0GBJUuyfRzV21not+3GvfLy9NLpnI7WsW1aRxQoo+UyqVv20Ty98sFrxiaedY/RsU1Odm1ZVzfJhCsrnr7B2byjpDP+hiZy1ZfMmxXw4XbG/bdfRo0c14Z3JahrVzO6wcJXYAsfqmvZJlKSSJUuqZMmSOnDggHr27KkPP/wwS+d99NFH13pp5JDQsFD1GzhYJUuWlCQt/nyRBvbro3mfLlDZcuVtjg43m0PHkvXCtNX64/CFOcj/aVFd/33xft3++HQdOnZKNcuH6dWPv9O2P/5SwcAAvfZUc/33pft151P/+3dIXn9fLd+0V8s37dVLva07JgA5ISXlrCpWrKj2HTtp8IB+docDZLtrThIvOn78uGbMmJHlJPGf9uzZoz/++EN33XWX8uTJI2PMDT3Z80bWqHFTl/d9+w/Ufz+Zp22//EKSiGy3ZOMel/ejP1yr3m1vVd0qxTXj6190z9C5LscHTVqm9VN6KKJokA4cSZYkTVqwSZLUsEbJ6xM0IOnOho10Z8NGdoeBbELKYeX2wpXslpiYqKioKFWoUEF333234uPjJUmPPvqoBg8ebHN0yMjI0NIlXykl5axuqVnT7nBwk/Pycuj+JlWUL8BXP/x26JJ9gvL5KzPT6OTpc9c5OgDwLNlWSbxaAwcOlK+vr/bv36/KlSs72zt37qyBAwfqjTfesDE6z/X77l3q1vUhnT+fqjx58+qNtyepbNlydoeFm1TVyCJaM7GbAvx8dDrlvDqP+kw7/zxm6efv662XHm2iT1bt0Kmz522IFMDNiruXVrYnicuWLdM333yjEiVKuLSXL19ef/755xXPT01NtayEzvDyu+yqaWRN6chIzftsoU4lJ2vl8mUa+dyz+iBmFokicsTuA4mq99h0Fcjvrw4NK2nasLZqMehjl0TRx9tLs17oIC8vh/q/vdTGaAHAM2Q5SezUqdO/Hj958uRVBXDmzBnlzZvX0n7s2LEsJXrR0dEaM2aMS9uI50fquZGjryoeXODr66eSJUtJkqpWq64dO7Zr7scz9fyoF22ODDejtPRM7f3/hSs/7U5Q7YrF1KfTbeo34WtJFxLE2SM7qlRYAbV+Zg5VRADZzvb5d7lQlpPE4ODgKx6/mi1r7rrrLs2cOVMvvfSSpAvl3szMTL322muXfK7zPw0fPlyDBg1yacvw8nM7DlyBMTp/nv9jxvXhcDjk7+st6X8JYtniIWo1eLaOJ6fYHB0AeIYsJ4k5tWXNa6+9psaNG2vz5s06f/68hg4dqh07duj48eP67rvvrni+v7+/peJ4Ns3kSKyeYuJbb+qOhncpLCxMZ86c0TdfL9HmTT9q8rvT7A4NN6ExvRpp2Y97deBIsgLz+un+JlV0V42Sajd8nry9HJozqpNqlQ9Tp+fmy9vLodCC+SRJx0+lKC09U5IUWjCfQkPyqWzxgpKkamWK6tTZVB04kqwTp1jggpxx9swZ7d+/3/n+0MGD2hkbq+DgYBULD7cxMlwN5iRa2T4nsUqVKtq2bZumTp0qb29vnTlzRp06dVKfPn1UrFgxu8PzSImJiXp++FAdO3pU+QMDVb5CRU1+d5pub3CH3aHhJlS0YD5Nf7atwkLyK+lMqrbvPaJ2w+dp1ZZ9KhkarLZ3VJAk/TjtUZfzWgz6WN/+cuH/oB9te6ue79bQeWzFWw9LknqPX6yPv/n1On0SeJodO7br0R7/u4P2+vhoSVK79h310thX7QoLV8mLHNHCYYy56cpuVBKRGxVqFW13CICLE9+MsDsEwEWAjaWrAZ/vzLGx32pfKcfGzkm2/O3Ytm1blvvecsstORgJAAAAlcRLsSVJrFmzphwOh65UxHQ4HMrIyLhOUQEAAOAiW5LEuLg4Oy4LAABwSSxcsbqqJHHWrFl69913FRcXp40bN6pUqVJ66623FBkZqfbt21/x/FKlSl3NZQEAAHCduJ0kTp06VSNHjtSAAQP0yiuvOG8HFyhQQG+99VaWksS/++KLLy7Z7nA4FBAQoHLlyikyMtLdMAEAALKMOYlWbieJEydO1LRp09ShQwe9+ur/lvjXqVNHzzzzjNsBdOjQ4ZLzEy+2ORwO3XnnnVq0aJEKFizo9vgAAABwn9tPoYmLi1OtWrUs7f7+/jpz5ozbASxfvly33Xabli9frqSkJCUlJWn58uWqW7euvvzyS61bt06JiYlXlYACAABkhcORc68blduVxMjISP3888+WeYVff/21qlSp4nYA/fv31/vvv68GDRo426KiohQQEKDHHntMO3bs0FtvvaWePXu6PTYAAEBWeN3I2VwOcTtJHDJkiPr06aNz587JGKMff/xRc+fOVXR0tD744AO3A/jjjz8UFBRkaQ8KCtLevXslSeXLl9exY8fcHhsAAABXx+0ksUePHkpPT9fQoUN19uxZdenSRcWLF9fbb7+tBx980O0AateurSFDhmjmzJkqUqSIJOno0aMaOnSobrvtNknS77//rhIlSrg9NgAAQFa4Pf/OA1zVFji9e/dW7969dezYMWVmZqpo0aJXHcD06dPVvn17lShRQhEREXI4HNq/f7/KlCmjzz//XJJ0+vRpvfDCC1d9DQAAALjnmjbTLly48DUHULFiRcXGxuqbb77R7t27ZYxRpUqV1Lx5c3l5XcjrO3TocM3XAQAAuBymJFpd1cKVf9uV/OI8Qnc4HA61atVKrVq1cvtcAAAAZD+3k8QBAwa4vE9LS9PWrVu1dOlSDRky5KqCWLt2rV5//XXFxsbK4XCocuXKGjJkiBo2bHhV4wEAALiD1c1WbieJ/fv3v2T75MmTtXnzZrcD+Pjjj9WjRw916tRJTz/9tIwx2rBhg6KiohQTE6MuXbq4PSYAAACujcP881EnV2nv3r2qWbOmkpOT3TqvcuXKeuyxxzRw4ECX9jfffFPTpk1TbGys27GcTcuWjwRkq0Ktou0OAXBx4psRdocAuAi4ppUS12bkN7/n2NgvtiyfY2PnpGxb8f3pp58qJCTE7fP27t2rtm3bWtrbtWunuLi47AgNAADgX3k5cu51o3I7Z69Vq5bLwhVjjBISEnT06FFNmTLF7QAiIiK0cuVKlStXzqV95cqVioiIcHs8AAAAXDu3k8R/bkfj5eWlIkWKqHHjxqpUqZLbAQwePFhPP/20fv75ZzVo0EAOh0Pr169XTEyM3n77bbfHAwAAcBcLV6zcShLT09NVunRptWzZUmFhYdkSwJNPPqmwsDC98cYbmj9/vqQL8xQ/+eQTtW/fPluuAQAAAPe4NSfRx8dHTz75pFJTU7M1iI4dO2r9+vVKTExUYmKi1q9fT4IIAACuG4cj517uWrdundq2bavw8HA5HA4tWrTI5Xj37t3lcDhcXrfffrtLn9TUVPXr10+FCxdWvnz51K5dOx08eNCtONxeuFKvXj1t3brV3dOuaMuWLfr44481e/bsHBkfAADgRnDmzBnVqFFDkyZNumyfVq1aKT4+3vlasmSJy/EBAwZo4cKFmjdvntavX6/Tp0/rnnvuUUZGRpbjcHtO4lNPPaXBgwfr4MGDql27tvLly+dy/JZbbnFrvCNHjujBBx/UmjVrVKBAARljlJSUpCZNmmjevHkqUqSIuyECAAC4JTetQm7durVat279r338/f0vO/UvKSlJ06dP16xZs9SsWTNJF/aljoiI0IoVK9SyZcssxZHlSmLPnj2VnJyszp07Ky4uTk8//bTuuOMO1axZU7Vq1XL+r7v69eun5ORk7dixQ8ePH9eJEye0fft2JScn6+mnn3Z7PAAAgNwkNTVVycnJLq9rnbq3Zs0aFS1aVBUqVFDv3r115MgR57EtW7YoLS1NLVq0cLaFh4erWrVq2rBhQ5avkeUkccaMGTp37pzi4uIsr7179zr/111Lly7V1KlTVblyZWdblSpVNHnyZH399ddujwcAAOAuRw7+FR0dreDgYJdXdPTVP2ChdevWmj17tlatWqU33nhDmzZtUtOmTZ2JZ0JCgvz8/FSwYEGX80JDQ5WQkJDl62T5dvPFB7OUKlUqy4NnRWZmpnx9fS3tvr6+yszMzNZrAQAAXEpO3m4ePny4Bg0a5NLm7+9/1eN17tzZ+edq1aqpTp06KlWqlL766it16tTpsucZY1z2ur4StxauuDNwVjVt2lT9+/fX4cOHnW2HDh3SwIEDFRUVle3XAwAAuJ78/f0VFBTk8rqWJPGfihUrplKlSun33y88WjAsLEznz5/XiRMnXPodOXJEoaGhWR7XrSSxQoUKCgkJ+deXuyZNmqRTp06pdOnSKlu2rMqVK6fSpUvr1KlTmjhxotvjAQAAuOtGfixfYmKiDhw4oGLFikmSateuLV9fXy1fvtzZJz4+Xtu3b1eDBg2yPK5bq5vHjBmj4OBgd065ooiICP30009asWKFYmNjZYxRlSpVnKtxAAAAPMnp06e1Z88e5/u4uDj9/PPPzoLc6NGjde+996pYsWLat2+fRowYocKFC6tjx46SpODgYPXq1UuDBw9WoUKFFBISomeeeUbVq1d3K79yK0l88MEHVbRoUXdOuayUlBStXLlS99xzj6QLz2q+OOFy3759WrZsmV588UUFBARky/UAAAAuJyem1F2tzZs3q0mTJs73F+czduvWTVOnTtWvv/6qmTNn6uTJkypWrJiaNGmiTz75RIGBgc5zJkyYIB8fHz3wwANKSUlRVFSUYmJi5O3tneU4HObiipQr8Pb2Vnx8fLYlie+9956+/PJLLV68WJIUGBioqlWrKk+ePJKknTt3aujQoRo4cKDbY59Ny9JHAq6rQq2ufiUbkBNOfDPC7hAAFwFu796cfV5b4/4OLVk1pHGZHBs7J2V5TmIWc8ksmz17tnr27OnSNmfOHK1evVqrV6/Wa6+95nyWMwAAQE66keck5pQsJ4mZmZnZVkWUpN27d6tChQrO9wEBAfLy+l84devW1W+//ZZt1wMAAEDW2VbYTUpKko/P/y5/9OhRl+OZmZnXvBs5AABAVuSiKYm5hltb4GSnEiVKaPv27Zc9vm3bNpUoUeI6RgQAADyVl8ORY68blW1J4t13362RI0fq3LlzlmMpKSkaM2aM2rRpY0NkAAAAsO1284gRIzR//nxVrFhRffv2VYUKFeRwOLRz505NmjRJ6enpGjGClXcAACDn3cgLTHKKbUliaGioNmzYoCeffFLPPvusc/W0w+FQ8+bNNWXKFLceHQMAAIDsY+OORFJkZKSWLl2q48ePO3cWL1eu3FU93g8AAOBq3cBTB3OMrUniRSEhIapbt67dYQAAAOD/5YokEQAAwE5eopT4T7atbgYAAEDuRSURAAB4POYkWpEkAgAAj8cWOFbcbgYAAIAFlUQAAODxbuTH5+UUKokAAACwoJIIAAA8HoVEKyqJAAAAsKCSCAAAPB5zEq2oJAIAAMCCSiIAAPB4FBKtSBIBAIDH49aqFd8JAAAALKgkAgAAj+fgfrMFlUQAAABYUEkEAAAejzqiFZVEAAAAWFBJBAAAHo/NtK2oJAIAAMCCSiIAAPB41BGtSBIBAIDH426zFbebAQAAYEElEQAAeDw207aikggAAAALKokAAMDjUTWz4jsBAACABZVEAADg8ZiTaEUlEQAAABZUEgEAgMejjmhFJREAAAAWVBIBAIDHY06i1U2ZJHrxNxq5UOLS4XaHALgoWPdpu0MAXKT89I5t1+bWqhXfCQAAACxuykoiAACAO7jdbEUlEQAAABZUEgEAgMejjmhFJREAAAAWVBIBAIDHY0qiFZVEAAAAWFBJBAAAHs+LWYkWJIkAAMDjcbvZitvNAAAAsKCSCAAAPJ6D280WVBIBAABgQSURAAB4POYkWlFJBAAAgAWVRAAA4PHYAseKSiIAAEAusm7dOrVt21bh4eFyOBxatGiRy3FjjEaPHq3w8HDlyZNHjRs31o4dO1z6pKamql+/fipcuLDy5cundu3a6eDBg27FQZIIAAA8nsORcy93nTlzRjVq1NCkSZMueXz8+PF68803NWnSJG3atElhYWFq3ry5Tp065ewzYMAALVy4UPPmzdP69et1+vRp3XPPPcrIyMj6d2KMMe6Hn7udS7c7AsAq8+b7Rw03uEL1+tsdAuAi5ad3bLv2stijOTZ2ozJBSk1NdWnz9/eXv7//Fc91OBxauHChOnToIOlCFTE8PFwDBgzQsGHDJF2oGoaGhmrcuHF6/PHHlZSUpCJFimjWrFnq3LmzJOnw4cOKiIjQkiVL1LJlyyzFTSURAAAgB0VHRys4ONjlFR0dfVVjxcXFKSEhQS1atHC2+fv7q1GjRtqwYYMkacuWLUpLS3PpEx4ermrVqjn7ZAULVwAAgMfLyc20hw8frkGDBrm0ZaWKeCkJCQmSpNDQUJf20NBQ/fnnn84+fn5+KliwoKXPxfOzgiQRAAAgB2X11rI7HP+Y7GiMsbT9U1b6/B23mwEAgMfzcuTcKzuFhYVJkqUieOTIEWd1MSwsTOfPn9eJEycu2ycrSBIBAABuEJGRkQoLC9Py5cudbefPn9fatWvVoEEDSVLt2rXl6+vr0ic+Pl7bt2939skKbjcDAACPl5NzEt11+vRp7dmzx/k+Li5OP//8s0JCQlSyZEkNGDBAY8eOVfny5VW+fHmNHTtWefPmVZcuXSRJwcHB6tWrlwYPHqxChQopJCREzzzzjKpXr65mzZplOQ6SRAAAgFxk8+bNatKkifP9xUUv3bp1U0xMjIYOHaqUlBQ99dRTOnHihOrVq6dly5YpMDDQec6ECRPk4+OjBx54QCkpKYqKilJMTIy8vb2zHAf7JALXCfskIrdhn0TkNnbuk7h6V2KOjd2kYqEcGzsnUUkEAAAeLzfdbs4tWLgCAAAACyqJAADA42X3VjU3AyqJAAAAsKCSCAAAPB5zEq2oJAIAAMCCSiIAAPB4bjzS2GNQSQQAAIAFlUQAAODxKCRakSQCAACP58X9ZgtuNwMAAMCCSiIAAPB41BGtqCQCAADAgkoiAAAApUQLKokAAACwoJIIAAA8Ho/ls6KSCAAAAAsqiQAAwOOxTaIVSSIAAPB45IhW3G4GAACABZVEAAAASokWVBIBAABgQSURAAB4PLbAsaKSCAAAAAvbk8Q//vhDzz//vB566CEdOXJEkrR06VLt2LHD5sgAAICncDhy7nWjsjVJXLt2rapXr64ffvhBCxYs0OnTpyVJ27Zt06hRo+wMDQAAwKPZmiQ+++yzevnll7V8+XL5+fk525s0aaKNGzfaGBkAAPAkjhx83ahsTRJ//fVXdezY0dJepEgRJSYm2hARAADwSGSJFrYmiQUKFFB8fLylfevWrSpevLgNEQEAAECyOUns0qWLhg0bpoSEBDkcDmVmZuq7777TM888o0ceecTO0AAAgAdx5OBfNypbk8RXXnlFJUuWVPHixXX69GlVqVJFd911lxo0aKDnn3/eztAAAAA8msMYY+wO4o8//tDWrVuVmZmpWrVqqXz58tc03rn0bAoMyEaZ9v+jBrgoVK+/3SEALlJ+ese2a/+8/1SOjV2zZGCOjZ2TcsUTV8qWLasyZcpIkhw38oZCAAAANwnbN9OePn26qlWrpoCAAAUEBKhatWr64IMP7A4LAAB4EBY3W9laSXzhhRc0YcIE9evXT/Xr15ckbdy4UQMHDtS+ffv08ssv2xkeAACAx7J1TmLhwoU1ceJEPfTQQy7tc+fOVb9+/XTs2LGrGpc5iciNmJOI3IY5icht7JyT+MuBnJuTWCOCOYluy8jIUJ06dSzttWvXVno6mR4AALg+buStanKKrXMS//Of/2jq1KmW9vfff19du3a1ISIAAABINlQSBw0a5Pyzw+HQBx98oGXLlun222+XJH3//fc6cOAAm2kDAIDrhs1VrK57krh161aX97Vr15Z0Ya9E6cJzm4sUKaIdO3Zc79AAAADw/657krh69errfUkAAIB/RSHRyvZ9EgEAAJD72Lq6uUmTJv/6hJVVq1Zdx2gAAIDHopRoYWuSWLNmTZf3aWlp+vnnn7V9+3Z169bNnqAAAABgb5I4YcKES7aPHj1ap0+fvs7R4KItmzcp5sPpiv1tu44ePaoJ70xW06hmdocFDzZ/3lx9+slcHT58SJJUplw5PfZEH93Z8C6bI8PNqPd9d6r3/XeoVLFCkqTYvfEa+/5SLdsQa+k78bnOevTeOzTk9QWaNGeNJKlgUF698ERrRd1eSSVCCyrx5GktXvOrxkz9Ssmnz13PjwI3sE+ila1J4uX85z//Ud26dfX666/bHYpHSkk5q4oVK6p9x04aPKCf3eEACg0LVb+Bg1WyZElJ0uLPF2lgvz6a9+kClS1X3ubocLM5dOSkXnhnsf44cFSS9J+2dfXfCb11+0PjFbs3wdmvbePquq1aKR0+ctLl/GJFglWsSLCGv/W5YvcmqGSxgpo4orOKFQlWl6EfXs+PAlyTXJkkbty4UQEBAXaH4bHubNhIdzZsZHcYgFOjxk1d3vftP1D//WSetv3yC0kist2Sddtd3o+e/JV633en6lYv7UwSw4sEa8Kw+9W2zxQtfOdxl/6//RGvh4b8LxmMO3hMoyd/qQ9ffkTe3l7KyMjM+Q8Bt7FPopWtSWKnTp1c3htjFB8fr82bN+uFF16wKSoAuVlGRoaWf7NUKSlndcs/5jUD2c3Ly6F7m9VSvjz++mHbPkkXHgQx/eWHNWHmSpfK4r8Jyp9HyWfOkSDmYuSIVrYmiUFBQS6rm728vFSxYkW9+OKLatGihY2RAchtft+9S926PqTz51OVJ29evfH2JJUtW87usHCTqlqumNbEDFKAn49Op6Sq8+APtDPuQkI4uHszpadnavLctVkaKyQ4r4b3bqnpn32XkyED2c7WJDEmJuaax0hNTVVqaqpLm/H2l7+//zWPDSD3KB0ZqXmfLdSp5GStXL5MI597Vh/EzCJRRI7Yve+I6j00TgXy51GHqJqa9uJ/1OLRd5QnwFd9HmqkBl3GZ2mcwHwBWvjOE4rdm6BX3v86h6PGNaGUaGHrZtplypRRYmKipf3kyZMqU6ZMlsaIjo5WcHCwy+u1cdHZHSoAm/n6+qlkyVKqWq26nh44WBUqVtLcj2faHRZuUmnpGdp74Jh+ij2gkZMW69fdh9SnSyPdUausiobk1+4lY3Tqxwk69eMElQovpFcHdtDOL0e5jJE/r7++mPSkTp+9UIlMT+dWM24stlYS9+3bp4yMDEt7amqqDh06lKUxhg8frkGDBrm0GW+qiMBNzxidP3/e7ijgIRwOyd/XR3O++lGrftjlcmzx5Cc156tNmvnFD862wHwBWjz5SaWeT9d9A99X6vn06x0y3MQWOFa2JIlffPGF88/ffPONgoODne8zMjK0cuVKlS5dOktj+ftbby2f45/Fa3L2zBnt37/f+f7QwYPaGRur4OBgFQsPtzEyeKqJb72pOxrepbCwMJ05c0bffL1Emzf9qMnvTrM7NNyExvS9R8u++00HEk4qMJ+/7m95q+6qXV7t+k7V8aSzOp501qV/WnqG/ko8pd//PCLpQgXxyylPKU+Ar3o8P0tB+QIUlO/Cjh1HT5xWZqa57p8JuBq2JIkdOnSQdGGF2D+frOLr66vSpUvrjTfesCEySNKOHdv1aI9HnO9fH3/h9n279h310thX7QoLHiwxMVHPDx+qY0ePKn9goMpXqKjJ707T7Q3usDs03ISKhgRq+ksPK6xwsJJOp2j774fVru9USwXxcmpVjlDd6qUlSb99MdLlWMU2o7U//nh2h4xswBY4Vg5jjG3/SRMZGalNmzapcOHC2ToulUTkRpn2/aMGXFKhev3tDgFwkfLTO7Zde1fC2St3ukoVw/Lm2Ng5ydY5iXFxcXZeHgAAQBKLmy/F1iTxxRdf/NfjI0eO/NfjAAAA2SKXZImjR4/WmDFjXNpCQ0OVkHBhn05jjMaMGaP3339fJ06cUL169TR58mRVrVo122OxNUlcuHChy/u0tDTFxcXJx8dHZcuWJUkEAAAep2rVqlqxYoXzvbe3t/PP48eP15tvvqmYmBhVqFBBL7/8spo3b65du3YpMDAwW+OwNUncunWrpS05OVndu3dXx44dbYgIAAB4oty0BY6Pj4/CwsIs7cYYvfXWW3ruueecjzaeMWOGQkNDNWfOHD3++OOWc66FrZtpX0pQUJBefPFFnt0MAABuCqmpqUpOTnZ5/fNpcX/3+++/Kzw8XJGRkXrwwQe1d+9eSRfWciQkJLg8utjf31+NGjXShg0bsj3uXJckSheeuJKUlGR3GAAAwEM4HDn3utTT4aKjL/10uHr16mnmzJn65ptvNG3aNCUkJKhBgwZKTEx0zksMDQ11Oefvcxazk623m995x3WpuzFG8fHxmjVrllq1amVTVAAAANnnUk+H++eDQC5q3bq188/Vq1dX/fr1VbZsWc2YMUO33367pAv7TP+dMcbSlh1sTRInTJjg8t7Ly0tFihRRt27dNHz4cJuiAgAAniYnZyRe6ulwWZUvXz5Vr15dv//+u/NhJAkJCSpWrJizz5EjRyzVxezAPokAAAC5VGpqqmJjY9WwYUNFRkYqLCxMy5cvV61atSRJ58+f19q1azVu3Lhsv7atSeLfHTx4UA6HQ8WLF7c7FAAA4GlyyeLmZ555Rm3btlXJkiV15MgRvfzyy0pOTla3bt3kcDg0YMAAjR07VuXLl1f58uU1duxY5c2bV126dMn2WGxduJKZmakXX3xRwcHBKlWqlEqWLKkCBQropZdeUmZmpp2hAQAAD+LIwb/ccfDgQT300EOqWLGiOnXqJD8/P33//fcqVaqUJGno0KEaMGCAnnrqKdWpU0eHDh3SsmXLsn2PRMnmZzcPHz5c06dP15gxY3THHXfIGKPvvvtOo0ePVu/evfXKK69c1bg8uxm5Ec9uRm7Ds5uR29j57Oa9R8/l2NhligTk2Ng5ydbbzTNmzNAHH3ygdu3aOdtq1Kih4sWL66mnnrrqJBEAAMAdObA4+IZn6+3m48ePq1KlSpb2SpUq6fjx4zZEBAAAAMmmJPHgwYOSLlQNJ02aZDk+adIk1ahR43qHBQAAPJQjB183KltuN1erVk0TJ07Ua6+9prvvvlsrVqxQ/fr15XA4tGHDBh04cEBLliyxIzQAAADIpkri2LFj1adPH7399tuKjY1Vp06ddPLkSR0/flydOnXSrl271LBhQztCAwAAnohSooVtq5vj4uLUq1cv/fbbb3rvvffUvn37bBub1c3IjVjdjNyG1c3Ibexc3bwvMedWN5cuxOpmt0RGRmrVqlWaNGmS7rvvPlWuXFk+Pq7h/PTTTzZFBwAAPIm7+xl6Alu3wPnzzz/12WefKSQkRO3bt7ckiQAAANcDW+BY2ZaVTZs2TYMHD1azZs20fft2FSlSxK5QAAAA8A+2JImtWrXSjz/+qEmTJumRRx6xIwQAAAAnColWtiSJGRkZ2rZtm0qUKGHH5QEAAHAFtiSJy5cvt+OyAAAAl8ScRCtbH8sHAACA3InlxAAAAMxKtKCSCAAAAAsqiQAAwOMxJ9GKJBEAAHg8ckQrbjcDAADAgkoiAADweNxutqKSCAAAAAsqiQAAwOM5mJVoQSURAAAAFlQSAQAAKCRaUEkEAACABZVEAADg8SgkWpEkAgAAj8cWOFbcbgYAAIAFlUQAAODx2ALHikoiAAAALKgkAgAAUEi0oJIIAAAACyqJAADA41FItKKSCAAAAAsqiQAAwOOxT6IVSSIAAPB4bIFjxe1mAAAAWFBJBAAAHo/bzVZUEgEAAGBBkggAAAALkkQAAABYMCcRAAB4POYkWlFJBAAAgAWVRAAA4PHYJ9GKJBEAAHg8bjdbcbsZAAAAFlQSAQCAx6OQaEUlEQAAABZUEgEAACglWlBJBAAAgAWVRAAA4PHYAseKSiIAAAAsqCQCAACPxz6JVlQSAQAAYEElEQAAeDwKiVYkiQAAAGSJFtxuBgAAgAVJIgAA8HiOHPzrakyZMkWRkZEKCAhQ7dq19e2332bzJ74ykkQAAIBc5JNPPtGAAQP03HPPaevWrWrYsKFat26t/fv3X9c4HMYYc12veB2cS7c7AsAq8+b7Rw03uEL1+tsdAuAi5ad3bLt2TuYOAW6uAKlXr55uvfVWTZ061dlWuXJldejQQdHR0dkc3eVRSQQAAMhBqampSk5OdnmlpqZesu/58+e1ZcsWtWjRwqW9RYsW2rBhw/UI1+mmXN3sbsaOS0tNTVV0dLSGDx8uf39/u8O5CbB07lrxm8xedlZtbib8Lm8OOZk7jH45WmPGjHFpGzVqlEaPHm3pe+zYMWVkZCg0NNSlPTQ0VAkJCTkX5CXclLebkT2Sk5MVHByspKQkBQUF2R0OwG8SuRK/S1xJamqqpXLo7+9/yf+oOHz4sIoXL64NGzaofv36zvZXXnlFs2bN0s6dO3M83ououQEAAOSgyyWEl1K4cGF5e3tbqoZHjhyxVBdzGnMSAQAAcgk/Pz/Vrl1by5cvd2lfvny5GjRocF1joZIIAACQiwwaNEgPP/yw6tSpo/r16+v999/X/v379cQTT1zXOEgScVn+/v4aNWoUE7GRa/CbRG7E7xLZrXPnzkpMTNSLL76o+Ph4VatWTUuWLFGpUqWuaxwsXAEAAIAFcxIBAABgQZIIAAAAC5JEAAAAWJAk4rL27dsnh8Ohn3/+2e5Q4IHs+P2tWbNGDodDJ0+evG7XhOdp3LixBgwYYHcYwBWRJOZCCQkJ6t+/v8qVK6eAgACFhobqzjvv1LvvvquzZ8/aHd6/6t69uxwOhxwOh3x9fRUaGqrmzZvrww8/VGZmpt3hIQs8+ffXoEEDxcfHKzg4+DpEi5xkjFGzZs3UsmVLy7EpU6YoODhY+/fvv6ZrOBwOLVq06JrGAHIzksRcZu/evapVq5aWLVumsWPHauvWrVqxYoUGDhyoxYsXa8WKFXaHeEWtWrVSfHy89u3bp6+//lpNmjRR//79dc899yg9Pd3u8PAvPPn3l5aWJj8/P4WFhcnh4DnbNzqHw6GPPvpIP/zwg9577z1ne1xcnIYNG6a3335bJUuWtDFC4AZgkKu0bNnSlChRwpw+ffqSxzMzM40xxvz555+mXbt2Jl++fCYwMNDcf//9JiEhwaXvlClTTJkyZYyvr6+pUKGCmTlzpsvx2NhYc8cddxh/f39TuXJls3z5ciPJLFy40BhjTFxcnJFktm7d6jxnx44dpnXr1iZfvnymaNGi5j//+Y85evSo83i3bt1M+/btLXGvXLnSSDLTpk1ztmXlM3z++eemdu3axt/f3xQqVMh07Njxit8hrp4n/f4kmalTp5p27dqZvHnzmpEjR5rVq1cbSebEiRPm5MmTJiAgwHz99dcuY3322Wcmb9685tSpU8YYYw4ePGgeeOABU6BAARMSEmLatWtn4uLi/vV7xvUTExNj8ufPb/bu3WsyMzNNkyZNTPv27c2aNWvMbbfdZvz8/ExYWJgZNmyYSUtLc55XqlQpM2HCBJexatSoYUaNGuU8Lsn5KlWqlDHm0r/B/v37m0aNGjnfN2rUyPTp08f06dPHBAcHm5CQEPPcc885//kyxpjU1FQzZMgQEx4ebvLmzWvq1q1rVq9enY3fDHBlVBJzkcTERC1btkx9+vRRvnz5LtnH4XDIGKMOHTro+PHjWrt2rZYvX64//vhDnTt3dvZbuHCh+vfvr8GDB2v79u16/PHH1aNHD61evVqSlJmZqQ4dOihv3rz64Ycf9P777+u555771/ji4+PVqFEj1axZU5s3b9bSpUv1119/6YEHHrjiZ2vatKlq1KihBQsWSFKWPsNXX32lTp06qU2bNtq6datWrlypOnXqXPFauDqe9Pu7aNSoUWrfvr1+/fVX9ezZ0+VYcHCw2rRpo9mzZ7u0z5kzR+3bt1f+/Pl19uxZNWnSRPnz59e6deu0fv165c+fX61atdL58+evGBdyXrdu3RQVFaUePXpo0qRJ2r59u95++23dfffduu222/TLL79o6tSpmj59ul5++eUsj7tp0yZJ0kcffaT4+Hjn+6yaMWOGfHx89MMPP+idd97RhAkT9MEHHziP9+jRQ999953mzZunbdu26f7771erVq30+++/u3Ud4JrYnKTib77//nsjySxYsMClvVChQiZfvnwmX758ZujQoWbZsmXG29vb7N+/39lnx44dRpL58ccfjTHGNGjQwPTu3dtlnPvvv9/cfffdxhhjvv76a+Pj42Pi4+Odx69UyXnhhRdMixYtXMY8cOCAkWR27dpljLl8JccYYzp37mwqV65sjDFZ+gz169c3Xbt2veL3huzhSb8/Yy5UEgcMGODS5++VRGOMWbBggcmfP785c+aMMcaYpKQkExAQYL766itjjDHTp083FStWtFSA8uTJY7755ptLxoHr76+//jJFihQxXl5eZsGCBWbEiBGWv2+TJ082+fPnNxkZGcaYK1cSjTEuv9eLslpJrFy5ssv1hw0b5vx97tmzxzgcDnPo0CGXcaKioszw4cPd/PTA1aOSmAv9cz7Ujz/+qJ9//llVq1ZVamqqYmNjFRERoYiICGefKlWqqECBAoqNjZUkxcbG6o477nAZ54477nAe37VrlyIiIhQWFuY8Xrdu3X+Na8uWLVq9erXy58/vfFWqVEmS9Mcff1zxcxljnJ8tK5/h559/VlRU1BXHRfbyhN/fRVeqTLdp00Y+Pj764osvJEmfffaZAgMD1aJFC2dMe/bsUWBgoDOmkJAQnTt3Lksx4fooWrSoHnvsMVWuXFkdO3ZUbGys6tev7/J7uOOOO3T69GkdPHjwusR0++23u1y/fv36+v3335WRkaGffvpJxhhVqFDB5fe+du1afle4rnh2cy5Srlw5ORwO7dy506W9TJkykqQ8efJIuvT/2V2q/Z99/n78cmP8m8zMTLVt21bjxo2zHCtWrNgVz4+NjVVkZGSWP8PFz4vrw5N+fxdd7rb6RX5+frrvvvs0Z84cPfjgg5ozZ446d+4sHx8fZ0y1a9e23JKWpCJFilwxJlw/Pj4+zr9vl/r9mf9/Qu3Fdi8vL2fbRWlpaVe8ztWe93eZmZny9vbWli1b5O3t7XIsf/78bo0FXAsqiblIoUKF1Lx5c02aNElnzpy5bL8qVapo//79OnDggLPtt99+U1JSkipXrixJqly5stavX+9y3oYNG5zHK1WqpP379+uvv/5yHr/SnJpbb71VO3bsUOnSpVWuXDmX15X+z3bVqlX69ddfde+992b5M9xyyy1auXLlv46L7ONJvz93dO3aVUuXLtWOHTu0evVqde3a1SWm33//XUWLFrXExDY6uVeVKlW0YcMGl2Ruw4YNCgwMVPHixSVdSPLj4+Odx5OTkxUXF+cyjq+vrzIyMlza/nmepEvu9fn9999b3pcvX17e3t6qVauWMjIydOTIEcvv6u/VdyDHXe/72/h3e/bsMaGhoaZSpUpm3rx55rfffjM7d+40s2bNMqGhoWbQoEEmMzPT1KpVyzRs2NBs2bLF/PDDD6Z27douc14WLlxofH19zdSpU83u3bvNG2+8Yby9vZ2r49LT003FihVNy5YtzS+//GLWr19v6tWrZySZRYsWGWOsc8IOHTpkihQpYu677z7zww8/mD/++MN88803pkePHiY9Pd0Yc2E+TqtWrUx8fLw5ePCg2bJli3nllVdM/vz5zT333OPsl5XPsHr1auPl5WVGjhxpfvvtN7Nt2zYzbty4HP974Mk85fdnzKXnk/1zTqIxF36rJUqUMDVq1DBly5Z16X/mzBlTvnx507hxY7Nu3Tqzd+9es2bNGvP000+bAwcOZM/fFGSLUaNGmRo1ahhjLqxIz5s3r+nTp4+JjY01ixYtMoULF3aZb/jss8+asLAws27dOvPrr7+aDh06mPz587v0KV++vHnyySdNfHy8OX78uDHGmKVLlxqHw2FmzJhhdu/ebUaOHGmCgoIscxLz589vBg4caHbu3GnmzJlj8uXLZ959911nn65du5rSpUubzz77zOzdu9f8+OOP5tVXX3XOhwWuB5LEXOjw4cOmb9++JjIy0vj6+pr8+fObunXrmtdee805gT47tyDx8/MzlSpVMosXLzaSzNKlS40xl96CZPfu3aZjx46mQIECJk+ePKZSpUpmwIABzgnY3bp1c24J4ePjY4oUKWKaNWtmPvzwQ+eE8Iuy8hk+++wzU7NmTePn52cKFy5sOnXqlC3fMS7PU35/WU0SjTFmyJAhRpIZOXKk5fuKj483jzzyiClcuLDx9/c3ZcqUMb179zZJSUlZ/s6R8/6eJBpjrrgFTlJSknnggQdMUFCQiYiIMDExMZaFK1988YUpV66c8fHxcW6BY4wxI0eONKGhoSY4ONgMHDjQ9O3b15IkPvXUU+aJJ54wQUFBpmDBgubZZ591Wchy/vx5M3LkSFO6dGnj6+trwsLCTMeOHc22bdty4usBLslhzD8mT8Bjfffdd7rzzju1Z88elS1b1u5w4GH4/QFA7kKS6MEWLlyo/Pnzq3z58tqzZ4/69++vggULWuaSATmB3x8A5G6sbvZgp06d0tChQ3XgwAEVLlxYzZo10xtvvGF3WPAQ/P4AIHejkggAAAALtsABAACABUkiAAAALEgSAQAAYEGSCAAAAAuSRAAAAFiQJALINqNHj1bNmjWd77t3764OHTpc9zj27dsnh8NxyWfmZpd/ftarcT3iBICrRZII3OS6d+8uh8Mhh8MhX19flSlTRs8884zOnDmT49d+++23FRMTk6W+1zthaty4sQYMGHBdrgUANyI20wY8QKtWrfTRRx8pLS1N3377rR599FGdOXNGU6dOtfRNS0uTr69vtlw3ODg4W8YBAFx/VBIBD+Dv76+wsDBFRESoS5cu6tq1qxYtWiTpf7dNP/zwQ5UpU0b+/v4yxigpKUmPPfaYihYtqqCgIDVt2lS//PKLy7ivvvqqQkNDFRgYqF69euncuXMux/95uzkzM1Pjxo1TuXLl5O/vr5IlS+qVV16RJEVGRkqSatWqJYfDocaNGzvP++ijj1S5cmUFBASoUqVKmjJlist1fvzxR9WqVUsBAQGqU6eOtm7des3f2bBhw1ShQgXlzZtXZcqU0QsvvKC0tDRLv/fee08RERHKmzev7r//fp08edLl+JViB4Dcikoi4IHy5MnjkvDs2bNH8+fP12effSZvb29JUps2bRQSEqIlS5YoODhY7733nqKiorR7926FhIRo/vz5GjVqlCZPnqyGDRtq1qxZeuedd1SmTJnLXnf48OGaNm2aJkyYoDvvvFPx8fHauXOnpAuJXt26dbVixQpVrVpVfn5+kqRp06Zp1KhRmjRpkmrVqqWtW7eqd+/eypcvn7p166YzZ87onnvuUdOmTfXxxx8rLi5O/fv3v+bvKDAwUDExMQoPD9evv/6q3r17KzAwUEOHDrV8b4sXL1ZycrJ69eqlPn36aPbs2VmKHQByNQPgptatWzfTvn175/sffvjBFCpUyDzwwAPGGGNGjRplfH19zZEjR5x9Vq5caYKCgsy5c+dcxipbtqx57733jDHG1K9f3zzxxBMux+vVq2dq1KhxyWsnJycbf39/M23atEvGGRcXZySZrVu3urRHRESYOXPmuLS99NJLpn79+sYYY9577z0TEhJizpw54zw+derUS471d40aNTL9+/e/7PF/Gj9+vKldu7bz/ahRo4y3t7c5cOCAs+3rr782Xl5eJj4+PkuxX+4zA0BuQCUR8ABffvml8ufPr/T0dKWlpal9+/aaOHGi83ipUqVUpEgR5/stW7bo9OnTKlSokMs4KSkp+uOPPyRJsbGxeuKJJ1yO169fX6tXr75kDLGxsUpNTVVUVFSW4z569KgOHDigXr16qXfv3s729PR053zH2NhY1ahRQ3nz5nWJ41p9+umneuutt7Rnzx6dPn1a6enpCgoKculTsmRJlShRwuW6mZmZ2rVrl7y9va8YOwDkZiSJgAdo0qSJpk6dKl9fX4WHh1sWpuTLl8/lfWZmpooVK6Y1a9ZYxipQoMBVxZAnTx63z8nMzJR04bZtvXr1XI5dvC1ujLmqeP7N999/rwcffFBjxoxRy5YtFRwcrHnz5umNN9741/McDofzf7MSOwDkZiSJgAfIly+fypUrl+X+t956qxISEuTj46PSpUtfsk/lypX1/fff65FHHnG2ff/995cds3z58sqTJ49WrlypRx991HL84hzEjIwMZ1toaKiKFy+uvXv3qmvXrpcct0qVKpo1a5ZSUlKciei/xZEV3333nUqVKqXnnnvO2fbnn39a+u3fv1+HDx9WeHi4JGnjxo3y8vJShQoVshQ7AORmJIkALJo1a6b69eurQ4cOGjdunCpWrKjDhw9ryZIl6tChg+rUqaP+/furW7duqlOnju68807Nnj1bO3bsuOzClYCAAA0bNkxDhw6Vn5+f7rjjDh09elQ7duxQr169VLRoUeXJk0dLly5ViRIlFBAQoODgYI0ePVpPP/20goKC1Lp1a6Wmpmrz5s06ceKEBg0apC5duui5555Tr1699Pzzz2vfvn16/fXXs/Q5jx49atmXMSwsTOXKldP+/fs1b9483Xbbbfrqq6+0cOHCS36mbt266fXXX1dycrKefvppPfDAAwoLC5OkK8YOALma3ZMiAeSsfy5c+adRo0a5LDa5KDk52fTr18+Eh4cbX19fExERYbp27Wr279/v7PPKK6+YwoULm/z585tu3bqZoUOHXnbhijHGZGRkmJdfftmUKlXK+Pr6mpIlS5qxY8c6j0+bNs1EREQYLy8v06hRI2f77NmzTc2aNY2fn58pWLCgueuuu8yCBQucxzdu3Ghq1Khh/Pz8TM2aNc1nn32WpYUrkiyvUaNGGWOMGTJkiClUqJDJnz+/6dy5s5kwYYIJDg62fG9Tpkwx4eHhJiAgwHTq1MkcP37c5Tr/FjsLVwDkZg5jcmBCDwAAAG5obKYNAAAAC5JEAAAAWJAkAgAAwIIkEQAAABYkiQAAALAgSQQAAIAFSSIAAAAsSBIBAABgQZIIAAAAC5JEAAAAWJAkAgAAwOL/ALf8Xbb6diLjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the confusion matrix\n",
    "category_labels = ['GoogleDoc', 'GoogleDrive', 'Youtube']\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=category_labels, yticklabels=category_labels)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2523fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(classifier, 'quic_text_rf_pooling.joblib') # put model here to export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d42918",
   "metadata": {},
   "source": [
    "# Trustee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af7808f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing training dataset using RandomForestClassifier(random_state=42) as expert model\n",
      "Expert model score: 1.0\n",
      "Initializing Trustee outer-loop with 10 iterations\n",
      "########## Outer-loop Iteration 0/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (1660, 1660) entries\n",
      "Student model 0-0 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9312484108822782\n",
      "Student model 0-0 fidelity: 0.9312484108822782\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (1810, 1810) entries\n",
      "Student model 0-1 trained with depth 9 and 13 leaves:\n",
      "Student model score: 0.9461895199847007\n",
      "Student model 0-1 fidelity: 0.9461895199847007\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (1960, 1960) entries\n",
      "Student model 0-2 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9536836253555213\n",
      "Student model 0-2 fidelity: 0.9536836253555213\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (2110, 2110) entries\n",
      "Student model 0-3 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9391909814323607\n",
      "Student model 0-3 fidelity: 0.9391909814323607\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (2260, 2260) entries\n",
      "Student model 0-4 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9337440500806838\n",
      "Student model 0-4 fidelity: 0.9337440500806838\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (2410, 2410) entries\n",
      "Student model 0-5 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.985439175930846\n",
      "Student model 0-5 fidelity: 0.985439175930846\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (2560, 2560) entries\n",
      "Student model 0-6 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9663383558732396\n",
      "Student model 0-6 fidelity: 0.9663383558732396\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (2710, 2710) entries\n",
      "Student model 0-7 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9716556109228905\n",
      "Student model 0-7 fidelity: 0.9716556109228905\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (2860, 2860) entries\n",
      "Student model 0-8 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9533122853661239\n",
      "Student model 0-8 fidelity: 0.9533122853661239\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (3010, 3010) entries\n",
      "Student model 0-9 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9662115510216776\n",
      "Student model 0-9 fidelity: 0.9662115510216776\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (3160, 3160) entries\n",
      "Student model 0-10 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9271433900146772\n",
      "Student model 0-10 fidelity: 0.9271433900146772\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (3310, 3310) entries\n",
      "Student model 0-11 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9301713753464899\n",
      "Student model 0-11 fidelity: 0.9301713753464899\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (3460, 3460) entries\n",
      "Student model 0-12 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9451686575746726\n",
      "Student model 0-12 fidelity: 0.9451686575746726\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (3610, 3610) entries\n",
      "Student model 0-13 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9733183848814924\n",
      "Student model 0-13 fidelity: 0.9733183848814924\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (3760, 3760) entries\n",
      "Student model 0-14 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9405820374126662\n",
      "Student model 0-14 fidelity: 0.9405820374126662\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (3910, 3910) entries\n",
      "Student model 0-15 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.967237150337605\n",
      "Student model 0-15 fidelity: 0.967237150337605\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (4060, 4060) entries\n",
      "Student model 0-16 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.8989833695716049\n",
      "Student model 0-16 fidelity: 0.8989833695716049\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (4210, 4210) entries\n",
      "Student model 0-17 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9526797606928881\n",
      "Student model 0-17 fidelity: 0.9526797606928881\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (4360, 4360) entries\n",
      "Student model 0-18 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9608058919856672\n",
      "Student model 0-18 fidelity: 0.9608058919856672\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (4510, 4510) entries\n",
      "Student model 0-19 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9451470953546967\n",
      "Student model 0-19 fidelity: 0.9451470953546967\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (4660, 4660) entries\n",
      "Student model 0-20 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9286477680026067\n",
      "Student model 0-20 fidelity: 0.9286477680026067\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (4810, 4810) entries\n",
      "Student model 0-21 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9249158249158249\n",
      "Student model 0-21 fidelity: 0.9249158249158249\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (4960, 4960) entries\n",
      "Student model 0-22 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9738073523983237\n",
      "Student model 0-22 fidelity: 0.9738073523983237\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (5110, 5110) entries\n",
      "Student model 0-23 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9466619995332867\n",
      "Student model 0-23 fidelity: 0.9466619995332867\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (5260, 5260) entries\n",
      "Student model 0-24 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.9568200199079259\n",
      "Student model 0-24 fidelity: 0.9568200199079259\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (5410, 5410) entries\n",
      "Student model 0-25 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9865009355787223\n",
      "Student model 0-25 fidelity: 0.9865009355787223\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (5560, 5560) entries\n",
      "Student model 0-26 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9599788383406281\n",
      "Student model 0-26 fidelity: 0.9599788383406281\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (5710, 5710) entries\n",
      "Student model 0-27 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9813519813519814\n",
      "Student model 0-27 fidelity: 0.9813519813519814\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (5860, 5860) entries\n",
      "Student model 0-28 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9588480871302764\n",
      "Student model 0-28 fidelity: 0.9588480871302764\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (6010, 6010) entries\n",
      "Student model 0-29 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.946598423770269\n",
      "Student model 0-29 fidelity: 0.946598423770269\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (6160, 6160) entries\n",
      "Student model 0-30 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9439849186971614\n",
      "Student model 0-30 fidelity: 0.9439849186971614\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (6310, 6310) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 0-31 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9598362101720674\n",
      "Student model 0-31 fidelity: 0.9598362101720674\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (6460, 6460) entries\n",
      "Student model 0-32 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9532369864846783\n",
      "Student model 0-32 fidelity: 0.9532369864846783\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (6610, 6610) entries\n",
      "Student model 0-33 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9514888264888265\n",
      "Student model 0-33 fidelity: 0.9514888264888265\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (6760, 6760) entries\n",
      "Student model 0-34 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9438136319831708\n",
      "Student model 0-34 fidelity: 0.9438136319831708\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (6910, 6910) entries\n",
      "Student model 0-35 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9626839594659385\n",
      "Student model 0-35 fidelity: 0.9626839594659385\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (7060, 7060) entries\n",
      "Student model 0-36 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.931450990345061\n",
      "Student model 0-36 fidelity: 0.931450990345061\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (7210, 7210) entries\n",
      "Student model 0-37 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9055338032913426\n",
      "Student model 0-37 fidelity: 0.9055338032913426\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (7360, 7360) entries\n",
      "Student model 0-38 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9489041322279471\n",
      "Student model 0-38 fidelity: 0.9489041322279471\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (7510, 7510) entries\n",
      "Student model 0-39 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9729217110573042\n",
      "Student model 0-39 fidelity: 0.9729217110573042\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (7660, 7660) entries\n",
      "Student model 0-40 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9603456458766345\n",
      "Student model 0-40 fidelity: 0.9603456458766345\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (7810, 7810) entries\n",
      "Student model 0-41 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.980542994370428\n",
      "Student model 0-41 fidelity: 0.980542994370428\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (7960, 7960) entries\n",
      "Student model 0-42 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9601661157725231\n",
      "Student model 0-42 fidelity: 0.9601661157725231\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (8110, 8110) entries\n",
      "Student model 0-43 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9678999769341962\n",
      "Student model 0-43 fidelity: 0.9678999769341962\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (8260, 8260) entries\n",
      "Student model 0-44 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9796823263285578\n",
      "Student model 0-44 fidelity: 0.9796823263285578\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (8410, 8410) entries\n",
      "Student model 0-45 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9610774410774411\n",
      "Student model 0-45 fidelity: 0.9610774410774411\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (8560, 8560) entries\n",
      "Student model 0-46 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.926371635610766\n",
      "Student model 0-46 fidelity: 0.926371635610766\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (8710, 8710) entries\n",
      "Student model 0-47 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9384431577979965\n",
      "Student model 0-47 fidelity: 0.9384431577979965\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (8860, 8860) entries\n",
      "Student model 0-48 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9869428750784683\n",
      "Student model 0-48 fidelity: 0.9869428750784683\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (9010, 9010) entries\n",
      "Student model 0-49 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9658435543240563\n",
      "Student model 0-49 fidelity: 0.9658435543240563\n",
      "########## Outer-loop Iteration 1/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (9160, 9160) entries\n",
      "Student model 1-0 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9537720155510696\n",
      "Student model 1-0 fidelity: 0.9537720155510696\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (9310, 9310) entries\n",
      "Student model 1-1 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9330097867808123\n",
      "Student model 1-1 fidelity: 0.9330097867808123\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (9460, 9460) entries\n",
      "Student model 1-2 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9528334366177788\n",
      "Student model 1-2 fidelity: 0.9528334366177788\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (9610, 9610) entries\n",
      "Student model 1-3 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9306693306693307\n",
      "Student model 1-3 fidelity: 0.9306693306693307\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (9760, 9760) entries\n",
      "Student model 1-4 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9738113399440631\n",
      "Student model 1-4 fidelity: 0.9738113399440631\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (9910, 9910) entries\n",
      "Student model 1-5 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9482737790220511\n",
      "Student model 1-5 fidelity: 0.9482737790220511\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (10060, 10060) entries\n",
      "Student model 1-6 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9392964392964392\n",
      "Student model 1-6 fidelity: 0.9392964392964392\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (10210, 10210) entries\n",
      "Student model 1-7 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9614856522774207\n",
      "Student model 1-7 fidelity: 0.9614856522774207\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (10360, 10360) entries\n",
      "Student model 1-8 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9473887814313345\n",
      "Student model 1-8 fidelity: 0.9473887814313345\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (10510, 10510) entries\n",
      "Student model 1-9 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9580668969800238\n",
      "Student model 1-9 fidelity: 0.9580668969800238\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (10660, 10660) entries\n",
      "Student model 1-10 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9630069575275054\n",
      "Student model 1-10 fidelity: 0.9630069575275054\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (10810, 10810) entries\n",
      "Student model 1-11 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.929493482035855\n",
      "Student model 1-11 fidelity: 0.929493482035855\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (10960, 10960) entries\n",
      "Student model 1-12 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9640698643925746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 1-12 fidelity: 0.9640698643925746\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (11110, 11110) entries\n",
      "Student model 1-13 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9282597564504996\n",
      "Student model 1-13 fidelity: 0.9282597564504996\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (11260, 11260) entries\n",
      "Student model 1-14 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9546620335898073\n",
      "Student model 1-14 fidelity: 0.9546620335898073\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (11410, 11410) entries\n",
      "Student model 1-15 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9652759349353777\n",
      "Student model 1-15 fidelity: 0.9652759349353777\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (11560, 11560) entries\n",
      "Student model 1-16 trained with depth 6 and 17 leaves:\n",
      "Student model score: 0.9673037704007871\n",
      "Student model 1-16 fidelity: 0.9673037704007871\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (11710, 11710) entries\n",
      "Student model 1-17 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9467237209550915\n",
      "Student model 1-17 fidelity: 0.9467237209550915\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (11860, 11860) entries\n",
      "Student model 1-18 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9797014905434155\n",
      "Student model 1-18 fidelity: 0.9797014905434155\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (12010, 12010) entries\n",
      "Student model 1-19 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9608465608465608\n",
      "Student model 1-19 fidelity: 0.9608465608465608\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (12160, 12160) entries\n",
      "Student model 1-20 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9264304540753345\n",
      "Student model 1-20 fidelity: 0.9264304540753345\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (12310, 12310) entries\n",
      "Student model 1-21 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.961028710209038\n",
      "Student model 1-21 fidelity: 0.961028710209038\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (12460, 12460) entries\n",
      "Student model 1-22 trained with depth 5 and 14 leaves:\n",
      "Student model score: 0.9598578811369508\n",
      "Student model 1-22 fidelity: 0.9598578811369508\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (12610, 12610) entries\n",
      "Student model 1-23 trained with depth 5 and 15 leaves:\n",
      "Student model score: 0.9280049280049281\n",
      "Student model 1-23 fidelity: 0.9280049280049281\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (12760, 12760) entries\n",
      "Student model 1-24 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9564444444444445\n",
      "Student model 1-24 fidelity: 0.9564444444444445\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (12910, 12910) entries\n",
      "Student model 1-25 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9526619690741828\n",
      "Student model 1-25 fidelity: 0.9526619690741828\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (13060, 13060) entries\n",
      "Student model 1-26 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9635610766045547\n",
      "Student model 1-26 fidelity: 0.9635610766045547\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (13210, 13210) entries\n",
      "Student model 1-27 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.9641511439337057\n",
      "Student model 1-27 fidelity: 0.9641511439337057\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (13360, 13360) entries\n",
      "Student model 1-28 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9668180502682606\n",
      "Student model 1-28 fidelity: 0.9668180502682606\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (13510, 13510) entries\n",
      "Student model 1-29 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9541969214870414\n",
      "Student model 1-29 fidelity: 0.9541969214870414\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (13660, 13660) entries\n",
      "Student model 1-30 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9872891423140889\n",
      "Student model 1-30 fidelity: 0.9872891423140889\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (13810, 13810) entries\n",
      "Student model 1-31 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9277159392957929\n",
      "Student model 1-31 fidelity: 0.9277159392957929\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (13960, 13960) entries\n",
      "Student model 1-32 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.93222364750677\n",
      "Student model 1-32 fidelity: 0.93222364750677\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (14110, 14110) entries\n",
      "Student model 1-33 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9867300455535749\n",
      "Student model 1-33 fidelity: 0.9867300455535749\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (14260, 14260) entries\n",
      "Student model 1-34 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9864673105624058\n",
      "Student model 1-34 fidelity: 0.9864673105624058\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (14410, 14410) entries\n",
      "Student model 1-35 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9514973855284975\n",
      "Student model 1-35 fidelity: 0.9514973855284975\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (14560, 14560) entries\n",
      "Student model 1-36 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9072272360407955\n",
      "Student model 1-36 fidelity: 0.9072272360407955\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (14710, 14710) entries\n",
      "Student model 1-37 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.973202718657264\n",
      "Student model 1-37 fidelity: 0.973202718657264\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (14860, 14860) entries\n",
      "Student model 1-38 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9646959445151584\n",
      "Student model 1-38 fidelity: 0.9646959445151584\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (15010, 15010) entries\n",
      "Student model 1-39 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9492044960885219\n",
      "Student model 1-39 fidelity: 0.9492044960885219\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (15160, 15160) entries\n",
      "Student model 1-40 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9532155797101449\n",
      "Student model 1-40 fidelity: 0.9532155797101449\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (15310, 15310) entries\n",
      "Student model 1-41 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9449418020846592\n",
      "Student model 1-41 fidelity: 0.9449418020846592\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (15460, 15460) entries\n",
      "Student model 1-42 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.950090669876766\n",
      "Student model 1-42 fidelity: 0.950090669876766\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (15610, 15610) entries\n",
      "Student model 1-43 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9008353659410716\n",
      "Student model 1-43 fidelity: 0.9008353659410716\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (15760, 15760) entries\n",
      "Student model 1-44 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9206770081770083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 1-44 fidelity: 0.9206770081770083\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (15910, 15910) entries\n",
      "Student model 1-45 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9539844580179917\n",
      "Student model 1-45 fidelity: 0.9539844580179917\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (16060, 16060) entries\n",
      "Student model 1-46 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9595496023620046\n",
      "Student model 1-46 fidelity: 0.9595496023620046\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (16210, 16210) entries\n",
      "Student model 1-47 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9666646664666466\n",
      "Student model 1-47 fidelity: 0.9666646664666466\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (16360, 16360) entries\n",
      "Student model 1-48 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.931609070491922\n",
      "Student model 1-48 fidelity: 0.931609070491922\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (16510, 16510) entries\n",
      "Student model 1-49 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9666419478432826\n",
      "Student model 1-49 fidelity: 0.9666419478432826\n",
      "########## Outer-loop Iteration 2/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (16660, 16660) entries\n",
      "Student model 2-0 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9417169886643079\n",
      "Student model 2-0 fidelity: 0.9417169886643079\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (16810, 16810) entries\n",
      "Student model 2-1 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9808797739495031\n",
      "Student model 2-1 fidelity: 0.9808797739495031\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (16960, 16960) entries\n",
      "Student model 2-2 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9397341320093537\n",
      "Student model 2-2 fidelity: 0.9397341320093537\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (17110, 17110) entries\n",
      "Student model 2-3 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9149257759784076\n",
      "Student model 2-3 fidelity: 0.9149257759784076\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (17260, 17260) entries\n",
      "Student model 2-4 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9426826472803485\n",
      "Student model 2-4 fidelity: 0.9426826472803485\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (17410, 17410) entries\n",
      "Student model 2-5 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9203571388761941\n",
      "Student model 2-5 fidelity: 0.9203571388761941\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (17560, 17560) entries\n",
      "Student model 2-6 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9676988449112343\n",
      "Student model 2-6 fidelity: 0.9676988449112343\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (17710, 17710) entries\n",
      "Student model 2-7 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9559561201486897\n",
      "Student model 2-7 fidelity: 0.9559561201486897\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (17860, 17860) entries\n",
      "Student model 2-8 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.9407254695879484\n",
      "Student model 2-8 fidelity: 0.9407254695879484\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (18010, 18010) entries\n",
      "Student model 2-9 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9316709501670083\n",
      "Student model 2-9 fidelity: 0.9316709501670083\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (18160, 18160) entries\n",
      "Student model 2-10 trained with depth 9 and 16 leaves:\n",
      "Student model score: 0.957995694438432\n",
      "Student model 2-10 fidelity: 0.957995694438432\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (18310, 18310) entries\n",
      "Student model 2-11 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9203166646775669\n",
      "Student model 2-11 fidelity: 0.9203166646775669\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (18460, 18460) entries\n",
      "Student model 2-12 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.955097444298865\n",
      "Student model 2-12 fidelity: 0.955097444298865\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (18610, 18610) entries\n",
      "Student model 2-13 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9609663628297168\n",
      "Student model 2-13 fidelity: 0.9609663628297168\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (18760, 18760) entries\n",
      "Student model 2-14 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9542208541429725\n",
      "Student model 2-14 fidelity: 0.9542208541429725\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (18910, 18910) entries\n",
      "Student model 2-15 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9531828909920484\n",
      "Student model 2-15 fidelity: 0.9531828909920484\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (19060, 19060) entries\n",
      "Student model 2-16 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9667987172231655\n",
      "Student model 2-16 fidelity: 0.9667987172231655\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (19210, 19210) entries\n",
      "Student model 2-17 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9331851552502188\n",
      "Student model 2-17 fidelity: 0.9331851552502188\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (19360, 19360) entries\n",
      "Student model 2-18 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9532767315843124\n",
      "Student model 2-18 fidelity: 0.9532767315843124\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (19510, 19510) entries\n",
      "Student model 2-19 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.967424984682489\n",
      "Student model 2-19 fidelity: 0.967424984682489\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (19660, 19660) entries\n",
      "Student model 2-20 trained with depth 8 and 17 leaves:\n",
      "Student model score: 0.9265214658701769\n",
      "Student model 2-20 fidelity: 0.9265214658701769\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (19810, 19810) entries\n",
      "Student model 2-21 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9791134791134791\n",
      "Student model 2-21 fidelity: 0.9791134791134791\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (19960, 19960) entries\n",
      "Student model 2-22 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9498736024159754\n",
      "Student model 2-22 fidelity: 0.9498736024159754\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (20110, 20110) entries\n",
      "Student model 2-23 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9672359058565956\n",
      "Student model 2-23 fidelity: 0.9672359058565956\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (20260, 20260) entries\n",
      "Student model 2-24 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9396841060127064\n",
      "Student model 2-24 fidelity: 0.9396841060127064\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (20410, 20410) entries\n",
      "Student model 2-25 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9238128289663948\n",
      "Student model 2-25 fidelity: 0.9238128289663948\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (20560, 20560) entries\n",
      "Student model 2-26 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.967376644630999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 2-26 fidelity: 0.967376644630999\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (20710, 20710) entries\n",
      "Student model 2-27 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9852032520325203\n",
      "Student model 2-27 fidelity: 0.9852032520325203\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (20860, 20860) entries\n",
      "Student model 2-28 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9523811435806424\n",
      "Student model 2-28 fidelity: 0.9523811435806424\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (21010, 21010) entries\n",
      "Student model 2-29 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9521506501866323\n",
      "Student model 2-29 fidelity: 0.9521506501866323\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (21160, 21160) entries\n",
      "Student model 2-30 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9245059267183161\n",
      "Student model 2-30 fidelity: 0.9245059267183161\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (21310, 21310) entries\n",
      "Student model 2-31 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9134363552149564\n",
      "Student model 2-31 fidelity: 0.9134363552149564\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (21460, 21460) entries\n",
      "Student model 2-32 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9370999570999571\n",
      "Student model 2-32 fidelity: 0.9370999570999571\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (21610, 21610) entries\n",
      "Student model 2-33 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9322929058708876\n",
      "Student model 2-33 fidelity: 0.9322929058708876\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (21760, 21760) entries\n",
      "Student model 2-34 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9467905974270897\n",
      "Student model 2-34 fidelity: 0.9467905974270897\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (21910, 21910) entries\n",
      "Student model 2-35 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9802517250191669\n",
      "Student model 2-35 fidelity: 0.9802517250191669\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (22060, 22060) entries\n",
      "Student model 2-36 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9523499204078377\n",
      "Student model 2-36 fidelity: 0.9523499204078377\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (22210, 22210) entries\n",
      "Student model 2-37 trained with depth 5 and 15 leaves:\n",
      "Student model score: 0.9872159090909091\n",
      "Student model 2-37 fidelity: 0.9872159090909091\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (22360, 22360) entries\n",
      "Student model 2-38 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9412474202297211\n",
      "Student model 2-38 fidelity: 0.9412474202297211\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (22510, 22510) entries\n",
      "Student model 2-39 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9795367609409356\n",
      "Student model 2-39 fidelity: 0.9795367609409356\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (22660, 22660) entries\n",
      "Student model 2-40 trained with depth 9 and 18 leaves:\n",
      "Student model score: 0.9397082527401676\n",
      "Student model 2-40 fidelity: 0.9397082527401676\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (22810, 22810) entries\n",
      "Student model 2-41 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9597306397306397\n",
      "Student model 2-41 fidelity: 0.9597306397306397\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (22960, 22960) entries\n",
      "Student model 2-42 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9052203675623138\n",
      "Student model 2-42 fidelity: 0.9052203675623138\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (23110, 23110) entries\n",
      "Student model 2-43 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9704103980896891\n",
      "Student model 2-43 fidelity: 0.9704103980896891\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (23260, 23260) entries\n",
      "Student model 2-44 trained with depth 5 and 14 leaves:\n",
      "Student model score: 0.9338995813379115\n",
      "Student model 2-44 fidelity: 0.9338995813379115\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (23410, 23410) entries\n",
      "Student model 2-45 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9642420197975753\n",
      "Student model 2-45 fidelity: 0.9642420197975753\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (23560, 23560) entries\n",
      "Student model 2-46 trained with depth 6 and 8 leaves:\n",
      "Student model score: 0.960747614170284\n",
      "Student model 2-46 fidelity: 0.960747614170284\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (23710, 23710) entries\n",
      "Student model 2-47 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9467305232431927\n",
      "Student model 2-47 fidelity: 0.9467305232431927\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (23860, 23860) entries\n",
      "Student model 2-48 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9532601402617692\n",
      "Student model 2-48 fidelity: 0.9532601402617692\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (24010, 24010) entries\n",
      "Student model 2-49 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9402557973986546\n",
      "Student model 2-49 fidelity: 0.9402557973986546\n",
      "########## Outer-loop Iteration 3/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (24160, 24160) entries\n",
      "Student model 3-0 trained with depth 6 and 16 leaves:\n",
      "Student model score: 0.9653542319749217\n",
      "Student model 3-0 fidelity: 0.9653542319749217\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (24310, 24310) entries\n",
      "Student model 3-1 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9478195586891239\n",
      "Student model 3-1 fidelity: 0.9478195586891239\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (24460, 24460) entries\n",
      "Student model 3-2 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9511111111111111\n",
      "Student model 3-2 fidelity: 0.9511111111111111\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (24610, 24610) entries\n",
      "Student model 3-3 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.936360884431145\n",
      "Student model 3-3 fidelity: 0.936360884431145\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (24760, 24760) entries\n",
      "Student model 3-4 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9598532357943892\n",
      "Student model 3-4 fidelity: 0.9598532357943892\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (24910, 24910) entries\n",
      "Student model 3-5 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9457252369623502\n",
      "Student model 3-5 fidelity: 0.9457252369623502\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (25060, 25060) entries\n",
      "Student model 3-6 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9589050366171515\n",
      "Student model 3-6 fidelity: 0.9589050366171515\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (25210, 25210) entries\n",
      "Student model 3-7 trained with depth 6 and 9 leaves:\n",
      "Student model score: 1.0\n",
      "Student model 3-7 fidelity: 1.0\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (25360, 25360) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 3-8 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9538777371346386\n",
      "Student model 3-8 fidelity: 0.9538777371346386\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (25510, 25510) entries\n",
      "Student model 3-9 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9447437336326224\n",
      "Student model 3-9 fidelity: 0.9447437336326224\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (25660, 25660) entries\n",
      "Student model 3-10 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.979508146577214\n",
      "Student model 3-10 fidelity: 0.979508146577214\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (25810, 25810) entries\n",
      "Student model 3-11 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9478776792833358\n",
      "Student model 3-11 fidelity: 0.9478776792833358\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (25960, 25960) entries\n",
      "Student model 3-12 trained with depth 8 and 11 leaves:\n",
      "Student model score: 0.968084203378321\n",
      "Student model 3-12 fidelity: 0.968084203378321\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (26110, 26110) entries\n",
      "Student model 3-13 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9534276314241833\n",
      "Student model 3-13 fidelity: 0.9534276314241833\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (26260, 26260) entries\n",
      "Student model 3-14 trained with depth 9 and 17 leaves:\n",
      "Student model score: 0.8804525778997259\n",
      "Student model 3-14 fidelity: 0.8804525778997259\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (26410, 26410) entries\n",
      "Student model 3-15 trained with depth 8 and 17 leaves:\n",
      "Student model score: 0.9612332112332113\n",
      "Student model 3-15 fidelity: 0.9612332112332113\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (26560, 26560) entries\n",
      "Student model 3-16 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9539632063693967\n",
      "Student model 3-16 fidelity: 0.9539632063693967\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (26710, 26710) entries\n",
      "Student model 3-17 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9115752779874917\n",
      "Student model 3-17 fidelity: 0.9115752779874917\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (26860, 26860) entries\n",
      "Student model 3-18 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9554909619402308\n",
      "Student model 3-18 fidelity: 0.9554909619402308\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (27010, 27010) entries\n",
      "Student model 3-19 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9803055246976687\n",
      "Student model 3-19 fidelity: 0.9803055246976687\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (27160, 27160) entries\n",
      "Student model 3-20 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9529852912388707\n",
      "Student model 3-20 fidelity: 0.9529852912388707\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (27310, 27310) entries\n",
      "Student model 3-21 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9869622147399925\n",
      "Student model 3-21 fidelity: 0.9869622147399925\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (27460, 27460) entries\n",
      "Student model 3-22 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9499929905106016\n",
      "Student model 3-22 fidelity: 0.9499929905106016\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (27610, 27610) entries\n",
      "Student model 3-23 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9533513903936438\n",
      "Student model 3-23 fidelity: 0.9533513903936438\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (27760, 27760) entries\n",
      "Student model 3-24 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9865586603782369\n",
      "Student model 3-24 fidelity: 0.9865586603782369\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (27910, 27910) entries\n",
      "Student model 3-25 trained with depth 6 and 8 leaves:\n",
      "Student model score: 0.9469951910752922\n",
      "Student model 3-25 fidelity: 0.9469951910752922\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (28060, 28060) entries\n",
      "Student model 3-26 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9582360137915692\n",
      "Student model 3-26 fidelity: 0.9582360137915692\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (28210, 28210) entries\n",
      "Student model 3-27 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9613903120700061\n",
      "Student model 3-27 fidelity: 0.9613903120700061\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (28360, 28360) entries\n",
      "Student model 3-28 trained with depth 5 and 14 leaves:\n",
      "Student model score: 0.9399693474227635\n",
      "Student model 3-28 fidelity: 0.9399693474227635\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (28510, 28510) entries\n",
      "Student model 3-29 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.8917748917748917\n",
      "Student model 3-29 fidelity: 0.8917748917748917\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (28660, 28660) entries\n",
      "Student model 3-30 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9565613026819922\n",
      "Student model 3-30 fidelity: 0.9565613026819922\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (28810, 28810) entries\n",
      "Student model 3-31 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9165888281678156\n",
      "Student model 3-31 fidelity: 0.9165888281678156\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (28960, 28960) entries\n",
      "Student model 3-32 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9381711855396065\n",
      "Student model 3-32 fidelity: 0.9381711855396065\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (29110, 29110) entries\n",
      "Student model 3-33 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9457314941786992\n",
      "Student model 3-33 fidelity: 0.9457314941786992\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (29260, 29260) entries\n",
      "Student model 3-34 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9662486433319767\n",
      "Student model 3-34 fidelity: 0.9662486433319767\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (29410, 29410) entries\n",
      "Student model 3-35 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9941747081022213\n",
      "Student model 3-35 fidelity: 0.9941747081022213\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (29560, 29560) entries\n",
      "Student model 3-36 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9790291561580378\n",
      "Student model 3-36 fidelity: 0.9790291561580378\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (29710, 29710) entries\n",
      "Student model 3-37 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9361194361194363\n",
      "Student model 3-37 fidelity: 0.9361194361194363\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (29860, 29860) entries\n",
      "Student model 3-38 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9676222104505386\n",
      "Student model 3-38 fidelity: 0.9676222104505386\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (30010, 30010) entries\n",
      "Student model 3-39 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9676986695433297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 3-39 fidelity: 0.9676986695433297\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (30160, 30160) entries\n",
      "Student model 3-40 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.927868067705647\n",
      "Student model 3-40 fidelity: 0.927868067705647\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (30310, 30310) entries\n",
      "Student model 3-41 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9594047986819071\n",
      "Student model 3-41 fidelity: 0.9594047986819071\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (30460, 30460) entries\n",
      "Student model 3-42 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9245009061974311\n",
      "Student model 3-42 fidelity: 0.9245009061974311\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (30610, 30610) entries\n",
      "Student model 3-43 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9472566664649739\n",
      "Student model 3-43 fidelity: 0.9472566664649739\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (30760, 30760) entries\n",
      "Student model 3-44 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9789210497747382\n",
      "Student model 3-44 fidelity: 0.9789210497747382\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (30910, 30910) entries\n",
      "Student model 3-45 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9711862706515113\n",
      "Student model 3-45 fidelity: 0.9711862706515113\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (31060, 31060) entries\n",
      "Student model 3-46 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9803240450627341\n",
      "Student model 3-46 fidelity: 0.9803240450627341\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (31210, 31210) entries\n",
      "Student model 3-47 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9794413418348872\n",
      "Student model 3-47 fidelity: 0.9794413418348872\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (31360, 31360) entries\n",
      "Student model 3-48 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.972475004890907\n",
      "Student model 3-48 fidelity: 0.972475004890907\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (31510, 31510) entries\n",
      "Student model 3-49 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.944890652041174\n",
      "Student model 3-49 fidelity: 0.944890652041174\n",
      "########## Outer-loop Iteration 4/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (31660, 31660) entries\n",
      "Student model 4-0 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9502113715529806\n",
      "Student model 4-0 fidelity: 0.9502113715529806\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (31810, 31810) entries\n",
      "Student model 4-1 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9464064498192939\n",
      "Student model 4-1 fidelity: 0.9464064498192939\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (31960, 31960) entries\n",
      "Student model 4-2 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9476725265331237\n",
      "Student model 4-2 fidelity: 0.9476725265331237\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (32110, 32110) entries\n",
      "Student model 4-3 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9469005847953215\n",
      "Student model 4-3 fidelity: 0.9469005847953215\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (32260, 32260) entries\n",
      "Student model 4-4 trained with depth 8 and 17 leaves:\n",
      "Student model score: 0.9373500761775099\n",
      "Student model 4-4 fidelity: 0.9373500761775099\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (32410, 32410) entries\n",
      "Student model 4-5 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9437530983375377\n",
      "Student model 4-5 fidelity: 0.9437530983375377\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (32560, 32560) entries\n",
      "Student model 4-6 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.941280789558537\n",
      "Student model 4-6 fidelity: 0.941280789558537\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (32710, 32710) entries\n",
      "Student model 4-7 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9332770442700359\n",
      "Student model 4-7 fidelity: 0.9332770442700359\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (32860, 32860) entries\n",
      "Student model 4-8 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.98676926824437\n",
      "Student model 4-8 fidelity: 0.98676926824437\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (33010, 33010) entries\n",
      "Student model 4-9 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9272768633748161\n",
      "Student model 4-9 fidelity: 0.9272768633748161\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (33160, 33160) entries\n",
      "Student model 4-10 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9262394275851579\n",
      "Student model 4-10 fidelity: 0.9262394275851579\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (33310, 33310) entries\n",
      "Student model 4-11 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9143836514129591\n",
      "Student model 4-11 fidelity: 0.9143836514129591\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (33460, 33460) entries\n",
      "Student model 4-12 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.8790427751695358\n",
      "Student model 4-12 fidelity: 0.8790427751695358\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (33610, 33610) entries\n",
      "Student model 4-13 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9797685899310071\n",
      "Student model 4-13 fidelity: 0.9797685899310071\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (33760, 33760) entries\n",
      "Student model 4-14 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9362507136789628\n",
      "Student model 4-14 fidelity: 0.9362507136789628\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (33910, 33910) entries\n",
      "Student model 4-15 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9745834906137132\n",
      "Student model 4-15 fidelity: 0.9745834906137132\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (34060, 34060) entries\n",
      "Student model 4-16 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9339310778368478\n",
      "Student model 4-16 fidelity: 0.9339310778368478\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (34210, 34210) entries\n",
      "Student model 4-17 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.9648735229640488\n",
      "Student model 4-17 fidelity: 0.9648735229640488\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (34360, 34360) entries\n",
      "Student model 4-18 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9654789654789656\n",
      "Student model 4-18 fidelity: 0.9654789654789656\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (34510, 34510) entries\n",
      "Student model 4-19 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9646550153727187\n",
      "Student model 4-19 fidelity: 0.9646550153727187\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (34660, 34660) entries\n",
      "Student model 4-20 trained with depth 8 and 18 leaves:\n",
      "Student model score: 0.9129669723729129\n",
      "Student model 4-20 fidelity: 0.9129669723729129\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (34810, 34810) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 4-21 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9184083105316808\n",
      "Student model 4-21 fidelity: 0.9184083105316808\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (34960, 34960) entries\n",
      "Student model 4-22 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9754655960744953\n",
      "Student model 4-22 fidelity: 0.9754655960744953\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (35110, 35110) entries\n",
      "Student model 4-23 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9719739971460282\n",
      "Student model 4-23 fidelity: 0.9719739971460282\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (35260, 35260) entries\n",
      "Student model 4-24 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9333764224770102\n",
      "Student model 4-24 fidelity: 0.9333764224770102\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (35410, 35410) entries\n",
      "Student model 4-25 trained with depth 5 and 14 leaves:\n",
      "Student model score: 0.9520978498567024\n",
      "Student model 4-25 fidelity: 0.9520978498567024\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (35560, 35560) entries\n",
      "Student model 4-26 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9867880960676801\n",
      "Student model 4-26 fidelity: 0.9867880960676801\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (35710, 35710) entries\n",
      "Student model 4-27 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.903258547008547\n",
      "Student model 4-27 fidelity: 0.903258547008547\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (35860, 35860) entries\n",
      "Student model 4-28 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9598765432098765\n",
      "Student model 4-28 fidelity: 0.9598765432098765\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (36010, 36010) entries\n",
      "Student model 4-29 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9625837575204663\n",
      "Student model 4-29 fidelity: 0.9625837575204663\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (36160, 36160) entries\n",
      "Student model 4-30 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9452212198171585\n",
      "Student model 4-30 fidelity: 0.9452212198171585\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (36310, 36310) entries\n",
      "Student model 4-31 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9584299741533897\n",
      "Student model 4-31 fidelity: 0.9584299741533897\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (36460, 36460) entries\n",
      "Student model 4-32 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9784620397523623\n",
      "Student model 4-32 fidelity: 0.9784620397523623\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (36610, 36610) entries\n",
      "Student model 4-33 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9593747319667211\n",
      "Student model 4-33 fidelity: 0.9593747319667211\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (36760, 36760) entries\n",
      "Student model 4-34 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9708638863842932\n",
      "Student model 4-34 fidelity: 0.9708638863842932\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (36910, 36910) entries\n",
      "Student model 4-35 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9598217439743486\n",
      "Student model 4-35 fidelity: 0.9598217439743486\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (37060, 37060) entries\n",
      "Student model 4-36 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9399523658176464\n",
      "Student model 4-36 fidelity: 0.9399523658176464\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (37210, 37210) entries\n",
      "Student model 4-37 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9860708922647109\n",
      "Student model 4-37 fidelity: 0.9860708922647109\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (37360, 37360) entries\n",
      "Student model 4-38 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9668187268476651\n",
      "Student model 4-38 fidelity: 0.9668187268476651\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (37510, 37510) entries\n",
      "Student model 4-39 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.986313480217377\n",
      "Student model 4-39 fidelity: 0.986313480217377\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (37660, 37660) entries\n",
      "Student model 4-40 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.987160674981658\n",
      "Student model 4-40 fidelity: 0.987160674981658\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (37810, 37810) entries\n",
      "Student model 4-41 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9343048256091735\n",
      "Student model 4-41 fidelity: 0.9343048256091735\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (37960, 37960) entries\n",
      "Student model 4-42 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9511564887124995\n",
      "Student model 4-42 fidelity: 0.9511564887124995\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (38110, 38110) entries\n",
      "Student model 4-43 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.951312775979931\n",
      "Student model 4-43 fidelity: 0.951312775979931\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (38260, 38260) entries\n",
      "Student model 4-44 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9729734622207741\n",
      "Student model 4-44 fidelity: 0.9729734622207741\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (38410, 38410) entries\n",
      "Student model 4-45 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9675979793626852\n",
      "Student model 4-45 fidelity: 0.9675979793626852\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (38560, 38560) entries\n",
      "Student model 4-46 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9503362514783169\n",
      "Student model 4-46 fidelity: 0.9503362514783169\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (38710, 38710) entries\n",
      "Student model 4-47 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9165309004018681\n",
      "Student model 4-47 fidelity: 0.9165309004018681\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (38860, 38860) entries\n",
      "Student model 4-48 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.962023597317715\n",
      "Student model 4-48 fidelity: 0.962023597317715\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (39010, 39010) entries\n",
      "Student model 4-49 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.959163910491344\n",
      "Student model 4-49 fidelity: 0.959163910491344\n",
      "########## Outer-loop Iteration 5/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (39160, 39160) entries\n",
      "Student model 5-0 trained with depth 8 and 15 leaves:\n",
      "Student model score: 0.8872826908541195\n",
      "Student model 5-0 fidelity: 0.8872826908541195\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (39310, 39310) entries\n",
      "Student model 5-1 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9438729952409322\n",
      "Student model 5-1 fidelity: 0.9438729952409322\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (39460, 39460) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 5-2 trained with depth 5 and 16 leaves:\n",
      "Student model score: 0.9321175950486295\n",
      "Student model 5-2 fidelity: 0.9321175950486295\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (39610, 39610) entries\n",
      "Student model 5-3 trained with depth 5 and 14 leaves:\n",
      "Student model score: 0.945765889456274\n",
      "Student model 5-3 fidelity: 0.945765889456274\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (39760, 39760) entries\n",
      "Student model 5-4 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9647522456248186\n",
      "Student model 5-4 fidelity: 0.9647522456248186\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (39910, 39910) entries\n",
      "Student model 5-5 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9225396458220887\n",
      "Student model 5-5 fidelity: 0.9225396458220887\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (40060, 40060) entries\n",
      "Student model 5-6 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9435891857365301\n",
      "Student model 5-6 fidelity: 0.9435891857365301\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (40210, 40210) entries\n",
      "Student model 5-7 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.900484544695071\n",
      "Student model 5-7 fidelity: 0.900484544695071\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (40360, 40360) entries\n",
      "Student model 5-8 trained with depth 4 and 11 leaves:\n",
      "Student model score: 0.9540184453227932\n",
      "Student model 5-8 fidelity: 0.9540184453227932\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (40510, 40510) entries\n",
      "Student model 5-9 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9675081813931744\n",
      "Student model 5-9 fidelity: 0.9675081813931744\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (40660, 40660) entries\n",
      "Student model 5-10 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9475147864199586\n",
      "Student model 5-10 fidelity: 0.9475147864199586\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (40810, 40810) entries\n",
      "Student model 5-11 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9525784157363105\n",
      "Student model 5-11 fidelity: 0.9525784157363105\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (40960, 40960) entries\n",
      "Student model 5-12 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9553479352745488\n",
      "Student model 5-12 fidelity: 0.9553479352745488\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (41110, 41110) entries\n",
      "Student model 5-13 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9732727134641009\n",
      "Student model 5-13 fidelity: 0.9732727134641009\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (41260, 41260) entries\n",
      "Student model 5-14 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9046871626222863\n",
      "Student model 5-14 fidelity: 0.9046871626222863\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (41410, 41410) entries\n",
      "Student model 5-15 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9787017106604736\n",
      "Student model 5-15 fidelity: 0.9787017106604736\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (41560, 41560) entries\n",
      "Student model 5-16 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9650694175245151\n",
      "Student model 5-16 fidelity: 0.9650694175245151\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (41710, 41710) entries\n",
      "Student model 5-17 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.8986350030653828\n",
      "Student model 5-17 fidelity: 0.8986350030653828\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (41860, 41860) entries\n",
      "Student model 5-18 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9401874839282792\n",
      "Student model 5-18 fidelity: 0.9401874839282792\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (42010, 42010) entries\n",
      "Student model 5-19 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9605011957155202\n",
      "Student model 5-19 fidelity: 0.9605011957155202\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (42160, 42160) entries\n",
      "Student model 5-20 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9463944618073059\n",
      "Student model 5-20 fidelity: 0.9463944618073059\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (42310, 42310) entries\n",
      "Student model 5-21 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9799283672998867\n",
      "Student model 5-21 fidelity: 0.9799283672998867\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (42460, 42460) entries\n",
      "Student model 5-22 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9863462470307983\n",
      "Student model 5-22 fidelity: 0.9863462470307983\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (42610, 42610) entries\n",
      "Student model 5-23 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9860219654828127\n",
      "Student model 5-23 fidelity: 0.9860219654828127\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (42760, 42760) entries\n",
      "Student model 5-24 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9256123253083738\n",
      "Student model 5-24 fidelity: 0.9256123253083738\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (42910, 42910) entries\n",
      "Student model 5-25 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9740494458653027\n",
      "Student model 5-25 fidelity: 0.9740494458653027\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (43060, 43060) entries\n",
      "Student model 5-26 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9600136328340484\n",
      "Student model 5-26 fidelity: 0.9600136328340484\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (43210, 43210) entries\n",
      "Student model 5-27 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9341187341187341\n",
      "Student model 5-27 fidelity: 0.9341187341187341\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (43360, 43360) entries\n",
      "Student model 5-28 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9600993350566585\n",
      "Student model 5-28 fidelity: 0.9600993350566585\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (43510, 43510) entries\n",
      "Student model 5-29 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9662261471133292\n",
      "Student model 5-29 fidelity: 0.9662261471133292\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (43660, 43660) entries\n",
      "Student model 5-30 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9877327980372477\n",
      "Student model 5-30 fidelity: 0.9877327980372477\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (43810, 43810) entries\n",
      "Student model 5-31 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.9630579297245964\n",
      "Student model 5-31 fidelity: 0.9630579297245964\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (43960, 43960) entries\n",
      "Student model 5-32 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9255573955408356\n",
      "Student model 5-32 fidelity: 0.9255573955408356\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (44110, 44110) entries\n",
      "Student model 5-33 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9609507640067912\n",
      "Student model 5-33 fidelity: 0.9609507640067912\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (44260, 44260) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 5-34 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9659660645867544\n",
      "Student model 5-34 fidelity: 0.9659660645867544\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (44410, 44410) entries\n",
      "Student model 5-35 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9729607904050095\n",
      "Student model 5-35 fidelity: 0.9729607904050095\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (44560, 44560) entries\n",
      "Student model 5-36 trained with depth 5 and 14 leaves:\n",
      "Student model score: 0.9533290344485792\n",
      "Student model 5-36 fidelity: 0.9533290344485792\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (44710, 44710) entries\n",
      "Student model 5-37 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9600065782035337\n",
      "Student model 5-37 fidelity: 0.9600065782035337\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (44860, 44860) entries\n",
      "Student model 5-38 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9939448490303575\n",
      "Student model 5-38 fidelity: 0.9939448490303575\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (45010, 45010) entries\n",
      "Student model 5-39 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9459191178503685\n",
      "Student model 5-39 fidelity: 0.9459191178503685\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (45160, 45160) entries\n",
      "Student model 5-40 trained with depth 8 and 16 leaves:\n",
      "Student model score: 0.8973274555723929\n",
      "Student model 5-40 fidelity: 0.8973274555723929\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (45310, 45310) entries\n",
      "Student model 5-41 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9801009097930647\n",
      "Student model 5-41 fidelity: 0.9801009097930647\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (45460, 45460) entries\n",
      "Student model 5-42 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9680346792415757\n",
      "Student model 5-42 fidelity: 0.9680346792415757\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (45610, 45610) entries\n",
      "Student model 5-43 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.940710947246895\n",
      "Student model 5-43 fidelity: 0.940710947246895\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (45760, 45760) entries\n",
      "Student model 5-44 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9267399267399267\n",
      "Student model 5-44 fidelity: 0.9267399267399267\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (45910, 45910) entries\n",
      "Student model 5-45 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9272064855474594\n",
      "Student model 5-45 fidelity: 0.9272064855474594\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (46060, 46060) entries\n",
      "Student model 5-46 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9525293272128715\n",
      "Student model 5-46 fidelity: 0.9525293272128715\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (46210, 46210) entries\n",
      "Student model 5-47 trained with depth 5 and 15 leaves:\n",
      "Student model score: 0.9257748424415091\n",
      "Student model 5-47 fidelity: 0.9257748424415091\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (46360, 46360) entries\n",
      "Student model 5-48 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9786734177810711\n",
      "Student model 5-48 fidelity: 0.9786734177810711\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (46510, 46510) entries\n",
      "Student model 5-49 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.951730648335289\n",
      "Student model 5-49 fidelity: 0.951730648335289\n",
      "########## Outer-loop Iteration 6/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (46660, 46660) entries\n",
      "Student model 6-0 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9670775948829573\n",
      "Student model 6-0 fidelity: 0.9670775948829573\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (46810, 46810) entries\n",
      "Student model 6-1 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9593280981555319\n",
      "Student model 6-1 fidelity: 0.9593280981555319\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (46960, 46960) entries\n",
      "Student model 6-2 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.8952309190943124\n",
      "Student model 6-2 fidelity: 0.8952309190943124\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (47110, 47110) entries\n",
      "Student model 6-3 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9725111744021643\n",
      "Student model 6-3 fidelity: 0.9725111744021643\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (47260, 47260) entries\n",
      "Student model 6-4 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.924869395349477\n",
      "Student model 6-4 fidelity: 0.924869395349477\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (47410, 47410) entries\n",
      "Student model 6-5 trained with depth 6 and 17 leaves:\n",
      "Student model score: 0.9041186241938636\n",
      "Student model 6-5 fidelity: 0.9041186241938636\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (47560, 47560) entries\n",
      "Student model 6-6 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9587893587893587\n",
      "Student model 6-6 fidelity: 0.9587893587893587\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (47710, 47710) entries\n",
      "Student model 6-7 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.972\n",
      "Student model 6-7 fidelity: 0.972\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (47860, 47860) entries\n",
      "Student model 6-8 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9623773971600058\n",
      "Student model 6-8 fidelity: 0.9623773971600058\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (48010, 48010) entries\n",
      "Student model 6-9 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9468469735245013\n",
      "Student model 6-9 fidelity: 0.9468469735245013\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (48160, 48160) entries\n",
      "Student model 6-10 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9737023551065297\n",
      "Student model 6-10 fidelity: 0.9737023551065297\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (48310, 48310) entries\n",
      "Student model 6-11 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.986826132400215\n",
      "Student model 6-11 fidelity: 0.986826132400215\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (48460, 48460) entries\n",
      "Student model 6-12 trained with depth 9 and 15 leaves:\n",
      "Student model score: 0.9662604618852783\n",
      "Student model 6-12 fidelity: 0.9662604618852783\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (48610, 48610) entries\n",
      "Student model 6-13 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9611232542891562\n",
      "Student model 6-13 fidelity: 0.9611232542891562\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (48760, 48760) entries\n",
      "Student model 6-14 trained with depth 6 and 16 leaves:\n",
      "Student model score: 0.9386870644368569\n",
      "Student model 6-14 fidelity: 0.9386870644368569\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (48910, 48910) entries\n",
      "Student model 6-15 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9574345825606048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 6-15 fidelity: 0.9574345825606048\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (49060, 49060) entries\n",
      "Student model 6-16 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9610253663761624\n",
      "Student model 6-16 fidelity: 0.9610253663761624\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (49210, 49210) entries\n",
      "Student model 6-17 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9388757502835173\n",
      "Student model 6-17 fidelity: 0.9388757502835173\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (49360, 49360) entries\n",
      "Student model 6-18 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9532831859335493\n",
      "Student model 6-18 fidelity: 0.9532831859335493\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (49510, 49510) entries\n",
      "Student model 6-19 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9349206349206348\n",
      "Student model 6-19 fidelity: 0.9349206349206348\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (49660, 49660) entries\n",
      "Student model 6-20 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9418215452050038\n",
      "Student model 6-20 fidelity: 0.9418215452050038\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (49810, 49810) entries\n",
      "Student model 6-21 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9803542673107889\n",
      "Student model 6-21 fidelity: 0.9803542673107889\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (49960, 49960) entries\n",
      "Student model 6-22 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.926323762308063\n",
      "Student model 6-22 fidelity: 0.926323762308063\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (50110, 50110) entries\n",
      "Student model 6-23 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.965127855409413\n",
      "Student model 6-23 fidelity: 0.965127855409413\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (50260, 50260) entries\n",
      "Student model 6-24 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9863176737328704\n",
      "Student model 6-24 fidelity: 0.9863176737328704\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (50410, 50410) entries\n",
      "Student model 6-25 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9384389772493047\n",
      "Student model 6-25 fidelity: 0.9384389772493047\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (50560, 50560) entries\n",
      "Student model 6-26 trained with depth 7 and 19 leaves:\n",
      "Student model score: 0.917703395968671\n",
      "Student model 6-26 fidelity: 0.917703395968671\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (50710, 50710) entries\n",
      "Student model 6-27 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9803081880625584\n",
      "Student model 6-27 fidelity: 0.9803081880625584\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (50860, 50860) entries\n",
      "Student model 6-28 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.8862517737084575\n",
      "Student model 6-28 fidelity: 0.8862517737084575\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (51010, 51010) entries\n",
      "Student model 6-29 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9617627321276512\n",
      "Student model 6-29 fidelity: 0.9617627321276512\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (51160, 51160) entries\n",
      "Student model 6-30 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9851944001417685\n",
      "Student model 6-30 fidelity: 0.9851944001417685\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (51310, 51310) entries\n",
      "Student model 6-31 trained with depth 6 and 17 leaves:\n",
      "Student model score: 0.9543845258130972\n",
      "Student model 6-31 fidelity: 0.9543845258130972\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (51460, 51460) entries\n",
      "Student model 6-32 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.91818531349581\n",
      "Student model 6-32 fidelity: 0.91818531349581\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (51610, 51610) entries\n",
      "Student model 6-33 trained with depth 5 and 14 leaves:\n",
      "Student model score: 0.9866916245638682\n",
      "Student model 6-33 fidelity: 0.9866916245638682\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (51760, 51760) entries\n",
      "Student model 6-34 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9482335550628234\n",
      "Student model 6-34 fidelity: 0.9482335550628234\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (51910, 51910) entries\n",
      "Student model 6-35 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9867907702972363\n",
      "Student model 6-35 fidelity: 0.9867907702972363\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (52060, 52060) entries\n",
      "Student model 6-36 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9868791941607474\n",
      "Student model 6-36 fidelity: 0.9868791941607474\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (52210, 52210) entries\n",
      "Student model 6-37 trained with depth 8 and 14 leaves:\n",
      "Student model score: 0.9300586887031955\n",
      "Student model 6-37 fidelity: 0.9300586887031955\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (52360, 52360) entries\n",
      "Student model 6-38 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9530228758169935\n",
      "Student model 6-38 fidelity: 0.9530228758169935\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (52510, 52510) entries\n",
      "Student model 6-39 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.965042427227301\n",
      "Student model 6-39 fidelity: 0.965042427227301\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (52660, 52660) entries\n",
      "Student model 6-40 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9098274692334098\n",
      "Student model 6-40 fidelity: 0.9098274692334098\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (52810, 52810) entries\n",
      "Student model 6-41 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9804635228657484\n",
      "Student model 6-41 fidelity: 0.9804635228657484\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (52960, 52960) entries\n",
      "Student model 6-42 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9395033109140617\n",
      "Student model 6-42 fidelity: 0.9395033109140617\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (53110, 53110) entries\n",
      "Student model 6-43 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9313376883546729\n",
      "Student model 6-43 fidelity: 0.9313376883546729\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (53260, 53260) entries\n",
      "Student model 6-44 trained with depth 5 and 14 leaves:\n",
      "Student model score: 0.9615088973442484\n",
      "Student model 6-44 fidelity: 0.9615088973442484\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (53410, 53410) entries\n",
      "Student model 6-45 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9394644423447495\n",
      "Student model 6-45 fidelity: 0.9394644423447495\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (53560, 53560) entries\n",
      "Student model 6-46 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9601137980085349\n",
      "Student model 6-46 fidelity: 0.9601137980085349\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (53710, 53710) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 6-47 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9607493582168617\n",
      "Student model 6-47 fidelity: 0.9607493582168617\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (53860, 53860) entries\n",
      "Student model 6-48 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9877169258508\n",
      "Student model 6-48 fidelity: 0.9877169258508\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (54010, 54010) entries\n",
      "Student model 6-49 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9806523581866884\n",
      "Student model 6-49 fidelity: 0.9806523581866884\n",
      "########## Outer-loop Iteration 7/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (54160, 54160) entries\n",
      "Student model 7-0 trained with depth 5 and 16 leaves:\n",
      "Student model score: 0.9381095734483584\n",
      "Student model 7-0 fidelity: 0.9381095734483584\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (54310, 54310) entries\n",
      "Student model 7-1 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9486021120458207\n",
      "Student model 7-1 fidelity: 0.9486021120458207\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (54460, 54460) entries\n",
      "Student model 7-2 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9718934479842356\n",
      "Student model 7-2 fidelity: 0.9718934479842356\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (54610, 54610) entries\n",
      "Student model 7-3 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9600471767654429\n",
      "Student model 7-3 fidelity: 0.9600471767654429\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (54760, 54760) entries\n",
      "Student model 7-4 trained with depth 5 and 14 leaves:\n",
      "Student model score: 0.943545653907496\n",
      "Student model 7-4 fidelity: 0.943545653907496\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (54910, 54910) entries\n",
      "Student model 7-5 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9576600527564412\n",
      "Student model 7-5 fidelity: 0.9576600527564412\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (55060, 55060) entries\n",
      "Student model 7-6 trained with depth 7 and 18 leaves:\n",
      "Student model score: 0.945806681247582\n",
      "Student model 7-6 fidelity: 0.945806681247582\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (55210, 55210) entries\n",
      "Student model 7-7 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9523809523809522\n",
      "Student model 7-7 fidelity: 0.9523809523809522\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (55360, 55360) entries\n",
      "Student model 7-8 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9734965516532536\n",
      "Student model 7-8 fidelity: 0.9734965516532536\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (55510, 55510) entries\n",
      "Student model 7-9 trained with depth 7 and 17 leaves:\n",
      "Student model score: 0.979511642055196\n",
      "Student model 7-9 fidelity: 0.979511642055196\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (55660, 55660) entries\n",
      "Student model 7-10 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.952034632034632\n",
      "Student model 7-10 fidelity: 0.952034632034632\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (55810, 55810) entries\n",
      "Student model 7-11 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.917872335005986\n",
      "Student model 7-11 fidelity: 0.917872335005986\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (55960, 55960) entries\n",
      "Student model 7-12 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9619294990723563\n",
      "Student model 7-12 fidelity: 0.9619294990723563\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (56110, 56110) entries\n",
      "Student model 7-13 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9675243091364112\n",
      "Student model 7-13 fidelity: 0.9675243091364112\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (56260, 56260) entries\n",
      "Student model 7-14 trained with depth 5 and 14 leaves:\n",
      "Student model score: 0.9332436514679504\n",
      "Student model 7-14 fidelity: 0.9332436514679504\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (56410, 56410) entries\n",
      "Student model 7-15 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9502164502164501\n",
      "Student model 7-15 fidelity: 0.9502164502164501\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (56560, 56560) entries\n",
      "Student model 7-16 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9616126543209876\n",
      "Student model 7-16 fidelity: 0.9616126543209876\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (56710, 56710) entries\n",
      "Student model 7-17 trained with depth 4 and 11 leaves:\n",
      "Student model score: 0.9792303848075962\n",
      "Student model 7-17 fidelity: 0.9792303848075962\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (56860, 56860) entries\n",
      "Student model 7-18 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.959727899582972\n",
      "Student model 7-18 fidelity: 0.959727899582972\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (57010, 57010) entries\n",
      "Student model 7-19 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9597483513371362\n",
      "Student model 7-19 fidelity: 0.9597483513371362\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (57160, 57160) entries\n",
      "Student model 7-20 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.93466608720846\n",
      "Student model 7-20 fidelity: 0.93466608720846\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (57310, 57310) entries\n",
      "Student model 7-21 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9439427111840906\n",
      "Student model 7-21 fidelity: 0.9439427111840906\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (57460, 57460) entries\n",
      "Student model 7-22 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9531484983958199\n",
      "Student model 7-22 fidelity: 0.9531484983958199\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (57610, 57610) entries\n",
      "Student model 7-23 trained with depth 6 and 17 leaves:\n",
      "Student model score: 0.9194080637919188\n",
      "Student model 7-23 fidelity: 0.9194080637919188\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (57760, 57760) entries\n",
      "Student model 7-24 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9534608879923386\n",
      "Student model 7-24 fidelity: 0.9534608879923386\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (57910, 57910) entries\n",
      "Student model 7-25 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9720411806501676\n",
      "Student model 7-25 fidelity: 0.9720411806501676\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (58060, 58060) entries\n",
      "Student model 7-26 trained with depth 9 and 14 leaves:\n",
      "Student model score: 0.932926519196542\n",
      "Student model 7-26 fidelity: 0.932926519196542\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (58210, 58210) entries\n",
      "Student model 7-27 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9589287422285988\n",
      "Student model 7-27 fidelity: 0.9589287422285988\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (58360, 58360) entries\n",
      "Student model 7-28 trained with depth 7 and 18 leaves:\n",
      "Student model score: 0.9064602125602309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 7-28 fidelity: 0.9064602125602309\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (58510, 58510) entries\n",
      "Student model 7-29 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9601195499296766\n",
      "Student model 7-29 fidelity: 0.9601195499296766\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (58660, 58660) entries\n",
      "Student model 7-30 trained with depth 7 and 17 leaves:\n",
      "Student model score: 0.9660714285714285\n",
      "Student model 7-30 fidelity: 0.9660714285714285\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (58810, 58810) entries\n",
      "Student model 7-31 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9774864633798802\n",
      "Student model 7-31 fidelity: 0.9774864633798802\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (58960, 58960) entries\n",
      "Student model 7-32 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.958697868804995\n",
      "Student model 7-32 fidelity: 0.958697868804995\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (59110, 59110) entries\n",
      "Student model 7-33 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9389337685298518\n",
      "Student model 7-33 fidelity: 0.9389337685298518\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (59260, 59260) entries\n",
      "Student model 7-34 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9803731042776894\n",
      "Student model 7-34 fidelity: 0.9803731042776894\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (59410, 59410) entries\n",
      "Student model 7-35 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9391534391534391\n",
      "Student model 7-35 fidelity: 0.9391534391534391\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (59560, 59560) entries\n",
      "Student model 7-36 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9603627695986136\n",
      "Student model 7-36 fidelity: 0.9603627695986136\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (59710, 59710) entries\n",
      "Student model 7-37 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.940824294892514\n",
      "Student model 7-37 fidelity: 0.940824294892514\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (59860, 59860) entries\n",
      "Student model 7-38 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9354924184146195\n",
      "Student model 7-38 fidelity: 0.9354924184146195\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (60010, 60010) entries\n",
      "Student model 7-39 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9663587969398367\n",
      "Student model 7-39 fidelity: 0.9663587969398367\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (60160, 60160) entries\n",
      "Student model 7-40 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9390835326673233\n",
      "Student model 7-40 fidelity: 0.9390835326673233\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (60310, 60310) entries\n",
      "Student model 7-41 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9472507221667356\n",
      "Student model 7-41 fidelity: 0.9472507221667356\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (60460, 60460) entries\n",
      "Student model 7-42 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9570761342885237\n",
      "Student model 7-42 fidelity: 0.9570761342885237\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (60610, 60610) entries\n",
      "Student model 7-43 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9543272864701436\n",
      "Student model 7-43 fidelity: 0.9543272864701436\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (60760, 60760) entries\n",
      "Student model 7-44 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9505340849908092\n",
      "Student model 7-44 fidelity: 0.9505340849908092\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (60910, 60910) entries\n",
      "Student model 7-45 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9455677655677656\n",
      "Student model 7-45 fidelity: 0.9455677655677656\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (61060, 61060) entries\n",
      "Student model 7-46 trained with depth 8 and 16 leaves:\n",
      "Student model score: 0.9442409442409442\n",
      "Student model 7-46 fidelity: 0.9442409442409442\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (61210, 61210) entries\n",
      "Student model 7-47 trained with depth 7 and 18 leaves:\n",
      "Student model score: 0.9791022497067917\n",
      "Student model 7-47 fidelity: 0.9791022497067917\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (61360, 61360) entries\n",
      "Student model 7-48 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9790373867406452\n",
      "Student model 7-48 fidelity: 0.9790373867406452\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (61510, 61510) entries\n",
      "Student model 7-49 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9746817829249105\n",
      "Student model 7-49 fidelity: 0.9746817829249105\n",
      "########## Outer-loop Iteration 8/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (61660, 61660) entries\n",
      "Student model 8-0 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9940970873786407\n",
      "Student model 8-0 fidelity: 0.9940970873786407\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (61810, 61810) entries\n",
      "Student model 8-1 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9534282311726319\n",
      "Student model 8-1 fidelity: 0.9534282311726319\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (61960, 61960) entries\n",
      "Student model 8-2 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9127054695760838\n",
      "Student model 8-2 fidelity: 0.9127054695760838\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (62110, 62110) entries\n",
      "Student model 8-3 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9265092703748167\n",
      "Student model 8-3 fidelity: 0.9265092703748167\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (62260, 62260) entries\n",
      "Student model 8-4 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9677212691602652\n",
      "Student model 8-4 fidelity: 0.9677212691602652\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (62410, 62410) entries\n",
      "Student model 8-5 trained with depth 8 and 17 leaves:\n",
      "Student model score: 0.900485656665432\n",
      "Student model 8-5 fidelity: 0.900485656665432\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (62560, 62560) entries\n",
      "Student model 8-6 trained with depth 8 and 13 leaves:\n",
      "Student model score: 0.9740041825428108\n",
      "Student model 8-6 fidelity: 0.9740041825428108\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (62710, 62710) entries\n",
      "Student model 8-7 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9235444934174516\n",
      "Student model 8-7 fidelity: 0.9235444934174516\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (62860, 62860) entries\n",
      "Student model 8-8 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9687322201607915\n",
      "Student model 8-8 fidelity: 0.9687322201607915\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (63010, 63010) entries\n",
      "Student model 8-9 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9579927301881375\n",
      "Student model 8-9 fidelity: 0.9579927301881375\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (63160, 63160) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 8-10 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9673534994459256\n",
      "Student model 8-10 fidelity: 0.9673534994459256\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (63310, 63310) entries\n",
      "Student model 8-11 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9795367609409356\n",
      "Student model 8-11 fidelity: 0.9795367609409356\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (63460, 63460) entries\n",
      "Student model 8-12 trained with depth 5 and 8 leaves:\n",
      "Student model score: 0.9398830924254652\n",
      "Student model 8-12 fidelity: 0.9398830924254652\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (63610, 63610) entries\n",
      "Student model 8-13 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9860708922647109\n",
      "Student model 8-13 fidelity: 0.9860708922647109\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (63760, 63760) entries\n",
      "Student model 8-14 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9931747465622803\n",
      "Student model 8-14 fidelity: 0.9931747465622803\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (63910, 63910) entries\n",
      "Student model 8-15 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9478850466802274\n",
      "Student model 8-15 fidelity: 0.9478850466802274\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (64060, 64060) entries\n",
      "Student model 8-16 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9725350056586963\n",
      "Student model 8-16 fidelity: 0.9725350056586963\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (64210, 64210) entries\n",
      "Student model 8-17 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9662802780383967\n",
      "Student model 8-17 fidelity: 0.9662802780383967\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (64360, 64360) entries\n",
      "Student model 8-18 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9460381636931502\n",
      "Student model 8-18 fidelity: 0.9460381636931502\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (64510, 64510) entries\n",
      "Student model 8-19 trained with depth 4 and 9 leaves:\n",
      "Student model score: 0.9596553773024361\n",
      "Student model 8-19 fidelity: 0.9596553773024361\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (64660, 64660) entries\n",
      "Student model 8-20 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9593033509700177\n",
      "Student model 8-20 fidelity: 0.9593033509700177\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (64810, 64810) entries\n",
      "Student model 8-21 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9700033704078193\n",
      "Student model 8-21 fidelity: 0.9700033704078193\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (64960, 64960) entries\n",
      "Student model 8-22 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9341228507422494\n",
      "Student model 8-22 fidelity: 0.9341228507422494\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (65110, 65110) entries\n",
      "Student model 8-23 trained with depth 5 and 13 leaves:\n",
      "Student model score: 0.9127819777660867\n",
      "Student model 8-23 fidelity: 0.9127819777660867\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (65260, 65260) entries\n",
      "Student model 8-24 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9665224476411322\n",
      "Student model 8-24 fidelity: 0.9665224476411322\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (65410, 65410) entries\n",
      "Student model 8-25 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9539788059843527\n",
      "Student model 8-25 fidelity: 0.9539788059843527\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (65560, 65560) entries\n",
      "Student model 8-26 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9603264420985799\n",
      "Student model 8-26 fidelity: 0.9603264420985799\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (65710, 65710) entries\n",
      "Student model 8-27 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9299025084703434\n",
      "Student model 8-27 fidelity: 0.9299025084703434\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (65860, 65860) entries\n",
      "Student model 8-28 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9066337821751543\n",
      "Student model 8-28 fidelity: 0.9066337821751543\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (66010, 66010) entries\n",
      "Student model 8-29 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.967410951621478\n",
      "Student model 8-29 fidelity: 0.967410951621478\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (66160, 66160) entries\n",
      "Student model 8-30 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9719977553310887\n",
      "Student model 8-30 fidelity: 0.9719977553310887\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (66310, 66310) entries\n",
      "Student model 8-31 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9645981757074119\n",
      "Student model 8-31 fidelity: 0.9645981757074119\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (66460, 66460) entries\n",
      "Student model 8-32 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9795092838196285\n",
      "Student model 8-32 fidelity: 0.9795092838196285\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (66610, 66610) entries\n",
      "Student model 8-33 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9745286582048642\n",
      "Student model 8-33 fidelity: 0.9745286582048642\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (66760, 66760) entries\n",
      "Student model 8-34 trained with depth 7 and 17 leaves:\n",
      "Student model score: 0.920509241432422\n",
      "Student model 8-34 fidelity: 0.920509241432422\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (66910, 66910) entries\n",
      "Student model 8-35 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9850427350427351\n",
      "Student model 8-35 fidelity: 0.9850427350427351\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (67060, 67060) entries\n",
      "Student model 8-36 trained with depth 5 and 12 leaves:\n",
      "Student model score: 0.9590384770508994\n",
      "Student model 8-36 fidelity: 0.9590384770508994\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (67210, 67210) entries\n",
      "Student model 8-37 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9629629629629629\n",
      "Student model 8-37 fidelity: 0.9629629629629629\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (67360, 67360) entries\n",
      "Student model 8-38 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9868211999136238\n",
      "Student model 8-38 fidelity: 0.9868211999136238\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (67510, 67510) entries\n",
      "Student model 8-39 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9214136679821312\n",
      "Student model 8-39 fidelity: 0.9214136679821312\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (67660, 67660) entries\n",
      "Student model 8-40 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.966042217369651\n",
      "Student model 8-40 fidelity: 0.966042217369651\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (67810, 67810) entries\n",
      "Student model 8-41 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9002060643709026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 8-41 fidelity: 0.9002060643709026\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (67960, 67960) entries\n",
      "Student model 8-42 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9789977982749067\n",
      "Student model 8-42 fidelity: 0.9789977982749067\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (68110, 68110) entries\n",
      "Student model 8-43 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9783454402926575\n",
      "Student model 8-43 fidelity: 0.9783454402926575\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (68260, 68260) entries\n",
      "Student model 8-44 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9525036219240084\n",
      "Student model 8-44 fidelity: 0.9525036219240084\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (68410, 68410) entries\n",
      "Student model 8-45 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9393880215025027\n",
      "Student model 8-45 fidelity: 0.9393880215025027\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (68560, 68560) entries\n",
      "Student model 8-46 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9729286300246103\n",
      "Student model 8-46 fidelity: 0.9729286300246103\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (68710, 68710) entries\n",
      "Student model 8-47 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9455385573032632\n",
      "Student model 8-47 fidelity: 0.9455385573032632\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (68860, 68860) entries\n",
      "Student model 8-48 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9733683654427524\n",
      "Student model 8-48 fidelity: 0.9733683654427524\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (69010, 69010) entries\n",
      "Student model 8-49 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9044929396662388\n",
      "Student model 8-49 fidelity: 0.9044929396662388\n",
      "########## Outer-loop Iteration 9/10 ##########\n",
      "Initializing Trustee inner-loop with 10 iterations\n",
      "########## Inner-loop Iteration 0/50 ##########\n",
      "Sampling 498 points from training dataset with (69160, 69160) entries\n",
      "Student model 9-0 trained with depth 6 and 16 leaves:\n",
      "Student model score: 0.8910668116958589\n",
      "Student model 9-0 fidelity: 0.8910668116958589\n",
      "########## Inner-loop Iteration 1/50 ##########\n",
      "Sampling 498 points from training dataset with (69310, 69310) entries\n",
      "Student model 9-1 trained with depth 8 and 17 leaves:\n",
      "Student model score: 0.9341974338832156\n",
      "Student model 9-1 fidelity: 0.9341974338832156\n",
      "########## Inner-loop Iteration 2/50 ##########\n",
      "Sampling 498 points from training dataset with (69460, 69460) entries\n",
      "Student model 9-2 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9710257290170609\n",
      "Student model 9-2 fidelity: 0.9710257290170609\n",
      "########## Inner-loop Iteration 3/50 ##########\n",
      "Sampling 498 points from training dataset with (69610, 69610) entries\n",
      "Student model 9-3 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.9533872468791117\n",
      "Student model 9-3 fidelity: 0.9533872468791117\n",
      "########## Inner-loop Iteration 4/50 ##########\n",
      "Sampling 498 points from training dataset with (69760, 69760) entries\n",
      "Student model 9-4 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9607281607281607\n",
      "Student model 9-4 fidelity: 0.9607281607281607\n",
      "########## Inner-loop Iteration 5/50 ##########\n",
      "Sampling 498 points from training dataset with (69910, 69910) entries\n",
      "Student model 9-5 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9599240965220347\n",
      "Student model 9-5 fidelity: 0.9599240965220347\n",
      "########## Inner-loop Iteration 6/50 ##########\n",
      "Sampling 498 points from training dataset with (70060, 70060) entries\n",
      "Student model 9-6 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9936299936299936\n",
      "Student model 9-6 fidelity: 0.9936299936299936\n",
      "########## Inner-loop Iteration 7/50 ##########\n",
      "Sampling 498 points from training dataset with (70210, 70210) entries\n",
      "Student model 9-7 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9463342093956286\n",
      "Student model 9-7 fidelity: 0.9463342093956286\n",
      "########## Inner-loop Iteration 8/50 ##########\n",
      "Sampling 498 points from training dataset with (70360, 70360) entries\n",
      "Student model 9-8 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.967286940450121\n",
      "Student model 9-8 fidelity: 0.967286940450121\n",
      "########## Inner-loop Iteration 9/50 ##########\n",
      "Sampling 498 points from training dataset with (70510, 70510) entries\n",
      "Student model 9-9 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9725165489359812\n",
      "Student model 9-9 fidelity: 0.9725165489359812\n",
      "########## Inner-loop Iteration 10/50 ##########\n",
      "Sampling 498 points from training dataset with (70660, 70660) entries\n",
      "Student model 9-10 trained with depth 6 and 16 leaves:\n",
      "Student model score: 0.9625261158594492\n",
      "Student model 9-10 fidelity: 0.9625261158594492\n",
      "########## Inner-loop Iteration 11/50 ##########\n",
      "Sampling 498 points from training dataset with (70810, 70810) entries\n",
      "Student model 9-11 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9528989139515455\n",
      "Student model 9-11 fidelity: 0.9528989139515455\n",
      "########## Inner-loop Iteration 12/50 ##########\n",
      "Sampling 498 points from training dataset with (70960, 70960) entries\n",
      "Student model 9-12 trained with depth 8 and 17 leaves:\n",
      "Student model score: 0.9531484983958199\n",
      "Student model 9-12 fidelity: 0.9531484983958199\n",
      "########## Inner-loop Iteration 13/50 ##########\n",
      "Sampling 498 points from training dataset with (71110, 71110) entries\n",
      "Student model 9-13 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9365419683985284\n",
      "Student model 9-13 fidelity: 0.9365419683985284\n",
      "########## Inner-loop Iteration 14/50 ##########\n",
      "Sampling 498 points from training dataset with (71260, 71260) entries\n",
      "Student model 9-14 trained with depth 6 and 14 leaves:\n",
      "Student model score: 0.9240582443337502\n",
      "Student model 9-14 fidelity: 0.9240582443337502\n",
      "########## Inner-loop Iteration 15/50 ##########\n",
      "Sampling 498 points from training dataset with (71410, 71410) entries\n",
      "Student model 9-15 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.9799027509133892\n",
      "Student model 9-15 fidelity: 0.9799027509133892\n",
      "########## Inner-loop Iteration 16/50 ##########\n",
      "Sampling 498 points from training dataset with (71560, 71560) entries\n",
      "Student model 9-16 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9460012592289496\n",
      "Student model 9-16 fidelity: 0.9460012592289496\n",
      "########## Inner-loop Iteration 17/50 ##########\n",
      "Sampling 498 points from training dataset with (71710, 71710) entries\n",
      "Student model 9-17 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.95497557997558\n",
      "Student model 9-17 fidelity: 0.95497557997558\n",
      "########## Inner-loop Iteration 18/50 ##########\n",
      "Sampling 498 points from training dataset with (71860, 71860) entries\n",
      "Student model 9-18 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9619337565315024\n",
      "Student model 9-18 fidelity: 0.9619337565315024\n",
      "########## Inner-loop Iteration 19/50 ##########\n",
      "Sampling 498 points from training dataset with (72010, 72010) entries\n",
      "Student model 9-19 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9130998816416248\n",
      "Student model 9-19 fidelity: 0.9130998816416248\n",
      "########## Inner-loop Iteration 20/50 ##########\n",
      "Sampling 498 points from training dataset with (72160, 72160) entries\n",
      "Student model 9-20 trained with depth 5 and 11 leaves:\n",
      "Student model score: 0.9708781758317362\n",
      "Student model 9-20 fidelity: 0.9708781758317362\n",
      "########## Inner-loop Iteration 21/50 ##########\n",
      "Sampling 498 points from training dataset with (72310, 72310) entries\n",
      "Student model 9-21 trained with depth 7 and 14 leaves:\n",
      "Student model score: 0.9734353358288814\n",
      "Student model 9-21 fidelity: 0.9734353358288814\n",
      "########## Inner-loop Iteration 22/50 ##########\n",
      "Sampling 498 points from training dataset with (72460, 72460) entries\n",
      "Student model 9-22 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9664097875304772\n",
      "Student model 9-22 fidelity: 0.9664097875304772\n",
      "########## Inner-loop Iteration 23/50 ##########\n",
      "Sampling 498 points from training dataset with (72610, 72610) entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model 9-23 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9598458713951246\n",
      "Student model 9-23 fidelity: 0.9598458713951246\n",
      "########## Inner-loop Iteration 24/50 ##########\n",
      "Sampling 498 points from training dataset with (72760, 72760) entries\n",
      "Student model 9-24 trained with depth 6 and 19 leaves:\n",
      "Student model score: 0.9202488202488203\n",
      "Student model 9-24 fidelity: 0.9202488202488203\n",
      "########## Inner-loop Iteration 25/50 ##########\n",
      "Sampling 498 points from training dataset with (72910, 72910) entries\n",
      "Student model 9-25 trained with depth 7 and 12 leaves:\n",
      "Student model score: 0.9539895098718629\n",
      "Student model 9-25 fidelity: 0.9539895098718629\n",
      "########## Inner-loop Iteration 26/50 ##########\n",
      "Sampling 498 points from training dataset with (73060, 73060) entries\n",
      "Student model 9-26 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9934659181019443\n",
      "Student model 9-26 fidelity: 0.9934659181019443\n",
      "########## Inner-loop Iteration 27/50 ##########\n",
      "Sampling 498 points from training dataset with (73210, 73210) entries\n",
      "Student model 9-27 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9731992589135446\n",
      "Student model 9-27 fidelity: 0.9731992589135446\n",
      "########## Inner-loop Iteration 28/50 ##########\n",
      "Sampling 498 points from training dataset with (73360, 73360) entries\n",
      "Student model 9-28 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.9490313765676084\n",
      "Student model 9-28 fidelity: 0.9490313765676084\n",
      "########## Inner-loop Iteration 29/50 ##########\n",
      "Sampling 498 points from training dataset with (73510, 73510) entries\n",
      "Student model 9-29 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9547652977501403\n",
      "Student model 9-29 fidelity: 0.9547652977501403\n",
      "########## Inner-loop Iteration 30/50 ##########\n",
      "Sampling 498 points from training dataset with (73660, 73660) entries\n",
      "Student model 9-30 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.963861958392831\n",
      "Student model 9-30 fidelity: 0.963861958392831\n",
      "########## Inner-loop Iteration 31/50 ##########\n",
      "Sampling 498 points from training dataset with (73810, 73810) entries\n",
      "Student model 9-31 trained with depth 8 and 12 leaves:\n",
      "Student model score: 0.925667893892193\n",
      "Student model 9-31 fidelity: 0.925667893892193\n",
      "########## Inner-loop Iteration 32/50 ##########\n",
      "Sampling 498 points from training dataset with (73960, 73960) entries\n",
      "Student model 9-32 trained with depth 5 and 10 leaves:\n",
      "Student model score: 0.9465807522968023\n",
      "Student model 9-32 fidelity: 0.9465807522968023\n",
      "########## Inner-loop Iteration 33/50 ##########\n",
      "Sampling 498 points from training dataset with (74110, 74110) entries\n",
      "Student model 9-33 trained with depth 6 and 12 leaves:\n",
      "Student model score: 0.9547042023663811\n",
      "Student model 9-33 fidelity: 0.9547042023663811\n",
      "########## Inner-loop Iteration 34/50 ##########\n",
      "Sampling 498 points from training dataset with (74260, 74260) entries\n",
      "Student model 9-34 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.941272732529563\n",
      "Student model 9-34 fidelity: 0.941272732529563\n",
      "########## Inner-loop Iteration 35/50 ##########\n",
      "Sampling 498 points from training dataset with (74410, 74410) entries\n",
      "Student model 9-35 trained with depth 6 and 10 leaves:\n",
      "Student model score: 0.9654748959973167\n",
      "Student model 9-35 fidelity: 0.9654748959973167\n",
      "########## Inner-loop Iteration 36/50 ##########\n",
      "Sampling 498 points from training dataset with (74560, 74560) entries\n",
      "Student model 9-36 trained with depth 7 and 11 leaves:\n",
      "Student model score: 0.9605296664120194\n",
      "Student model 9-36 fidelity: 0.9605296664120194\n",
      "########## Inner-loop Iteration 37/50 ##########\n",
      "Sampling 498 points from training dataset with (74710, 74710) entries\n",
      "Student model 9-37 trained with depth 7 and 10 leaves:\n",
      "Student model score: 0.952562779497764\n",
      "Student model 9-37 fidelity: 0.952562779497764\n",
      "########## Inner-loop Iteration 38/50 ##########\n",
      "Sampling 498 points from training dataset with (74860, 74860) entries\n",
      "Student model 9-38 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9635400105988342\n",
      "Student model 9-38 fidelity: 0.9635400105988342\n",
      "########## Inner-loop Iteration 39/50 ##########\n",
      "Sampling 498 points from training dataset with (75010, 75010) entries\n",
      "Student model 9-39 trained with depth 5 and 9 leaves:\n",
      "Student model score: 0.9466619995332867\n",
      "Student model 9-39 fidelity: 0.9466619995332867\n",
      "########## Inner-loop Iteration 40/50 ##########\n",
      "Sampling 498 points from training dataset with (75160, 75160) entries\n",
      "Student model 9-40 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.954286067388927\n",
      "Student model 9-40 fidelity: 0.954286067388927\n",
      "########## Inner-loop Iteration 41/50 ##########\n",
      "Sampling 498 points from training dataset with (75310, 75310) entries\n",
      "Student model 9-41 trained with depth 6 and 9 leaves:\n",
      "Student model score: 0.9530228758169935\n",
      "Student model 9-41 fidelity: 0.9530228758169935\n",
      "########## Inner-loop Iteration 42/50 ##########\n",
      "Sampling 498 points from training dataset with (75460, 75460) entries\n",
      "Student model 9-42 trained with depth 6 and 13 leaves:\n",
      "Student model score: 0.9678457719610641\n",
      "Student model 9-42 fidelity: 0.9678457719610641\n",
      "########## Inner-loop Iteration 43/50 ##########\n",
      "Sampling 498 points from training dataset with (75610, 75610) entries\n",
      "Student model 9-43 trained with depth 10 and 17 leaves:\n",
      "Student model score: 0.9595920891240661\n",
      "Student model 9-43 fidelity: 0.9595920891240661\n",
      "########## Inner-loop Iteration 44/50 ##########\n",
      "Sampling 498 points from training dataset with (75760, 75760) entries\n",
      "Student model 9-44 trained with depth 6 and 15 leaves:\n",
      "Student model score: 0.9177671166043258\n",
      "Student model 9-44 fidelity: 0.9177671166043258\n",
      "########## Inner-loop Iteration 45/50 ##########\n",
      "Sampling 498 points from training dataset with (75910, 75910) entries\n",
      "Student model 9-45 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.933150183150183\n",
      "Student model 9-45 fidelity: 0.933150183150183\n",
      "########## Inner-loop Iteration 46/50 ##########\n",
      "Sampling 498 points from training dataset with (76060, 76060) entries\n",
      "Student model 9-46 trained with depth 7 and 16 leaves:\n",
      "Student model score: 0.9397900574371163\n",
      "Student model 9-46 fidelity: 0.9397900574371163\n",
      "########## Inner-loop Iteration 47/50 ##########\n",
      "Sampling 498 points from training dataset with (76210, 76210) entries\n",
      "Student model 9-47 trained with depth 7 and 13 leaves:\n",
      "Student model score: 0.959610095063456\n",
      "Student model 9-47 fidelity: 0.959610095063456\n",
      "########## Inner-loop Iteration 48/50 ##########\n",
      "Sampling 498 points from training dataset with (76360, 76360) entries\n",
      "Student model 9-48 trained with depth 6 and 11 leaves:\n",
      "Student model score: 0.9784858865633398\n",
      "Student model 9-48 fidelity: 0.9784858865633398\n",
      "########## Inner-loop Iteration 49/50 ##########\n",
      "Sampling 498 points from training dataset with (76510, 76510) entries\n",
      "Student model 9-49 trained with depth 7 and 15 leaves:\n",
      "Student model score: 0.9426826472803485\n",
      "Student model 9-49 fidelity: 0.9426826472803485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model explanation global fidelity report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   GoogleDoc       0.98      0.93      0.95       348\n",
      " GoogleDrive       0.94      0.97      0.95       324\n",
      "     Youtube       0.93      0.95      0.94       345\n",
      "\n",
      "    accuracy                           0.95      1017\n",
      "   macro avg       0.95      0.95      0.95      1017\n",
      "weighted avg       0.95      0.95      0.95      1017\n",
      "\n",
      "Model explanation score report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   GoogleDoc       0.98      0.94      0.96       346\n",
      " GoogleDrive       0.93      0.96      0.95       325\n",
      "     Youtube       0.93      0.95      0.94       346\n",
      "\n",
      "    accuracy                           0.95      1017\n",
      "   macro avg       0.95      0.95      0.95      1017\n",
      "weighted avg       0.95      0.95      0.95      1017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "#model = joblib.load('quic_text_rf.joblib')\n",
    "num_iter=50\n",
    "num_stability_iter=10\n",
    "\n",
    "trustee = ClassificationTrustee(expert=classifier)\n",
    "trustee.fit(X_train, y_train, num_iter=num_iter, num_stability_iter=num_stability_iter, samples_size=0.3, verbose=True)\n",
    "dt, pruned_dt, agreement, reward = trustee.explain()\n",
    "dt_y_pred = dt.predict(X_test)\n",
    "pruned_dt_y_pred = pruned_dt.predict(X_test)\n",
    "\n",
    "all_trees = trustee.get_all_students()\n",
    "\n",
    "print(\"Model explanation global fidelity report:\")\n",
    "print(classification_report(y_pred, dt_y_pred))\n",
    "print(\"Model explanation score report:\")\n",
    "print(classification_report(y_test, dt_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b39f2b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flowpic_x,y_rf_pruned_pool.pdf'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output decision tree to pdf\n",
    "features = ['feature_{}'.format(MyFeature(i)) for i in range(1, 10001)]\n",
    "classes = ['GoogleDoc', 'GoogleDrive', 'Youtube']\n",
    "\n",
    "dot_data = tree.export_graphviz(\n",
    "    dt,\n",
    "    class_names=classes,\n",
    "    feature_names= features,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True,\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"flowpic_x,y_rf_pool\")\n",
    "\n",
    "# Output pruned decision tree to pdf\n",
    "dot_data = tree.export_graphviz(\n",
    "    pruned_dt,\n",
    "    class_names=classes,\n",
    "    feature_names=features,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True,\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"flowpic_x,y_rf_pruned_pool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a67fa804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "all tree:\n",
      "feat_name: (1410-1425,1410-1425), count_total: 86, num_trees: 85, samples: 20366\n",
      "feat_name: (0-15,1410-1425), count_total: 164, num_trees: 158, samples: 25343\n",
      "feat_name: (1350-1365,1425-1440), count_total: 26, num_trees: 26, samples: 3430\n",
      "feat_name: (1485-1500,1395-1410), count_total: 257, num_trees: 254, samples: 34786\n",
      "feat_name: (300-315,1065-1080), count_total: 2, num_trees: 2, samples: 262\n",
      "feat_name: (1185-1200,1260-1275), count_total: 4, num_trees: 4, samples: 503\n",
      "feat_name: (1380-1395,90-105), count_total: 3, num_trees: 3, samples: 38\n",
      "feat_name: (315-330,90-105), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (405-420,435-450), count_total: 6, num_trees: 6, samples: 538\n",
      "feat_name: (1290-1305,105-120), count_total: 4, num_trees: 4, samples: 285\n",
      "feat_name: (90-105,105-120), count_total: 5, num_trees: 5, samples: 373\n",
      "feat_name: (0-15,135-150), count_total: 3, num_trees: 3, samples: 107\n",
      "feat_name: (1485-1500,135-150), count_total: 180, num_trees: 176, samples: 47417\n",
      "feat_name: (1350-1365,1410-1425), count_total: 38, num_trees: 38, samples: 9238\n",
      "feat_name: (1260-1275,1425-1440), count_total: 2, num_trees: 2, samples: 209\n",
      "feat_name: (0-15,390-405), count_total: 45, num_trees: 45, samples: 5295\n",
      "feat_name: (90-105,930-945), count_total: 4, num_trees: 4, samples: 366\n",
      "feat_name: (1485-1500,165-180), count_total: 5, num_trees: 5, samples: 488\n",
      "feat_name: (1440-1455,270-285), count_total: 5, num_trees: 5, samples: 524\n",
      "feat_name: (525-540,855-870), count_total: 2, num_trees: 2, samples: 242\n",
      "feat_name: (1065-1080,75-90), count_total: 6, num_trees: 6, samples: 51\n",
      "feat_name: (0-15,90-105), count_total: 166, num_trees: 159, samples: 47268\n",
      "feat_name: (495-510,480-495), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1470-1485,1410-1425), count_total: 42, num_trees: 42, samples: 6879\n",
      "feat_name: (1170-1185,1425-1440), count_total: 7, num_trees: 7, samples: 973\n",
      "feat_name: (0-15,330-345), count_total: 227, num_trees: 226, samples: 31664\n",
      "feat_name: (285-300,1020-1035), count_total: 3, num_trees: 3, samples: 321\n",
      "feat_name: (315-330,75-90), count_total: 2, num_trees: 2, samples: 220\n",
      "feat_name: (1320-1335,75-90), count_total: 8, num_trees: 8, samples: 86\n",
      "feat_name: (1260-1275,60-75), count_total: 6, num_trees: 6, samples: 336\n",
      "feat_name: (795-810,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1335-1350,1410-1425), count_total: 17, num_trees: 17, samples: 3955\n",
      "feat_name: (150-165,1410-1425), count_total: 4, num_trees: 4, samples: 336\n",
      "feat_name: (135-150,1410-1425), count_total: 2, num_trees: 2, samples: 105\n",
      "feat_name: (1485-1500,90-105), count_total: 24, num_trees: 24, samples: 1920\n",
      "feat_name: (1080-1095,105-120), count_total: 6, num_trees: 6, samples: 286\n",
      "feat_name: (1260-1275,90-105), count_total: 12, num_trees: 12, samples: 788\n",
      "feat_name: (1425-1440,1410-1425), count_total: 86, num_trees: 85, samples: 22473\n",
      "feat_name: (1140-1155,1425-1440), count_total: 9, num_trees: 9, samples: 1067\n",
      "feat_name: (0-15,1290-1305), count_total: 15, num_trees: 15, samples: 1279\n",
      "feat_name: (1410-1425,1380-1395), count_total: 9, num_trees: 9, samples: 975\n",
      "feat_name: (930-945,1410-1425), count_total: 2, num_trees: 2, samples: 242\n",
      "feat_name: (1410-1425,900-915), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1425-1440,75-90), count_total: 7, num_trees: 7, samples: 248\n",
      "feat_name: (1020-1035,1425-1440), count_total: 4, num_trees: 4, samples: 168\n",
      "feat_name: (165-180,90-105), count_total: 3, num_trees: 2, samples: 106\n",
      "feat_name: (1365-1380,1425-1440), count_total: 19, num_trees: 19, samples: 2864\n",
      "feat_name: (1485-1500,1305-1320), count_total: 11, num_trees: 11, samples: 1370\n",
      "feat_name: (1455-1470,1410-1425), count_total: 29, num_trees: 29, samples: 4704\n",
      "feat_name: (795-810,135-150), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1020-1035,60-75), count_total: 8, num_trees: 8, samples: 594\n",
      "feat_name: (975-990,165-180), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (90-105,1410-1425), count_total: 17, num_trees: 17, samples: 1477\n",
      "feat_name: (1485-1500,1425-1440), count_total: 201, num_trees: 194, samples: 47111\n",
      "feat_name: (1080-1095,1425-1440), count_total: 8, num_trees: 8, samples: 637\n",
      "feat_name: (1470-1485,1290-1305), count_total: 11, num_trees: 11, samples: 1299\n",
      "feat_name: (75-90,1410-1425), count_total: 13, num_trees: 13, samples: 1085\n",
      "feat_name: (375-390,495-510), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (0-15,210-225), count_total: 16, num_trees: 16, samples: 1749\n",
      "feat_name: (1320-1335,1425-1440), count_total: 33, num_trees: 33, samples: 5129\n",
      "feat_name: (300-315,1410-1425), count_total: 2, num_trees: 2, samples: 248\n",
      "feat_name: (1455-1470,1380-1395), count_total: 6, num_trees: 6, samples: 517\n",
      "feat_name: (720-735,75-90), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (30-45,1410-1425), count_total: 4, num_trees: 4, samples: 220\n",
      "feat_name: (375-390,375-390), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1425-1440,120-135), count_total: 5, num_trees: 5, samples: 467\n",
      "feat_name: (1155-1170,1425-1440), count_total: 13, num_trees: 13, samples: 1759\n",
      "feat_name: (255-270,405-420), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (1080-1095,1335-1350), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (1365-1380,75-90), count_total: 3, num_trees: 3, samples: 39\n",
      "feat_name: (360-375,75-90), count_total: 11, num_trees: 11, samples: 889\n",
      "feat_name: (255-270,105-120), count_total: 2, num_trees: 2, samples: 5\n",
      "feat_name: (1380-1395,1425-1440), count_total: 20, num_trees: 20, samples: 2761\n",
      "feat_name: (975-990,1410-1425), count_total: 3, num_trees: 3, samples: 356\n",
      "feat_name: (1425-1440,90-105), count_total: 19, num_trees: 19, samples: 1991\n",
      "feat_name: (1305-1320,90-105), count_total: 3, num_trees: 3, samples: 288\n",
      "feat_name: (1485-1500,150-165), count_total: 156, num_trees: 138, samples: 26882\n",
      "feat_name: (660-675,960-975), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1485-1500,1350-1365), count_total: 3, num_trees: 3, samples: 290\n",
      "feat_name: (30-45,210-225), count_total: 7, num_trees: 7, samples: 925\n",
      "feat_name: (1470-1485,135-150), count_total: 2, num_trees: 2, samples: 102\n",
      "feat_name: (1365-1380,105-120), count_total: 17, num_trees: 17, samples: 1604\n",
      "feat_name: (255-270,675-690), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1440-1455,1410-1425), count_total: 30, num_trees: 30, samples: 5008\n",
      "feat_name: (465-480,495-510), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1440-1455,90-105), count_total: 66, num_trees: 66, samples: 10332\n",
      "feat_name: (1110-1125,1410-1425), count_total: 13, num_trees: 13, samples: 1359\n",
      "feat_name: (1455-1470,1425-1440), count_total: 25, num_trees: 25, samples: 3785\n",
      "feat_name: (1140-1155,1380-1395), count_total: 4, num_trees: 4, samples: 543\n",
      "feat_name: (990-1005,1410-1425), count_total: 9, num_trees: 9, samples: 1019\n",
      "feat_name: (615-630,120-135), count_total: 5, num_trees: 5, samples: 458\n",
      "feat_name: (1215-1230,270-285), count_total: 3, num_trees: 3, samples: 141\n",
      "feat_name: (1485-1500,855-870), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (135-150,705-720), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1215-1230,75-90), count_total: 6, num_trees: 6, samples: 136\n",
      "feat_name: (1470-1485,525-540), count_total: 6, num_trees: 6, samples: 609\n",
      "feat_name: (660-675,1380-1395), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1440-1455,810-825), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (1035-1050,90-105), count_total: 5, num_trees: 5, samples: 518\n",
      "feat_name: (1395-1410,90-105), count_total: 2, num_trees: 2, samples: 27\n",
      "feat_name: (840-855,120-135), count_total: 2, num_trees: 2, samples: 83\n",
      "feat_name: (915-930,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (450-465,120-135), count_total: 2, num_trees: 2, samples: 129\n",
      "feat_name: (795-810,150-165), count_total: 3, num_trees: 3, samples: 368\n",
      "feat_name: (1335-1350,945-960), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (15-30,420-435), count_total: 2, num_trees: 2, samples: 259\n",
      "feat_name: (495-510,1410-1425), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (1350-1365,1380-1395), count_total: 8, num_trees: 8, samples: 521\n",
      "feat_name: (360-375,120-135), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1140-1155,1410-1425), count_total: 5, num_trees: 5, samples: 637\n",
      "feat_name: (1305-1320,1425-1440), count_total: 9, num_trees: 9, samples: 1167\n",
      "feat_name: (855-870,705-720), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1485-1500,75-90), count_total: 27, num_trees: 27, samples: 2161\n",
      "feat_name: (1380-1395,480-495), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (0-15,1380-1395), count_total: 23, num_trees: 22, samples: 2605\n",
      "feat_name: (1485-1500,915-930), count_total: 18, num_trees: 18, samples: 1831\n",
      "feat_name: (1050-1065,210-225), count_total: 2, num_trees: 2, samples: 25\n",
      "feat_name: (285-300,720-735), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (1485-1500,945-960), count_total: 15, num_trees: 15, samples: 2886\n",
      "feat_name: (1170-1185,1380-1395), count_total: 6, num_trees: 6, samples: 457\n",
      "feat_name: (45-60,105-120), count_total: 4, num_trees: 4, samples: 365\n",
      "feat_name: (1170-1185,105-120), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1320-1335,285-300), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (600-615,300-315), count_total: 2, num_trees: 2, samples: 188\n",
      "feat_name: (1440-1455,120-135), count_total: 4, num_trees: 4, samples: 232\n",
      "feat_name: (675-690,60-75), count_total: 2, num_trees: 2, samples: 104\n",
      "feat_name: (1350-1365,60-75), count_total: 3, num_trees: 3, samples: 279\n",
      "feat_name: (1125-1140,1380-1395), count_total: 8, num_trees: 8, samples: 905\n",
      "feat_name: (480-495,900-915), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1485-1500,105-120), count_total: 37, num_trees: 37, samples: 2943\n",
      "feat_name: (1065-1080,135-150), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (330-345,990-1005), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (0-15,585-600), count_total: 27, num_trees: 27, samples: 3180\n",
      "feat_name: (1455-1470,60-75), count_total: 18, num_trees: 18, samples: 1517\n",
      "feat_name: (585-600,1410-1425), count_total: 7, num_trees: 7, samples: 453\n",
      "feat_name: (1170-1185,60-75), count_total: 13, num_trees: 13, samples: 1405\n",
      "feat_name: (75-90,135-150), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (225-240,60-75), count_total: 6, num_trees: 6, samples: 727\n",
      "feat_name: (330-345,1200-1215), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (1215-1230,60-75), count_total: 13, num_trees: 13, samples: 922\n",
      "feat_name: (120-135,945-960), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (840-855,75-90), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (1485-1500,435-450), count_total: 14, num_trees: 14, samples: 1166\n",
      "feat_name: (150-165,765-780), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (0-15,75-90), count_total: 148, num_trees: 134, samples: 38050\n",
      "feat_name: (0-15,60-75), count_total: 70, num_trees: 64, samples: 7417\n",
      "feat_name: (645-660,465-480), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (735-750,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1290-1305,60-75), count_total: 15, num_trees: 15, samples: 1357\n",
      "feat_name: (585-600,900-915), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (1410-1425,1425-1440), count_total: 24, num_trees: 24, samples: 3621\n",
      "feat_name: (1080-1095,1410-1425), count_total: 4, num_trees: 4, samples: 609\n",
      "feat_name: (1395-1410,285-300), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (435-450,1140-1155), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (285-300,930-945), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (45-60,180-195), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (1035-1050,1425-1440), count_total: 3, num_trees: 3, samples: 293\n",
      "feat_name: (1470-1485,1380-1395), count_total: 34, num_trees: 34, samples: 4178\n",
      "feat_name: (510-525,945-960), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (15-30,90-105), count_total: 10, num_trees: 10, samples: 231\n",
      "feat_name: (150-165,90-105), count_total: 3, num_trees: 3, samples: 111\n",
      "feat_name: (1350-1365,120-135), count_total: 6, num_trees: 6, samples: 311\n",
      "feat_name: (915-930,1410-1425), count_total: 3, num_trees: 3, samples: 137\n",
      "feat_name: (390-405,945-960), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (1335-1350,1425-1440), count_total: 19, num_trees: 19, samples: 2932\n",
      "feat_name: (510-525,540-555), count_total: 2, num_trees: 2, samples: 233\n",
      "feat_name: (585-600,90-105), count_total: 3, num_trees: 3, samples: 95\n",
      "feat_name: (390-405,180-195), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1440-1455,435-450), count_total: 7, num_trees: 7, samples: 627\n",
      "feat_name: (240-255,540-555), count_total: 2, num_trees: 2, samples: 154\n",
      "feat_name: (1470-1485,90-105), count_total: 22, num_trees: 22, samples: 2284\n",
      "feat_name: (1335-1350,60-75), count_total: 6, num_trees: 6, samples: 768\n",
      "feat_name: (1395-1410,60-75), count_total: 6, num_trees: 6, samples: 700\n",
      "feat_name: (1290-1305,1410-1425), count_total: 4, num_trees: 4, samples: 814\n",
      "feat_name: (360-375,135-150), count_total: 6, num_trees: 6, samples: 267\n",
      "feat_name: (765-780,540-555), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (1470-1485,240-255), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (0-15,105-120), count_total: 13, num_trees: 13, samples: 1614\n",
      "feat_name: (825-840,1305-1320), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1395-1410,75-90), count_total: 4, num_trees: 4, samples: 125\n",
      "feat_name: (45-60,1410-1425), count_total: 8, num_trees: 8, samples: 641\n",
      "feat_name: (360-375,1215-1230), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1395-1410,1410-1425), count_total: 10, num_trees: 10, samples: 2239\n",
      "feat_name: (840-855,60-75), count_total: 7, num_trees: 7, samples: 810\n",
      "feat_name: (1485-1500,1440-1455), count_total: 24, num_trees: 24, samples: 3334\n",
      "feat_name: (30-45,60-75), count_total: 4, num_trees: 4, samples: 465\n",
      "feat_name: (945-960,915-930), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (30-45,165-180), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (1485-1500,180-195), count_total: 3, num_trees: 3, samples: 238\n",
      "feat_name: (1050-1065,60-75), count_total: 30, num_trees: 30, samples: 3658\n",
      "feat_name: (780-795,150-165), count_total: 1, num_trees: 1, samples: 121\n",
      "feat_name: (45-60,60-75), count_total: 4, num_trees: 4, samples: 44\n",
      "feat_name: (285-300,900-915), count_total: 2, num_trees: 2, samples: 119\n",
      "feat_name: (540-555,1335-1350), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (105-120,1410-1425), count_total: 13, num_trees: 13, samples: 1322\n",
      "feat_name: (1110-1125,1425-1440), count_total: 9, num_trees: 9, samples: 853\n",
      "feat_name: (1275-1290,60-75), count_total: 7, num_trees: 7, samples: 384\n",
      "feat_name: (15-30,75-90), count_total: 15, num_trees: 15, samples: 1115\n",
      "feat_name: (1035-1050,75-90), count_total: 3, num_trees: 3, samples: 14\n",
      "feat_name: (975-990,105-120), count_total: 2, num_trees: 2, samples: 91\n",
      "feat_name: (1080-1095,270-285), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (105-120,330-345), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1485-1500,960-975), count_total: 2, num_trees: 2, samples: 228\n",
      "feat_name: (720-735,1410-1425), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (300-315,1005-1020), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (645-660,75-90), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (690-705,90-105), count_total: 3, num_trees: 3, samples: 189\n",
      "feat_name: (1335-1350,1320-1335), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (975-990,1425-1440), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (90-105,1125-1140), count_total: 3, num_trees: 3, samples: 10\n",
      "feat_name: (1185-1200,75-90), count_total: 2, num_trees: 2, samples: 20\n",
      "feat_name: (315-330,780-795), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (195-210,660-675), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (1395-1410,1425-1440), count_total: 26, num_trees: 26, samples: 4043\n",
      "feat_name: (195-210,1290-1305), count_total: 5, num_trees: 5, samples: 661\n",
      "feat_name: (1440-1455,60-75), count_total: 15, num_trees: 15, samples: 1258\n",
      "feat_name: (240-255,75-90), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1230-1245,1380-1395), count_total: 4, num_trees: 4, samples: 46\n",
      "feat_name: (1335-1350,105-120), count_total: 2, num_trees: 2, samples: 94\n",
      "feat_name: (1050-1065,270-285), count_total: 4, num_trees: 4, samples: 408\n",
      "feat_name: (1065-1080,90-105), count_total: 5, num_trees: 5, samples: 38\n",
      "feat_name: (345-360,105-120), count_total: 1, num_trees: 1, samples: 14\n",
      "feat_name: (360-375,645-660), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (225-240,1290-1305), count_total: 7, num_trees: 7, samples: 912\n",
      "feat_name: (945-960,1020-1035), count_total: 1, num_trees: 1, samples: 130\n",
      "feat_name: (540-555,105-120), count_total: 3, num_trees: 3, samples: 309\n",
      "feat_name: (165-180,75-90), count_total: 2, num_trees: 2, samples: 23\n",
      "feat_name: (1410-1425,105-120), count_total: 22, num_trees: 22, samples: 3417\n",
      "feat_name: (1305-1320,60-75), count_total: 7, num_trees: 7, samples: 831\n",
      "feat_name: (360-375,90-105), count_total: 2, num_trees: 2, samples: 195\n",
      "feat_name: (1395-1410,915-930), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (75-90,90-105), count_total: 3, num_trees: 3, samples: 110\n",
      "feat_name: (90-105,765-780), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1035-1050,60-75), count_total: 6, num_trees: 6, samples: 601\n",
      "feat_name: (1095-1110,1410-1425), count_total: 8, num_trees: 8, samples: 936\n",
      "feat_name: (105-120,60-75), count_total: 42, num_trees: 42, samples: 4562\n",
      "feat_name: (0-15,345-360), count_total: 25, num_trees: 24, samples: 2490\n",
      "feat_name: (1485-1500,480-495), count_total: 5, num_trees: 5, samples: 429\n",
      "feat_name: (585-600,960-975), count_total: 5, num_trees: 5, samples: 471\n",
      "feat_name: (1155-1170,375-390), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (405-420,1275-1290), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1050-1065,90-105), count_total: 10, num_trees: 10, samples: 786\n",
      "feat_name: (1020-1035,1380-1395), count_total: 2, num_trees: 2, samples: 122\n",
      "feat_name: (675-690,90-105), count_total: 8, num_trees: 8, samples: 714\n",
      "feat_name: (855-870,75-90), count_total: 2, num_trees: 2, samples: 92\n",
      "feat_name: (1395-1410,360-375), count_total: 2, num_trees: 2, samples: 105\n",
      "feat_name: (1230-1245,105-120), count_total: 9, num_trees: 9, samples: 712\n",
      "feat_name: (1455-1470,270-285), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (1470-1485,960-975), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (795-810,75-90), count_total: 1, num_trees: 1, samples: 137\n",
      "feat_name: (1485-1500,930-945), count_total: 4, num_trees: 4, samples: 399\n",
      "feat_name: (120-135,480-495), count_total: 2, num_trees: 2, samples: 274\n",
      "feat_name: (1065-1080,345-360), count_total: 2, num_trees: 2, samples: 18\n",
      "feat_name: (135-150,1095-1110), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1380-1395,960-975), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1470-1485,1425-1440), count_total: 22, num_trees: 22, samples: 3179\n",
      "feat_name: (90-105,1380-1395), count_total: 7, num_trees: 7, samples: 733\n",
      "feat_name: (1230-1245,270-285), count_total: 5, num_trees: 5, samples: 353\n",
      "feat_name: (30-45,930-945), count_total: 2, num_trees: 2, samples: 141\n",
      "feat_name: (1440-1455,960-975), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (1035-1050,1215-1230), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (255-270,120-135), count_total: 2, num_trees: 2, samples: 135\n",
      "feat_name: (255-270,1410-1425), count_total: 2, num_trees: 2, samples: 10\n",
      "feat_name: (1380-1395,1380-1395), count_total: 3, num_trees: 3, samples: 366\n",
      "feat_name: (1290-1305,1425-1440), count_total: 9, num_trees: 9, samples: 1021\n",
      "feat_name: (1350-1365,90-105), count_total: 25, num_trees: 25, samples: 2818\n",
      "feat_name: (1200-1215,435-450), count_total: 1, num_trees: 1, samples: 77\n",
      "feat_name: (1425-1440,930-945), count_total: 2, num_trees: 2, samples: 174\n",
      "feat_name: (720-735,630-645), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (1425-1440,1425-1440), count_total: 21, num_trees: 21, samples: 3170\n",
      "feat_name: (1050-1065,105-120), count_total: 10, num_trees: 10, samples: 1089\n",
      "feat_name: (465-480,120-135), count_total: 2, num_trees: 2, samples: 143\n",
      "feat_name: (120-135,105-120), count_total: 13, num_trees: 12, samples: 921\n",
      "feat_name: (330-345,165-180), count_total: 2, num_trees: 2, samples: 97\n",
      "feat_name: (1410-1425,135-150), count_total: 5, num_trees: 5, samples: 452\n",
      "feat_name: (585-600,180-195), count_total: 1, num_trees: 1, samples: 74\n",
      "feat_name: (1455-1470,1290-1305), count_total: 7, num_trees: 7, samples: 661\n",
      "feat_name: (1440-1455,1425-1440), count_total: 29, num_trees: 29, samples: 4187\n",
      "feat_name: (195-210,1410-1425), count_total: 2, num_trees: 2, samples: 190\n",
      "feat_name: (1110-1125,60-75), count_total: 16, num_trees: 16, samples: 1745\n",
      "feat_name: (765-780,1410-1425), count_total: 3, num_trees: 3, samples: 254\n",
      "feat_name: (45-60,90-105), count_total: 5, num_trees: 5, samples: 29\n",
      "feat_name: (690-705,330-345), count_total: 2, num_trees: 2, samples: 13\n",
      "feat_name: (1185-1200,60-75), count_total: 11, num_trees: 11, samples: 1156\n",
      "feat_name: (105-120,1290-1305), count_total: 2, num_trees: 2, samples: 26\n",
      "feat_name: (1215-1230,1410-1425), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (345-360,570-585), count_total: 1, num_trees: 1, samples: 134\n",
      "feat_name: (75-90,1290-1305), count_total: 3, num_trees: 3, samples: 292\n",
      "feat_name: (825-840,105-120), count_total: 3, num_trees: 3, samples: 12\n",
      "feat_name: (90-105,60-75), count_total: 31, num_trees: 30, samples: 3025\n",
      "feat_name: (795-810,1380-1395), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (585-600,75-90), count_total: 3, num_trees: 3, samples: 122\n",
      "feat_name: (1440-1455,1365-1380), count_total: 2, num_trees: 2, samples: 102\n",
      "feat_name: (600-615,135-150), count_total: 2, num_trees: 2, samples: 105\n",
      "feat_name: (645-660,1410-1425), count_total: 2, num_trees: 2, samples: 238\n",
      "feat_name: (1485-1500,120-135), count_total: 8, num_trees: 8, samples: 57\n",
      "feat_name: (30-45,225-240), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1320-1335,1380-1395), count_total: 3, num_trees: 3, samples: 254\n",
      "feat_name: (285-300,1410-1425), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (1260-1275,1410-1425), count_total: 3, num_trees: 3, samples: 34\n",
      "feat_name: (1275-1290,90-105), count_total: 3, num_trees: 3, samples: 109\n",
      "feat_name: (615-630,75-90), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1080-1095,60-75), count_total: 12, num_trees: 12, samples: 1303\n",
      "feat_name: (405-420,900-915), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (1080-1095,1380-1395), count_total: 6, num_trees: 6, samples: 582\n",
      "feat_name: (585-600,705-720), count_total: 2, num_trees: 2, samples: 217\n",
      "feat_name: (1395-1410,585-600), count_total: 4, num_trees: 4, samples: 484\n",
      "feat_name: (1335-1350,90-105), count_total: 6, num_trees: 6, samples: 446\n",
      "feat_name: (1485-1500,750-765), count_total: 1, num_trees: 1, samples: 74\n",
      "feat_name: (1350-1365,465-480), count_total: 2, num_trees: 2, samples: 101\n",
      "feat_name: (600-615,75-90), count_total: 7, num_trees: 7, samples: 359\n",
      "feat_name: (1395-1410,105-120), count_total: 12, num_trees: 12, samples: 1364\n",
      "feat_name: (1365-1380,1410-1425), count_total: 20, num_trees: 20, samples: 5491\n",
      "feat_name: (405-420,495-510), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (870-885,90-105), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1260-1275,1365-1380), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (105-120,945-960), count_total: 4, num_trees: 4, samples: 483\n",
      "feat_name: (1470-1485,60-75), count_total: 11, num_trees: 11, samples: 906\n",
      "feat_name: (585-600,300-315), count_total: 2, num_trees: 2, samples: 19\n",
      "feat_name: (975-990,90-105), count_total: 7, num_trees: 7, samples: 635\n",
      "feat_name: (60-75,1410-1425), count_total: 9, num_trees: 9, samples: 830\n",
      "feat_name: (15-30,60-75), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (1320-1335,90-105), count_total: 5, num_trees: 5, samples: 491\n",
      "feat_name: (1245-1260,135-150), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (1275-1290,1380-1395), count_total: 2, num_trees: 2, samples: 122\n",
      "feat_name: (1245-1260,1425-1440), count_total: 2, num_trees: 2, samples: 317\n",
      "feat_name: (870-885,1020-1035), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (30-45,300-315), count_total: 2, num_trees: 2, samples: 121\n",
      "feat_name: (1290-1305,75-90), count_total: 2, num_trees: 2, samples: 25\n",
      "feat_name: (165-180,120-135), count_total: 3, num_trees: 3, samples: 209\n",
      "feat_name: (150-165,60-75), count_total: 3, num_trees: 3, samples: 19\n",
      "feat_name: (210-225,1290-1305), count_total: 6, num_trees: 6, samples: 633\n",
      "feat_name: (840-855,1410-1425), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (1440-1455,1380-1395), count_total: 12, num_trees: 12, samples: 724\n",
      "feat_name: (1485-1500,375-390), count_total: 3, num_trees: 3, samples: 218\n",
      "feat_name: (45-60,300-315), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (1335-1350,1380-1395), count_total: 3, num_trees: 3, samples: 278\n",
      "feat_name: (1350-1365,360-375), count_total: 2, num_trees: 2, samples: 20\n",
      "feat_name: (1440-1455,105-120), count_total: 7, num_trees: 7, samples: 848\n",
      "feat_name: (1470-1485,510-525), count_total: 4, num_trees: 4, samples: 327\n",
      "feat_name: (1335-1350,120-135), count_total: 2, num_trees: 2, samples: 209\n",
      "feat_name: (75-90,1380-1395), count_total: 4, num_trees: 4, samples: 431\n",
      "feat_name: (645-660,285-300), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (1380-1395,1410-1425), count_total: 6, num_trees: 6, samples: 699\n",
      "feat_name: (0-15,960-975), count_total: 3, num_trees: 3, samples: 376\n",
      "feat_name: (570-585,1410-1425), count_total: 2, num_trees: 2, samples: 231\n",
      "feat_name: (585-600,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1230-1245,1410-1425), count_total: 2, num_trees: 2, samples: 13\n",
      "feat_name: (1410-1425,120-135), count_total: 11, num_trees: 11, samples: 972\n",
      "feat_name: (1095-1110,1425-1440), count_total: 3, num_trees: 3, samples: 487\n",
      "feat_name: (15-30,495-510), count_total: 1, num_trees: 1, samples: 133\n",
      "feat_name: (975-990,135-150), count_total: 3, num_trees: 3, samples: 264\n",
      "feat_name: (855-870,60-75), count_total: 16, num_trees: 16, samples: 2113\n",
      "feat_name: (1185-1200,1380-1395), count_total: 8, num_trees: 8, samples: 330\n",
      "feat_name: (1050-1065,1410-1425), count_total: 2, num_trees: 2, samples: 130\n",
      "feat_name: (480-495,135-150), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (840-855,1290-1305), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (45-60,765-780), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (75-90,60-75), count_total: 4, num_trees: 4, samples: 162\n",
      "feat_name: (135-150,345-360), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (990-1005,150-165), count_total: 2, num_trees: 2, samples: 108\n",
      "feat_name: (1155-1170,90-105), count_total: 2, num_trees: 2, samples: 15\n",
      "feat_name: (1365-1380,90-105), count_total: 2, num_trees: 2, samples: 224\n",
      "feat_name: (1095-1110,90-105), count_total: 3, num_trees: 3, samples: 123\n",
      "feat_name: (390-405,75-90), count_total: 3, num_trees: 3, samples: 173\n",
      "feat_name: (1140-1155,810-825), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (1380-1395,135-150), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (360-375,1125-1140), count_total: 6, num_trees: 6, samples: 542\n",
      "feat_name: (270-285,60-75), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (900-915,885-900), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (1455-1470,1065-1080), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (1125-1140,75-90), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (600-615,90-105), count_total: 1, num_trees: 1, samples: 75\n",
      "feat_name: (360-375,180-195), count_total: 3, num_trees: 3, samples: 155\n",
      "feat_name: (1395-1410,240-255), count_total: 4, num_trees: 4, samples: 400\n",
      "feat_name: (1380-1395,75-90), count_total: 7, num_trees: 7, samples: 59\n",
      "feat_name: (45-60,120-135), count_total: 7, num_trees: 7, samples: 635\n",
      "feat_name: (915-930,75-90), count_total: 3, num_trees: 3, samples: 205\n",
      "feat_name: (345-360,75-90), count_total: 3, num_trees: 3, samples: 174\n",
      "feat_name: (300-315,885-900), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (225-240,1050-1065), count_total: 3, num_trees: 3, samples: 331\n",
      "feat_name: (30-45,1380-1395), count_total: 4, num_trees: 4, samples: 221\n",
      "feat_name: (180-195,1290-1305), count_total: 7, num_trees: 7, samples: 700\n",
      "feat_name: (1110-1125,90-105), count_total: 2, num_trees: 2, samples: 97\n",
      "feat_name: (195-210,915-930), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (285-300,1290-1305), count_total: 2, num_trees: 2, samples: 266\n",
      "feat_name: (990-1005,135-150), count_total: 2, num_trees: 2, samples: 91\n",
      "feat_name: (180-195,105-120), count_total: 2, num_trees: 2, samples: 115\n",
      "feat_name: (15-30,225-240), count_total: 4, num_trees: 4, samples: 202\n",
      "feat_name: (615-630,1410-1425), count_total: 3, num_trees: 3, samples: 135\n",
      "feat_name: (1485-1500,225-240), count_total: 3, num_trees: 3, samples: 278\n",
      "feat_name: (270-285,1290-1305), count_total: 5, num_trees: 5, samples: 408\n",
      "feat_name: (90-105,120-135), count_total: 5, num_trees: 5, samples: 500\n",
      "feat_name: (1485-1500,240-255), count_total: 2, num_trees: 2, samples: 73\n",
      "feat_name: (45-60,705-720), count_total: 2, num_trees: 2, samples: 104\n",
      "feat_name: (1290-1305,195-210), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (1365-1380,135-150), count_total: 10, num_trees: 10, samples: 935\n",
      "feat_name: (930-945,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1395-1410,135-150), count_total: 12, num_trees: 12, samples: 955\n",
      "feat_name: (135-150,915-930), count_total: 3, num_trees: 3, samples: 240\n",
      "feat_name: (1095-1110,105-120), count_total: 2, num_trees: 2, samples: 10\n",
      "feat_name: (930-945,75-90), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (1410-1425,285-300), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (45-60,900-915), count_total: 4, num_trees: 4, samples: 417\n",
      "feat_name: (0-15,540-555), count_total: 2, num_trees: 2, samples: 186\n",
      "feat_name: (825-840,180-195), count_total: 2, num_trees: 2, samples: 270\n",
      "feat_name: (195-210,1380-1395), count_total: 2, num_trees: 2, samples: 134\n",
      "feat_name: (0-15,270-285), count_total: 7, num_trees: 7, samples: 422\n",
      "feat_name: (1365-1380,900-915), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (180-195,1380-1395), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (0-15,465-480), count_total: 2, num_trees: 2, samples: 22\n",
      "feat_name: (1395-1410,735-750), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (495-510,105-120), count_total: 3, num_trees: 3, samples: 306\n",
      "feat_name: (975-990,60-75), count_total: 6, num_trees: 6, samples: 969\n",
      "feat_name: (1020-1035,420-435), count_total: 3, num_trees: 3, samples: 395\n",
      "feat_name: (120-135,1380-1395), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (1110-1125,540-555), count_total: 2, num_trees: 2, samples: 238\n",
      "feat_name: (1095-1110,1035-1050), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (90-105,885-900), count_total: 3, num_trees: 3, samples: 162\n",
      "feat_name: (270-285,1080-1095), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (1245-1260,90-105), count_total: 8, num_trees: 8, samples: 604\n",
      "feat_name: (1425-1440,1380-1395), count_total: 4, num_trees: 4, samples: 152\n",
      "feat_name: (0-15,525-540), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (570-585,135-150), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1440-1455,75-90), count_total: 3, num_trees: 3, samples: 119\n",
      "feat_name: (390-405,90-105), count_total: 6, num_trees: 6, samples: 202\n",
      "feat_name: (0-15,720-735), count_total: 10, num_trees: 10, samples: 1016\n",
      "feat_name: (1245-1260,660-675), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (150-165,900-915), count_total: 3, num_trees: 3, samples: 322\n",
      "feat_name: (75-90,1065-1080), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (795-810,60-75), count_total: 2, num_trees: 2, samples: 59\n",
      "feat_name: (1215-1230,90-105), count_total: 3, num_trees: 3, samples: 109\n",
      "feat_name: (960-975,1410-1425), count_total: 4, num_trees: 4, samples: 398\n",
      "feat_name: (885-900,90-105), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (90-105,90-105), count_total: 2, num_trees: 2, samples: 95\n",
      "feat_name: (1020-1035,120-135), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (120-135,75-90), count_total: 2, num_trees: 2, samples: 203\n",
      "feat_name: (135-150,900-915), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (555-570,450-465), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (930-945,345-360), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1230-1245,90-105), count_total: 10, num_trees: 10, samples: 685\n",
      "feat_name: (1395-1410,315-330), count_total: 1, num_trees: 1, samples: 79\n",
      "feat_name: (240-255,105-120), count_total: 2, num_trees: 2, samples: 105\n",
      "feat_name: (1065-1080,1380-1395), count_total: 3, num_trees: 3, samples: 154\n",
      "feat_name: (675-690,135-150), count_total: 4, num_trees: 4, samples: 365\n",
      "feat_name: (1095-1110,75-90), count_total: 2, num_trees: 2, samples: 21\n",
      "feat_name: (795-810,300-315), count_total: 3, num_trees: 3, samples: 230\n",
      "feat_name: (540-555,120-135), count_total: 2, num_trees: 2, samples: 193\n",
      "feat_name: (1260-1275,360-375), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1005-1020,420-435), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (270-285,180-195), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (555-570,1425-1440), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (105-120,1380-1395), count_total: 5, num_trees: 5, samples: 416\n",
      "feat_name: (1455-1470,930-945), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (60-75,1290-1305), count_total: 2, num_trees: 2, samples: 116\n",
      "feat_name: (390-405,1290-1305), count_total: 3, num_trees: 3, samples: 144\n",
      "feat_name: (915-930,840-855), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (915-930,90-105), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (345-360,240-255), count_total: 2, num_trees: 2, samples: 174\n",
      "feat_name: (90-105,900-915), count_total: 9, num_trees: 9, samples: 983\n",
      "feat_name: (45-60,1290-1305), count_total: 2, num_trees: 2, samples: 223\n",
      "feat_name: (1080-1095,90-105), count_total: 2, num_trees: 2, samples: 94\n",
      "feat_name: (1425-1440,105-120), count_total: 7, num_trees: 7, samples: 522\n",
      "feat_name: (630-645,255-270), count_total: 7, num_trees: 7, samples: 550\n",
      "feat_name: (1050-1065,825-840), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (480-495,150-165), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (780-795,105-120), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (345-360,180-195), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (105-120,120-135), count_total: 2, num_trees: 2, samples: 243\n",
      "feat_name: (960-975,60-75), count_total: 3, num_trees: 3, samples: 214\n",
      "feat_name: (885-900,1305-1320), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1125-1140,1410-1425), count_total: 6, num_trees: 6, samples: 888\n",
      "feat_name: (1470-1485,105-120), count_total: 5, num_trees: 5, samples: 271\n",
      "feat_name: (1485-1500,735-750), count_total: 4, num_trees: 4, samples: 417\n",
      "feat_name: (1350-1365,420-435), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (585-600,930-945), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (1425-1440,420-435), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (1170-1185,270-285), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (0-15,285-300), count_total: 2, num_trees: 2, samples: 239\n",
      "feat_name: (45-60,165-180), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (315-330,825-840), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (1305-1320,360-375), count_total: 3, num_trees: 3, samples: 294\n",
      "feat_name: (30-45,900-915), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (420-435,165-180), count_total: 2, num_trees: 2, samples: 222\n",
      "feat_name: (300-315,900-915), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (1455-1470,570-585), count_total: 2, num_trees: 2, samples: 138\n",
      "feat_name: (195-210,900-915), count_total: 3, num_trees: 3, samples: 388\n",
      "feat_name: (1485-1500,1080-1095), count_total: 2, num_trees: 2, samples: 257\n",
      "feat_name: (1005-1020,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (630-645,750-765), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1200-1215,390-405), count_total: 6, num_trees: 6, samples: 475\n",
      "feat_name: (1440-1455,735-750), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (30-45,480-495), count_total: 3, num_trees: 3, samples: 398\n",
      "feat_name: (1275-1290,75-90), count_total: 4, num_trees: 4, samples: 129\n",
      "feat_name: (45-60,135-150), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (1455-1470,225-240), count_total: 3, num_trees: 3, samples: 272\n",
      "feat_name: (555-570,1410-1425), count_total: 4, num_trees: 4, samples: 201\n",
      "feat_name: (90-105,1290-1305), count_total: 3, num_trees: 3, samples: 373\n",
      "feat_name: (990-1005,645-660), count_total: 2, num_trees: 2, samples: 177\n",
      "feat_name: (750-765,60-75), count_total: 3, num_trees: 3, samples: 178\n",
      "feat_name: (450-465,1245-1260), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (435-450,135-150), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (120-135,60-75), count_total: 6, num_trees: 6, samples: 407\n",
      "feat_name: (1245-1260,300-315), count_total: 3, num_trees: 3, samples: 173\n",
      "feat_name: (75-90,1245-1260), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1110-1125,105-120), count_total: 8, num_trees: 8, samples: 742\n",
      "feat_name: (1095-1110,825-840), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (510-525,1410-1425), count_total: 1, num_trees: 1, samples: 133\n",
      "feat_name: (1080-1095,75-90), count_total: 3, num_trees: 3, samples: 16\n",
      "feat_name: (420-435,60-75), count_total: 3, num_trees: 3, samples: 227\n",
      "feat_name: (30-45,75-90), count_total: 2, num_trees: 2, samples: 30\n",
      "feat_name: (150-165,75-90), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (90-105,270-285), count_total: 2, num_trees: 2, samples: 107\n",
      "feat_name: (885-900,60-75), count_total: 2, num_trees: 2, samples: 101\n",
      "feat_name: (345-360,270-285), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (45-60,840-855), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (105-120,930-945), count_total: 6, num_trees: 6, samples: 547\n",
      "feat_name: (105-120,660-675), count_total: 2, num_trees: 2, samples: 225\n",
      "feat_name: (180-195,165-180), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (855-870,1290-1305), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (1425-1440,60-75), count_total: 3, num_trees: 3, samples: 130\n",
      "feat_name: (585-600,1380-1395), count_total: 3, num_trees: 3, samples: 342\n",
      "feat_name: (660-675,945-960), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (0-15,420-435), count_total: 2, num_trees: 2, samples: 141\n",
      "feat_name: (705-720,90-105), count_total: 5, num_trees: 5, samples: 471\n",
      "feat_name: (150-165,105-120), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (1080-1095,165-180), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (1200-1215,90-105), count_total: 4, num_trees: 4, samples: 114\n",
      "feat_name: (390-405,240-255), count_total: 2, num_trees: 2, samples: 167\n",
      "feat_name: (1245-1260,255-270), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1095-1110,555-570), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (945-960,1380-1395), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (60-75,1380-1395), count_total: 4, num_trees: 4, samples: 376\n",
      "feat_name: (915-930,60-75), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1485-1500,1185-1200), count_total: 4, num_trees: 4, samples: 373\n",
      "feat_name: (690-705,390-405), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (375-390,1410-1425), count_total: 4, num_trees: 4, samples: 373\n",
      "feat_name: (405-420,240-255), count_total: 6, num_trees: 6, samples: 491\n",
      "feat_name: (1425-1440,390-405), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (120-135,1290-1305), count_total: 4, num_trees: 4, samples: 289\n",
      "feat_name: (1170-1185,75-90), count_total: 3, num_trees: 3, samples: 20\n",
      "feat_name: (975-990,615-630), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (1470-1485,480-495), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (810-825,1410-1425), count_total: 2, num_trees: 2, samples: 253\n",
      "feat_name: (1410-1425,420-435), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (1455-1470,75-90), count_total: 4, num_trees: 4, samples: 123\n",
      "feat_name: (345-360,1275-1290), count_total: 2, num_trees: 2, samples: 198\n",
      "feat_name: (960-975,1170-1185), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (1260-1275,1380-1395), count_total: 2, num_trees: 2, samples: 141\n",
      "feat_name: (15-30,120-135), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (270-285,1410-1425), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (945-960,450-465), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1320-1335,60-75), count_total: 10, num_trees: 9, samples: 833\n",
      "feat_name: (465-480,1410-1425), count_total: 2, num_trees: 2, samples: 89\n",
      "feat_name: (1140-1155,825-840), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (900-915,180-195), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (855-870,120-135), count_total: 1, num_trees: 1, samples: 133\n",
      "feat_name: (150-165,1290-1305), count_total: 2, num_trees: 2, samples: 131\n",
      "feat_name: (675-690,330-345), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (735-750,195-210), count_total: 2, num_trees: 2, samples: 132\n",
      "feat_name: (1485-1500,405-420), count_total: 3, num_trees: 3, samples: 188\n",
      "feat_name: (1350-1365,105-120), count_total: 6, num_trees: 6, samples: 472\n",
      "feat_name: (675-690,75-90), count_total: 2, num_trees: 2, samples: 96\n",
      "feat_name: (1260-1275,270-285), count_total: 3, num_trees: 3, samples: 272\n",
      "feat_name: (1065-1080,390-405), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1170-1185,510-525), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (30-45,315-330), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1095-1110,60-75), count_total: 11, num_trees: 11, samples: 1193\n",
      "feat_name: (1020-1035,1410-1425), count_total: 4, num_trees: 4, samples: 466\n",
      "feat_name: (930-945,90-105), count_total: 3, num_trees: 3, samples: 91\n",
      "feat_name: (420-435,1320-1335), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1140-1155,60-75), count_total: 4, num_trees: 4, samples: 425\n",
      "feat_name: (780-795,495-510), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (30-45,105-120), count_total: 6, num_trees: 6, samples: 611\n",
      "feat_name: (855-870,1050-1065), count_total: 2, num_trees: 2, samples: 135\n",
      "feat_name: (1155-1170,1380-1395), count_total: 4, num_trees: 4, samples: 117\n",
      "feat_name: (345-360,165-180), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (555-570,60-75), count_total: 5, num_trees: 5, samples: 416\n",
      "feat_name: (285-300,60-75), count_total: 2, num_trees: 2, samples: 45\n",
      "feat_name: (1380-1395,60-75), count_total: 4, num_trees: 4, samples: 270\n",
      "feat_name: (1200-1215,480-495), count_total: 1, num_trees: 1, samples: 78\n",
      "feat_name: (420-435,90-105), count_total: 2, num_trees: 2, samples: 183\n",
      "feat_name: (75-90,180-195), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1470-1485,120-135), count_total: 2, num_trees: 2, samples: 231\n",
      "feat_name: (360-375,1290-1305), count_total: 2, num_trees: 2, samples: 227\n",
      "feat_name: (1185-1200,195-210), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1440-1455,240-255), count_total: 2, num_trees: 2, samples: 94\n",
      "feat_name: (930-945,435-450), count_total: 2, num_trees: 2, samples: 127\n",
      "feat_name: (1125-1140,90-105), count_total: 3, num_trees: 3, samples: 257\n",
      "feat_name: (300-315,195-210), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1305-1320,1380-1395), count_total: 8, num_trees: 8, samples: 569\n",
      "feat_name: (1485-1500,300-315), count_total: 10, num_trees: 10, samples: 784\n",
      "feat_name: (840-855,510-525), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1275-1290,105-120), count_total: 3, num_trees: 3, samples: 467\n",
      "feat_name: (1005-1020,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (390-405,315-330), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (195-210,630-645), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (0-15,405-420), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1245-1260,60-75), count_total: 3, num_trees: 3, samples: 153\n",
      "feat_name: (390-405,675-690), count_total: 2, num_trees: 2, samples: 78\n",
      "feat_name: (15-30,945-960), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (825-840,345-360), count_total: 2, num_trees: 2, samples: 236\n",
      "feat_name: (645-660,930-945), count_total: 2, num_trees: 2, samples: 9\n",
      "feat_name: (1230-1245,345-360), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (870-885,1425-1440), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (945-960,105-120), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (1290-1305,480-495), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (105-120,900-915), count_total: 5, num_trees: 5, samples: 594\n",
      "feat_name: (0-15,1350-1365), count_total: 1, num_trees: 1, samples: 20\n",
      "feat_name: (105-120,1305-1320), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (1395-1410,1380-1395), count_total: 2, num_trees: 2, samples: 208\n",
      "feat_name: (1140-1155,210-225), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (735-750,1215-1230), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (360-375,1410-1425), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (435-450,900-915), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (765-780,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1245-1260,345-360), count_total: 2, num_trees: 2, samples: 89\n",
      "feat_name: (300-315,330-345), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (600-615,480-495), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1110-1125,1185-1200), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (135-150,1290-1305), count_total: 8, num_trees: 8, samples: 1018\n",
      "feat_name: (690-705,1005-1020), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (1335-1350,75-90), count_total: 5, num_trees: 5, samples: 51\n",
      "feat_name: (990-1005,90-105), count_total: 2, num_trees: 2, samples: 18\n",
      "feat_name: (1395-1410,480-495), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (915-930,120-135), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (45-60,720-735), count_total: 2, num_trees: 2, samples: 178\n",
      "feat_name: (660-675,135-150), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1230-1245,375-390), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1215-1230,675-690), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1245-1260,75-90), count_total: 3, num_trees: 3, samples: 29\n",
      "feat_name: (420-435,75-90), count_total: 4, num_trees: 4, samples: 408\n",
      "feat_name: (555-570,1380-1395), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1290-1305,90-105), count_total: 4, num_trees: 4, samples: 102\n",
      "feat_name: (570-585,750-765), count_total: 2, num_trees: 2, samples: 234\n",
      "feat_name: (1110-1125,1380-1395), count_total: 7, num_trees: 7, samples: 700\n",
      "feat_name: (585-600,105-120), count_total: 2, num_trees: 2, samples: 132\n",
      "feat_name: (1035-1050,1410-1425), count_total: 4, num_trees: 4, samples: 333\n",
      "feat_name: (210-225,1380-1395), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (105-120,105-120), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (1185-1200,525-540), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1470-1485,900-915), count_total: 5, num_trees: 5, samples: 303\n",
      "feat_name: (405-420,90-105), count_total: 2, num_trees: 2, samples: 176\n",
      "feat_name: (855-870,105-120), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (1470-1485,435-450), count_total: 4, num_trees: 4, samples: 419\n",
      "feat_name: (1170-1185,225-240), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (135-150,1065-1080), count_total: 2, num_trees: 2, samples: 32\n",
      "feat_name: (975-990,1095-1110), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1470-1485,165-180), count_total: 2, num_trees: 2, samples: 81\n",
      "feat_name: (75-90,900-915), count_total: 5, num_trees: 5, samples: 478\n",
      "feat_name: (165-180,60-75), count_total: 2, num_trees: 2, samples: 245\n",
      "feat_name: (1485-1500,630-645), count_total: 4, num_trees: 4, samples: 431\n",
      "feat_name: (1185-1200,285-300), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (705-720,645-660), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1455-1470,135-150), count_total: 2, num_trees: 2, samples: 10\n",
      "feat_name: (420-435,1410-1425), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1290-1305,1215-1230), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (930-945,195-210), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (1185-1200,105-120), count_total: 3, num_trees: 3, samples: 87\n",
      "feat_name: (525-540,315-330), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (390-405,1410-1425), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1320-1335,450-465), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (15-30,1185-1200), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (1110-1125,435-450), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (1050-1065,1380-1395), count_total: 8, num_trees: 8, samples: 313\n",
      "feat_name: (240-255,90-105), count_total: 2, num_trees: 2, samples: 103\n",
      "feat_name: (630-645,435-450), count_total: 5, num_trees: 5, samples: 388\n",
      "feat_name: (975-990,525-540), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1125-1140,225-240), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1470-1485,270-285), count_total: 6, num_trees: 6, samples: 569\n",
      "feat_name: (1215-1230,870-885), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (435-450,285-300), count_total: 1, num_trees: 1, samples: 25\n",
      "feat_name: (975-990,1335-1350), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (1365-1380,1050-1065), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (1395-1410,1305-1320), count_total: 2, num_trees: 2, samples: 269\n",
      "feat_name: (1485-1500,675-690), count_total: 2, num_trees: 2, samples: 13\n",
      "feat_name: (600-615,435-450), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (1155-1170,60-75), count_total: 2, num_trees: 2, samples: 184\n",
      "feat_name: (1035-1050,150-165), count_total: 5, num_trees: 5, samples: 440\n",
      "feat_name: (1485-1500,270-285), count_total: 4, num_trees: 4, samples: 117\n",
      "feat_name: (885-900,915-930), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (675-690,1305-1320), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (555-570,120-135), count_total: 4, num_trees: 4, samples: 195\n",
      "feat_name: (60-75,105-120), count_total: 2, num_trees: 2, samples: 125\n",
      "feat_name: (630-645,1410-1425), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1275-1290,165-180), count_total: 2, num_trees: 2, samples: 5\n",
      "feat_name: (675-690,285-300), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (810-825,540-555), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (1305-1320,270-285), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (165-180,135-150), count_total: 5, num_trees: 5, samples: 426\n",
      "feat_name: (135-150,120-135), count_total: 3, num_trees: 3, samples: 318\n",
      "feat_name: (330-345,210-225), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (870-885,75-90), count_total: 3, num_trees: 3, samples: 16\n",
      "feat_name: (1410-1425,60-75), count_total: 6, num_trees: 6, samples: 555\n",
      "feat_name: (960-975,90-105), count_total: 3, num_trees: 3, samples: 110\n",
      "feat_name: (1425-1440,885-900), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (615-630,105-120), count_total: 1, num_trees: 1, samples: 79\n",
      "feat_name: (1440-1455,945-960), count_total: 3, num_trees: 3, samples: 254\n",
      "feat_name: (420-435,135-150), count_total: 1, num_trees: 1, samples: 77\n",
      "feat_name: (945-960,1425-1440), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (1050-1065,75-90), count_total: 5, num_trees: 5, samples: 47\n",
      "feat_name: (120-135,150-165), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (105-120,390-405), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (165-180,1290-1305), count_total: 4, num_trees: 4, samples: 391\n",
      "feat_name: (165-180,105-120), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (1215-1230,225-240), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (420-435,420-435), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (120-135,660-675), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1395-1410,945-960), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (840-855,450-465), count_total: 1, num_trees: 1, samples: 130\n",
      "feat_name: (330-345,90-105), count_total: 2, num_trees: 2, samples: 108\n",
      "feat_name: (1185-1200,1425-1440), count_total: 2, num_trees: 2, samples: 207\n",
      "feat_name: (1170-1185,420-435), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1365-1380,1380-1395), count_total: 3, num_trees: 3, samples: 254\n",
      "feat_name: (975-990,150-165), count_total: 3, num_trees: 3, samples: 266\n",
      "feat_name: (105-120,720-735), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (1200-1215,60-75), count_total: 3, num_trees: 3, samples: 146\n",
      "feat_name: (1470-1485,630-645), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (540-555,90-105), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1275-1290,1410-1425), count_total: 3, num_trees: 3, samples: 219\n",
      "feat_name: (975-990,975-990), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1065-1080,1425-1440), count_total: 2, num_trees: 2, samples: 337\n",
      "feat_name: (1350-1365,720-735), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (585-600,840-855), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1035-1050,225-240), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (15-30,1410-1425), count_total: 2, num_trees: 2, samples: 186\n",
      "feat_name: (600-615,690-705), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1410-1425,390-405), count_total: 2, num_trees: 2, samples: 108\n",
      "feat_name: (1080-1095,1065-1080), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (195-210,225-240), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (90-105,855-870), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (525-540,1410-1425), count_total: 5, num_trees: 5, samples: 246\n",
      "feat_name: (810-825,105-120), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (105-120,495-510), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1185-1200,1410-1425), count_total: 3, num_trees: 3, samples: 19\n",
      "feat_name: (720-735,150-165), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1185-1200,570-585), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (1485-1500,285-300), count_total: 3, num_trees: 3, samples: 204\n",
      "feat_name: (765-780,390-405), count_total: 1, num_trees: 1, samples: 121\n",
      "feat_name: (405-420,135-150), count_total: 5, num_trees: 5, samples: 433\n",
      "feat_name: (1455-1470,360-375), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (1020-1035,585-600), count_total: 3, num_trees: 3, samples: 330\n",
      "feat_name: (1410-1425,90-105), count_total: 7, num_trees: 7, samples: 53\n",
      "feat_name: (405-420,150-165), count_total: 3, num_trees: 3, samples: 236\n",
      "feat_name: (1050-1065,1425-1440), count_total: 5, num_trees: 5, samples: 683\n",
      "feat_name: (195-210,90-105), count_total: 2, num_trees: 2, samples: 15\n",
      "feat_name: (1065-1080,1410-1425), count_total: 2, num_trees: 2, samples: 109\n",
      "feat_name: (1200-1215,1425-1440), count_total: 7, num_trees: 7, samples: 757\n",
      "feat_name: (1035-1050,135-150), count_total: 2, num_trees: 2, samples: 272\n",
      "feat_name: (1110-1125,390-405), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1275-1290,735-750), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (495-510,945-960), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1230-1245,60-75), count_total: 7, num_trees: 7, samples: 636\n",
      "feat_name: (990-1005,480-495), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (150-165,360-375), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1005-1020,1410-1425), count_total: 6, num_trees: 6, samples: 772\n",
      "feat_name: (1260-1275,75-90), count_total: 3, num_trees: 3, samples: 38\n",
      "feat_name: (795-810,405-420), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1290-1305,165-180), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1380-1395,255-270), count_total: 3, num_trees: 3, samples: 248\n",
      "feat_name: (540-555,1410-1425), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (240-255,1290-1305), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (1080-1095,465-480), count_total: 2, num_trees: 2, samples: 207\n",
      "feat_name: (1185-1200,330-345), count_total: 2, num_trees: 2, samples: 109\n",
      "feat_name: (660-675,1410-1425), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1365-1380,480-495), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1200-1215,105-120), count_total: 4, num_trees: 4, samples: 388\n",
      "feat_name: (240-255,135-150), count_total: 3, num_trees: 3, samples: 286\n",
      "feat_name: (1380-1395,1170-1185), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (1455-1470,1080-1095), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (165-180,285-300), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1290-1305,240-255), count_total: 2, num_trees: 2, samples: 243\n",
      "feat_name: (105-120,885-900), count_total: 2, num_trees: 2, samples: 224\n",
      "feat_name: (600-615,960-975), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (150-165,840-855), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (885-900,1350-1365), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1140-1155,90-105), count_total: 2, num_trees: 2, samples: 111\n",
      "feat_name: (645-660,720-735), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (345-360,285-300), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (90-105,870-885), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1305-1320,660-675), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (645-660,1005-1020), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (450-465,255-270), count_total: 2, num_trees: 2, samples: 131\n",
      "feat_name: (300-315,930-945), count_total: 2, num_trees: 2, samples: 223\n",
      "feat_name: (615-630,60-75), count_total: 2, num_trees: 2, samples: 4\n",
      "feat_name: (1410-1425,75-90), count_total: 3, num_trees: 3, samples: 24\n",
      "feat_name: (195-210,60-75), count_total: 2, num_trees: 2, samples: 129\n",
      "feat_name: (1125-1140,900-915), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (450-465,270-285), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (60-75,525-540), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (810-825,825-840), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (900-915,120-135), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (1155-1170,75-90), count_total: 3, num_trees: 3, samples: 21\n",
      "feat_name: (0-15,900-915), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (870-885,345-360), count_total: 1, num_trees: 1, samples: 142\n",
      "feat_name: (630-645,90-105), count_total: 2, num_trees: 2, samples: 225\n",
      "feat_name: (885-900,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1380-1395,495-510), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (135-150,105-120), count_total: 3, num_trees: 3, samples: 223\n",
      "feat_name: (225-240,90-105), count_total: 3, num_trees: 3, samples: 131\n",
      "feat_name: (1230-1245,1425-1440), count_total: 1, num_trees: 1, samples: 144\n",
      "feat_name: (1305-1320,105-120), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1365-1380,975-990), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1110-1125,75-90), count_total: 2, num_trees: 2, samples: 122\n",
      "feat_name: (1350-1365,390-405), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1455-1470,105-120), count_total: 3, num_trees: 3, samples: 341\n",
      "feat_name: (1455-1470,795-810), count_total: 2, num_trees: 2, samples: 115\n",
      "feat_name: (750-765,1230-1245), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (1095-1110,1380-1395), count_total: 5, num_trees: 5, samples: 676\n",
      "feat_name: (945-960,1410-1425), count_total: 1, num_trees: 1, samples: 147\n",
      "feat_name: (705-720,210-225), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (300-315,510-525), count_total: 1, num_trees: 1, samples: 121\n",
      "feat_name: (360-375,165-180), count_total: 3, num_trees: 3, samples: 252\n",
      "feat_name: (180-195,1410-1425), count_total: 3, num_trees: 3, samples: 303\n",
      "feat_name: (660-675,1335-1350), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (975-990,75-90), count_total: 2, num_trees: 2, samples: 14\n",
      "feat_name: (990-1005,60-75), count_total: 1, num_trees: 1, samples: 170\n",
      "feat_name: (1020-1035,75-90), count_total: 3, num_trees: 3, samples: 110\n",
      "feat_name: (540-555,60-75), count_total: 2, num_trees: 2, samples: 98\n",
      "feat_name: (1425-1440,330-345), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1440-1455,225-240), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (570-585,120-135), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1035-1050,1395-1410), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1455-1470,150-165), count_total: 1, num_trees: 1, samples: 136\n",
      "feat_name: (270-285,990-1005), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1080-1095,390-405), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (465-480,885-900), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (420-435,105-120), count_total: 3, num_trees: 3, samples: 199\n",
      "feat_name: (675-690,105-120), count_total: 2, num_trees: 2, samples: 15\n",
      "feat_name: (1425-1440,1305-1320), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (840-855,285-300), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1335-1350,930-945), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (1365-1380,270-285), count_total: 3, num_trees: 3, samples: 306\n",
      "feat_name: (420-435,1110-1125), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (135-150,240-255), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (285-300,465-480), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (900-915,75-90), count_total: 2, num_trees: 2, samples: 20\n",
      "feat_name: (375-390,390-405), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1425-1440,945-960), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (90-105,915-930), count_total: 4, num_trees: 4, samples: 516\n",
      "feat_name: (1290-1305,225-240), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (1485-1500,900-915), count_total: 2, num_trees: 2, samples: 168\n",
      "feat_name: (1200-1215,1080-1095), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (0-15,660-675), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (360-375,1155-1170), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (270-285,735-750), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (870-885,60-75), count_total: 2, num_trees: 2, samples: 44\n",
      "feat_name: (1005-1020,1425-1440), count_total: 3, num_trees: 3, samples: 205\n",
      "feat_name: (1395-1410,255-270), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (570-585,735-750), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (390-405,120-135), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (195-210,105-120), count_total: 2, num_trees: 2, samples: 220\n",
      "feat_name: (375-390,105-120), count_total: 3, num_trees: 3, samples: 345\n",
      "feat_name: (45-60,495-510), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (75-90,1035-1050), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1305-1320,225-240), count_total: 2, num_trees: 2, samples: 64\n",
      "feat_name: (120-135,420-435), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (525-540,945-960), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (450-465,330-345), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (1245-1260,225-240), count_total: 1, num_trees: 1, samples: 37\n",
      "feat_name: (255-270,1380-1395), count_total: 1, num_trees: 1, samples: 33\n",
      "feat_name: (105-120,90-105), count_total: 5, num_trees: 5, samples: 14\n",
      "feat_name: (285-300,1065-1080), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (1275-1290,1425-1440), count_total: 2, num_trees: 2, samples: 199\n",
      "feat_name: (435-450,75-90), count_total: 2, num_trees: 2, samples: 15\n",
      "feat_name: (690-705,120-135), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (15-30,1230-1245), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (435-450,270-285), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (225-240,120-135), count_total: 2, num_trees: 2, samples: 191\n",
      "feat_name: (1380-1395,1275-1290), count_total: 2, num_trees: 2, samples: 183\n",
      "feat_name: (645-660,900-915), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1245-1260,1380-1395), count_total: 3, num_trees: 3, samples: 158\n",
      "feat_name: (180-195,90-105), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (750-765,930-945), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1245-1260,120-135), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (135-150,930-945), count_total: 1, num_trees: 1, samples: 140\n",
      "feat_name: (600-615,1410-1425), count_total: 4, num_trees: 4, samples: 496\n",
      "feat_name: (1290-1305,1380-1395), count_total: 5, num_trees: 5, samples: 452\n",
      "feat_name: (600-615,225-240), count_total: 2, num_trees: 2, samples: 192\n",
      "feat_name: (690-705,75-90), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (60-75,1350-1365), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (975-990,120-135), count_total: 2, num_trees: 2, samples: 190\n",
      "feat_name: (315-330,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1065-1080,825-840), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (360-375,150-165), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (210-225,120-135), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (1380-1395,435-450), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (780-795,1290-1305), count_total: 2, num_trees: 2, samples: 29\n",
      "feat_name: (465-480,720-735), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (210-225,375-390), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (990-1005,105-120), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1365-1380,465-480), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (1410-1425,1035-1050), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (510-525,105-120), count_total: 4, num_trees: 4, samples: 194\n",
      "feat_name: (45-60,75-90), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (165-180,840-855), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (990-1005,570-585), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1260-1275,1035-1050), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1245-1260,315-330), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (90-105,1335-1350), count_total: 2, num_trees: 2, samples: 42\n",
      "feat_name: (660-675,120-135), count_total: 2, num_trees: 2, samples: 94\n",
      "feat_name: (15-30,105-120), count_total: 2, num_trees: 2, samples: 17\n",
      "feat_name: (765-780,1380-1395), count_total: 2, num_trees: 2, samples: 94\n",
      "feat_name: (300-315,1020-1035), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (1095-1110,225-240), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1125-1140,915-930), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (1185-1200,240-255), count_total: 3, num_trees: 3, samples: 405\n",
      "feat_name: (810-825,60-75), count_total: 2, num_trees: 2, samples: 35\n",
      "feat_name: (375-390,90-105), count_total: 9, num_trees: 8, samples: 600\n",
      "feat_name: (375-390,75-90), count_total: 4, num_trees: 4, samples: 277\n",
      "feat_name: (165-180,645-660), count_total: 1, num_trees: 1, samples: 74\n",
      "feat_name: (330-345,780-795), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (30-45,765-780), count_total: 1, num_trees: 1, samples: 40\n",
      "feat_name: (150-165,930-945), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (270-285,840-855), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (1335-1350,225-240), count_total: 2, num_trees: 2, samples: 101\n",
      "feat_name: (1305-1320,1350-1365), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (945-960,630-645), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (1140-1155,75-90), count_total: 2, num_trees: 2, samples: 6\n",
      "feat_name: (1200-1215,75-90), count_total: 4, num_trees: 4, samples: 111\n",
      "feat_name: (630-645,300-315), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (375-390,735-750), count_total: 2, num_trees: 2, samples: 108\n",
      "feat_name: (120-135,720-735), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (630-645,135-150), count_total: 3, num_trees: 3, samples: 269\n",
      "feat_name: (1200-1215,1380-1395), count_total: 4, num_trees: 4, samples: 33\n",
      "feat_name: (180-195,75-90), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (660-675,150-165), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (330-345,75-90), count_total: 2, num_trees: 2, samples: 123\n",
      "feat_name: (90-105,1140-1155), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (930-945,1425-1440), count_total: 1, num_trees: 1, samples: 35\n",
      "feat_name: (225-240,1170-1185), count_total: 1, num_trees: 1, samples: 28\n",
      "feat_name: (1125-1140,120-135), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (945-960,435-450), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (870-885,1380-1395), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (135-150,60-75), count_total: 4, num_trees: 4, samples: 513\n",
      "feat_name: (1395-1410,825-840), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (30-45,1350-1365), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (645-660,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1245-1260,270-285), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (1440-1455,495-510), count_total: 2, num_trees: 2, samples: 204\n",
      "feat_name: (1110-1125,825-840), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (225-240,105-120), count_total: 1, num_trees: 1, samples: 121\n",
      "feat_name: (225-240,300-315), count_total: 1, num_trees: 1, samples: 72\n",
      "feat_name: (585-600,450-465), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (1320-1335,105-120), count_total: 3, num_trees: 3, samples: 278\n",
      "feat_name: (30-45,1290-1305), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (360-375,915-930), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (1410-1425,1170-1185), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (45-60,870-885), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (90-105,75-90), count_total: 2, num_trees: 2, samples: 203\n",
      "feat_name: (885-900,270-285), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1125-1140,330-345), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (750-765,105-120), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1110-1125,120-135), count_total: 2, num_trees: 2, samples: 59\n",
      "feat_name: (1485-1500,1275-1290), count_total: 1, num_trees: 1, samples: 25\n",
      "feat_name: (30-45,390-405), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (1185-1200,585-600), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1020-1035,90-105), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (105-120,1020-1035), count_total: 1, num_trees: 1, samples: 139\n",
      "feat_name: (255-270,1125-1140), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (300-315,525-540), count_total: 1, num_trees: 1, samples: 140\n",
      "feat_name: (480-495,390-405), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1470-1485,1305-1320), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (75-90,120-135), count_total: 3, num_trees: 3, samples: 321\n",
      "feat_name: (1080-1095,1290-1305), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (945-960,60-75), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (1425-1440,270-285), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (405-420,1245-1260), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (525-540,135-150), count_total: 1, num_trees: 1, samples: 145\n",
      "feat_name: (1470-1485,225-240), count_total: 3, num_trees: 3, samples: 289\n",
      "feat_name: (1485-1500,360-375), count_total: 2, num_trees: 2, samples: 95\n",
      "feat_name: (765-780,480-495), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (510-525,1290-1305), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (450-465,135-150), count_total: 2, num_trees: 2, samples: 204\n",
      "feat_name: (705-720,225-240), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (795-810,465-480), count_total: 2, num_trees: 2, samples: 262\n",
      "feat_name: (285-300,90-105), count_total: 3, num_trees: 3, samples: 164\n",
      "feat_name: (1470-1485,930-945), count_total: 2, num_trees: 2, samples: 230\n",
      "feat_name: (120-135,900-915), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (105-120,1350-1365), count_total: 2, num_trees: 2, samples: 144\n",
      "feat_name: (1350-1365,495-510), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1080-1095,300-315), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (885-900,1410-1425), count_total: 4, num_trees: 4, samples: 347\n",
      "feat_name: (1455-1470,735-750), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (420-435,930-945), count_total: 2, num_trees: 2, samples: 217\n",
      "feat_name: (1350-1365,435-450), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (705-720,135-150), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (855-870,90-105), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (630-645,120-135), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (135-150,1380-1395), count_total: 2, num_trees: 2, samples: 173\n",
      "feat_name: (1320-1335,1410-1425), count_total: 2, num_trees: 2, samples: 139\n",
      "feat_name: (1185-1200,270-285), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1440-1455,300-315), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (435-450,90-105), count_total: 2, num_trees: 2, samples: 126\n",
      "feat_name: (915-930,375-390), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (90-105,1350-1365), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (360-375,435-450), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1350-1365,270-285), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1470-1485,75-90), count_total: 4, num_trees: 4, samples: 39\n",
      "feat_name: (1200-1215,840-855), count_total: 1, num_trees: 1, samples: 136\n",
      "feat_name: (75-90,705-720), count_total: 1, num_trees: 1, samples: 134\n",
      "feat_name: (105-120,1065-1080), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1185-1200,390-405), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (45-60,1170-1185), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (75-90,1275-1290), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (660-675,255-270), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (1260-1275,300-315), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (1110-1125,1290-1305), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (1095-1110,120-135), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1455-1470,900-915), count_total: 2, num_trees: 2, samples: 197\n",
      "feat_name: (45-60,1350-1365), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (390-405,930-945), count_total: 2, num_trees: 2, samples: 222\n",
      "feat_name: (0-15,480-495), count_total: 2, num_trees: 2, samples: 227\n",
      "feat_name: (1200-1215,450-465), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (360-375,945-960), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1230-1245,165-180), count_total: 1, num_trees: 1, samples: 31\n",
      "feat_name: (1035-1050,105-120), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (795-810,1215-1230), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (870-885,555-570), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1305-1320,75-90), count_total: 4, num_trees: 4, samples: 132\n",
      "feat_name: (1110-1125,690-705), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (480-495,510-525), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1215-1230,1380-1395), count_total: 2, num_trees: 2, samples: 14\n",
      "feat_name: (60-75,900-915), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (675-690,990-1005), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1365-1380,300-315), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (1410-1425,735-750), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (30-45,510-525), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (330-345,900-915), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (255-270,720-735), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1380-1395,270-285), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1335-1350,510-525), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (210-225,1320-1335), count_total: 1, num_trees: 1, samples: 32\n",
      "feat_name: (405-420,180-195), count_total: 1, num_trees: 1, samples: 77\n",
      "feat_name: (990-1005,615-630), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (600-615,1200-1215), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (225-240,1380-1395), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (1215-1230,1425-1440), count_total: 3, num_trees: 3, samples: 227\n",
      "feat_name: (870-885,1410-1425), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (60-75,945-960), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1290-1305,1020-1035), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (990-1005,435-450), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (1425-1440,960-975), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (180-195,150-165), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (45-60,420-435), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (285-300,915-930), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (120-135,135-150), count_total: 3, num_trees: 3, samples: 213\n",
      "feat_name: (255-270,150-165), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (1335-1350,270-285), count_total: 2, num_trees: 2, samples: 203\n",
      "feat_name: (435-450,510-525), count_total: 1, num_trees: 1, samples: 143\n",
      "feat_name: (75-90,105-120), count_total: 3, num_trees: 3, samples: 194\n",
      "feat_name: (300-315,60-75), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1140-1155,285-300), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1305-1320,825-840), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (30-45,915-930), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (1170-1185,1410-1425), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (945-960,180-195), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (375-390,840-855), count_total: 2, num_trees: 2, samples: 193\n",
      "feat_name: (435-450,60-75), count_total: 3, num_trees: 3, samples: 162\n",
      "feat_name: (300-315,270-285), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (315-330,945-960), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (480-495,120-135), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1320-1335,1170-1185), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1440-1455,555-570), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (810-825,585-600), count_total: 1, num_trees: 1, samples: 138\n",
      "feat_name: (915-930,1380-1395), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (90-105,1170-1185), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (645-660,105-120), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (90-105,300-315), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (120-135,210-225), count_total: 2, num_trees: 2, samples: 175\n",
      "feat_name: (1215-1230,1035-1050), count_total: 2, num_trees: 2, samples: 169\n",
      "feat_name: (1050-1065,675-690), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (510-525,120-135), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (690-705,1410-1425), count_total: 2, num_trees: 2, samples: 124\n",
      "feat_name: (375-390,60-75), count_total: 2, num_trees: 2, samples: 116\n",
      "feat_name: (435-450,420-435), count_total: 1, num_trees: 1, samples: 32\n",
      "feat_name: (165-180,1410-1425), count_total: 2, num_trees: 2, samples: 156\n",
      "feat_name: (120-135,375-390), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (885-900,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1425-1440,300-315), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (30-45,1035-1050), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1470-1485,360-375), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (30-45,660-675), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1005-1020,360-375), count_total: 2, num_trees: 2, samples: 107\n",
      "feat_name: (120-135,510-525), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (765-780,600-615), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1410-1425,435-450), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (330-345,1245-1260), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (435-450,660-675), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (165-180,1380-1395), count_total: 3, num_trees: 3, samples: 256\n",
      "feat_name: (945-960,465-480), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (330-345,300-315), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (795-810,810-825), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1365-1380,150-165), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1260-1275,915-930), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (1440-1455,1290-1305), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (1485-1500,780-795), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (585-600,480-495), count_total: 2, num_trees: 2, samples: 118\n",
      "feat_name: (1395-1410,195-210), count_total: 2, num_trees: 2, samples: 20\n",
      "feat_name: (1080-1095,1020-1035), count_total: 1, num_trees: 1, samples: 139\n",
      "feat_name: (45-60,225-240), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (135-150,510-525), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (255-270,135-150), count_total: 1, num_trees: 1, samples: 79\n",
      "feat_name: (780-795,300-315), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (45-60,690-705), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (210-225,930-945), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1440-1455,255-270), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (1125-1140,60-75), count_total: 3, num_trees: 3, samples: 283\n",
      "feat_name: (930-945,540-555), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (1230-1245,225-240), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (225-240,615-630), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (120-135,330-345), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (1080-1095,285-300), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1065-1080,60-75), count_total: 1, num_trees: 1, samples: 33\n",
      "feat_name: (1125-1140,1425-1440), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1335-1350,1275-1290), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (105-120,75-90), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1365-1380,60-75), count_total: 4, num_trees: 4, samples: 219\n",
      "feat_name: (660-675,240-255), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (180-195,60-75), count_total: 1, num_trees: 1, samples: 135\n",
      "feat_name: (1290-1305,360-375), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (510-525,60-75), count_total: 2, num_trees: 2, samples: 145\n",
      "feat_name: (855-870,855-870), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1290-1305,120-135), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (45-60,1125-1140), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (1230-1245,75-90), count_total: 3, num_trees: 3, samples: 21\n",
      "feat_name: (405-420,60-75), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (1140-1155,1125-1140), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (315-330,660-675), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (45-60,945-960), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (60-75,930-945), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (435-450,750-765), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (45-60,150-165), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1290-1305,135-150), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (15-30,405-420), count_total: 2, num_trees: 2, samples: 274\n",
      "feat_name: (60-75,135-150), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (495-510,90-105), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (60-75,285-300), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (945-960,345-360), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1155-1170,270-285), count_total: 2, num_trees: 2, samples: 34\n",
      "feat_name: (1350-1365,135-150), count_total: 2, num_trees: 2, samples: 181\n",
      "feat_name: (870-885,435-450), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (165-180,900-915), count_total: 2, num_trees: 2, samples: 236\n",
      "feat_name: (315-330,900-915), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1365-1380,930-945), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (855-870,1410-1425), count_total: 2, num_trees: 2, samples: 283\n",
      "feat_name: (30-45,270-285), count_total: 2, num_trees: 2, samples: 81\n",
      "feat_name: (75-90,1320-1335), count_total: 1, num_trees: 1, samples: 144\n",
      "feat_name: (1425-1440,135-150), count_total: 3, num_trees: 3, samples: 285\n",
      "feat_name: (465-480,180-195), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (0-15,510-525), count_total: 2, num_trees: 2, samples: 267\n",
      "feat_name: (1020-1035,105-120), count_total: 2, num_trees: 2, samples: 6\n",
      "feat_name: (1395-1410,1320-1335), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (1050-1065,405-420), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (1200-1215,1410-1425), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (915-930,345-360), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (660-675,75-90), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (330-345,1410-1425), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1365-1380,120-135), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (225-240,1065-1080), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (630-645,1305-1320), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (480-495,720-735), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (1485-1500,495-510), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1410-1425,1320-1335), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (165-180,465-480), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (945-960,1365-1380), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (450-465,480-495), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (555-570,390-405), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1470-1485,1350-1365), count_total: 2, num_trees: 2, samples: 85\n",
      "feat_name: (570-585,705-720), count_total: 1, num_trees: 1, samples: 74\n",
      "feat_name: (375-390,1245-1260), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1365-1380,1365-1380), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (285-300,1245-1260), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (90-105,210-225), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (900-915,660-675), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (1185-1200,990-1005), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1215-1230,105-120), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1470-1485,1065-1080), count_total: 3, num_trees: 3, samples: 385\n",
      "feat_name: (225-240,285-300), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (60-75,90-105), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (330-345,930-945), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (795-810,105-120), count_total: 2, num_trees: 2, samples: 9\n",
      "feat_name: (1455-1470,90-105), count_total: 3, num_trees: 3, samples: 131\n",
      "feat_name: (480-495,1380-1395), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (885-900,900-915), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (750-765,1410-1425), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (15-30,180-195), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1110-1125,330-345), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (30-45,1185-1200), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (300-315,990-1005), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (690-705,765-780), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (75-90,75-90), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1440-1455,135-150), count_total: 2, num_trees: 2, samples: 170\n",
      "feat_name: (465-480,75-90), count_total: 2, num_trees: 2, samples: 102\n",
      "feat_name: (390-405,405-420), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1275-1290,240-255), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (525-540,90-105), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1320-1335,390-405), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (270-285,225-240), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1305-1320,120-135), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1470-1485,945-960), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (720-735,60-75), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (645-660,840-855), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (825-840,840-855), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (300-315,90-105), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (1320-1335,960-975), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (240-255,285-300), count_total: 1, num_trees: 1, samples: 138\n",
      "feat_name: (390-405,105-120), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1485-1500,585-600), count_total: 3, num_trees: 3, samples: 177\n",
      "feat_name: (390-405,540-555), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (240-255,195-210), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (315-330,270-285), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (240-255,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1065-1080,810-825), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (750-765,1425-1440), count_total: 2, num_trees: 2, samples: 28\n",
      "feat_name: (1155-1170,1410-1425), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (1155-1170,390-405), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (105-120,465-480), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (270-285,270-285), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (705-720,60-75), count_total: 2, num_trees: 2, samples: 103\n",
      "feat_name: (1485-1500,255-270), count_total: 2, num_trees: 2, samples: 174\n",
      "feat_name: (1410-1425,1290-1305), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (705-720,105-120), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (45-60,1005-1020), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (105-120,735-750), count_total: 1, num_trees: 1, samples: 143\n",
      "feat_name: (1440-1455,480-495), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (360-375,240-255), count_total: 1, num_trees: 1, samples: 77\n",
      "feat_name: (735-750,1410-1425), count_total: 2, num_trees: 2, samples: 225\n",
      "feat_name: (30-45,975-990), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1335-1350,180-195), count_total: 1, num_trees: 1, samples: 25\n",
      "feat_name: (90-105,375-390), count_total: 2, num_trees: 2, samples: 216\n",
      "feat_name: (225-240,1185-1200), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (750-765,90-105), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (120-135,1350-1365), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (360-375,1380-1395), count_total: 2, num_trees: 2, samples: 199\n",
      "feat_name: (600-615,930-945), count_total: 2, num_trees: 2, samples: 213\n",
      "feat_name: (45-60,1050-1065), count_total: 1, num_trees: 1, samples: 144\n",
      "feat_name: (375-390,1305-1320), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (135-150,1140-1155), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (1440-1455,1350-1365), count_total: 2, num_trees: 2, samples: 32\n",
      "feat_name: (1380-1395,1365-1380), count_total: 2, num_trees: 2, samples: 232\n",
      "feat_name: (780-795,1380-1395), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (195-210,675-690), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (75-90,495-510), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (660-675,90-105), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (435-450,315-330), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (1095-1110,270-285), count_total: 3, num_trees: 3, samples: 96\n",
      "feat_name: (90-105,1050-1065), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (1035-1050,270-285), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (960-975,120-135), count_total: 3, num_trees: 3, samples: 201\n",
      "feat_name: (1350-1365,945-960), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (60-75,420-435), count_total: 2, num_trees: 2, samples: 198\n",
      "feat_name: (435-450,1425-1440), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (1440-1455,150-165), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (270-285,75-90), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (15-30,930-945), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (810-825,120-135), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (285-300,105-120), count_total: 2, num_trees: 2, samples: 233\n",
      "feat_name: (150-165,120-135), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (465-480,270-285), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1080-1095,1005-1020), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (15-30,210-225), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1410-1425,1125-1140), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (1410-1425,765-780), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (885-900,330-345), count_total: 1, num_trees: 1, samples: 139\n",
      "feat_name: (90-105,195-210), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (1080-1095,585-600), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (480-495,60-75), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (45-60,750-765), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (285-300,435-450), count_total: 2, num_trees: 2, samples: 231\n",
      "feat_name: (90-105,1245-1260), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (645-660,825-840), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1155-1170,105-120), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1200-1215,1305-1320), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (705-720,120-135), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1215-1230,165-180), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (825-840,1380-1395), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (780-795,90-105), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (330-345,660-675), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (795-810,945-960), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (135-150,465-480), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (30-45,1230-1245), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (390-405,450-465), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (600-615,60-75), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (735-750,795-810), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (180-195,480-495), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (675-690,975-990), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (615-630,765-780), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (1245-1260,390-405), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (810-825,90-105), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (1005-1020,75-90), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (120-135,1410-1425), count_total: 2, num_trees: 2, samples: 181\n",
      "feat_name: (645-660,90-105), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (1350-1365,75-90), count_total: 1, num_trees: 1, samples: 20\n",
      "feat_name: (1050-1065,315-330), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (1260-1275,240-255), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (1080-1095,930-945), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (240-255,1380-1395), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (345-360,150-165), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (690-705,435-450), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (945-960,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (15-30,1380-1395), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (15-30,720-735), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (240-255,60-75), count_total: 1, num_trees: 1, samples: 134\n",
      "feat_name: (1005-1020,270-285), count_total: 1, num_trees: 1, samples: 25\n",
      "feat_name: (60-75,120-135), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (345-360,990-1005), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (885-900,300-315), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (810-825,75-90), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (240-255,975-990), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1215-1230,150-165), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (15-30,840-855), count_total: 2, num_trees: 2, samples: 254\n",
      "feat_name: (435-450,465-480), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (315-330,915-930), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (1245-1260,1410-1425), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (645-660,1275-1290), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (780-795,120-135), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (330-345,60-75), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (780-795,1065-1080), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (105-120,135-150), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1380-1395,105-120), count_total: 2, num_trees: 2, samples: 204\n",
      "feat_name: (75-90,930-945), count_total: 1, num_trees: 1, samples: 135\n",
      "feat_name: (1080-1095,225-240), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (315-330,1380-1395), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (330-345,105-120), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1320-1335,270-285), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1365-1380,960-975), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (375-390,120-135), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (1275-1290,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (180-195,420-435), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (420-435,900-915), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1440-1455,360-375), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (1320-1335,225-240), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (945-960,810-825), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (1380-1395,330-345), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (345-360,300-315), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (225-240,525-540), count_total: 1, num_trees: 1, samples: 136\n",
      "feat_name: (240-255,675-690), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (1440-1455,420-435), count_total: 1, num_trees: 1, samples: 32\n",
      "feat_name: (1440-1455,1275-1290), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1140-1155,105-120), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1485-1500,825-840), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (285-300,420-435), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (0-15,735-750), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (660-675,270-285), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (945-960,75-90), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (180-195,270-285), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (735-750,1005-1020), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (795-810,90-105), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (360-375,60-75), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (1335-1350,750-765), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (405-420,255-270), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (450-465,780-795), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (75-90,735-750), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (60-75,915-930), count_total: 1, num_trees: 1, samples: 121\n",
      "feat_name: (1365-1380,945-960), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (60-75,630-645), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (510-525,600-615), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (870-885,390-405), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1275-1290,135-150), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (15-30,150-165), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (990-1005,1425-1440), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (990-1005,285-300), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (705-720,75-90), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (165-180,1125-1140), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (570-585,375-390), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (90-105,135-150), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (720-735,330-345), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (645-660,60-75), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (135-150,405-420), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1395-1410,120-135), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1425-1440,1170-1185), count_total: 2, num_trees: 2, samples: 105\n",
      "feat_name: (75-90,1215-1230), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (0-15,1140-1155), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (555-570,1065-1080), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (180-195,900-915), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (885-900,1380-1395), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (645-660,810-825), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1170-1185,90-105), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1440-1455,645-660), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1245-1260,330-345), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (75-90,345-360), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1425-1440,1290-1305), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (375-390,165-180), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (840-855,90-105), count_total: 1, num_trees: 1, samples: 136\n",
      "feat_name: (600-615,540-555), count_total: 1, num_trees: 1, samples: 14\n",
      "feat_name: (60-75,1020-1035), count_total: 2, num_trees: 2, samples: 101\n",
      "feat_name: (780-795,705-720), count_total: 1, num_trees: 1, samples: 137\n",
      "feat_name: (690-705,1020-1035), count_total: 1, num_trees: 1, samples: 136\n",
      "feat_name: (195-210,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1305-1320,1365-1380), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (135-150,1275-1290), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (840-855,1380-1395), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (30-45,450-465), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (180-195,705-720), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1065-1080,465-480), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (30-45,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "\n",
      "sorted features:\n",
      "feat_name: (1485-1500,1395-1410), count_total: 257, num_trees: 254, samples: 34786\n",
      "feat_name: (0-15,330-345), count_total: 227, num_trees: 226, samples: 31664\n",
      "feat_name: (1485-1500,1425-1440), count_total: 201, num_trees: 194, samples: 47111\n",
      "feat_name: (1485-1500,135-150), count_total: 180, num_trees: 176, samples: 47417\n",
      "feat_name: (0-15,90-105), count_total: 166, num_trees: 159, samples: 47268\n",
      "feat_name: (0-15,1410-1425), count_total: 164, num_trees: 158, samples: 25343\n",
      "feat_name: (1485-1500,150-165), count_total: 156, num_trees: 138, samples: 26882\n",
      "feat_name: (0-15,75-90), count_total: 148, num_trees: 134, samples: 38050\n",
      "feat_name: (1425-1440,1410-1425), count_total: 86, num_trees: 85, samples: 22473\n",
      "feat_name: (1410-1425,1410-1425), count_total: 86, num_trees: 85, samples: 20366\n",
      "feat_name: (1440-1455,90-105), count_total: 66, num_trees: 66, samples: 10332\n",
      "feat_name: (0-15,60-75), count_total: 70, num_trees: 64, samples: 7417\n",
      "feat_name: (0-15,390-405), count_total: 45, num_trees: 45, samples: 5295\n",
      "feat_name: (1470-1485,1410-1425), count_total: 42, num_trees: 42, samples: 6879\n",
      "feat_name: (105-120,60-75), count_total: 42, num_trees: 42, samples: 4562\n",
      "feat_name: (1350-1365,1410-1425), count_total: 38, num_trees: 38, samples: 9238\n",
      "feat_name: (1485-1500,105-120), count_total: 37, num_trees: 37, samples: 2943\n",
      "feat_name: (1470-1485,1380-1395), count_total: 34, num_trees: 34, samples: 4178\n",
      "feat_name: (1320-1335,1425-1440), count_total: 33, num_trees: 33, samples: 5129\n",
      "feat_name: (1440-1455,1410-1425), count_total: 30, num_trees: 30, samples: 5008\n",
      "feat_name: (1050-1065,60-75), count_total: 30, num_trees: 30, samples: 3658\n",
      "feat_name: (90-105,60-75), count_total: 31, num_trees: 30, samples: 3025\n",
      "feat_name: (1455-1470,1410-1425), count_total: 29, num_trees: 29, samples: 4704\n",
      "feat_name: (1440-1455,1425-1440), count_total: 29, num_trees: 29, samples: 4187\n",
      "feat_name: (0-15,585-600), count_total: 27, num_trees: 27, samples: 3180\n",
      "feat_name: (1485-1500,75-90), count_total: 27, num_trees: 27, samples: 2161\n",
      "feat_name: (1395-1410,1425-1440), count_total: 26, num_trees: 26, samples: 4043\n",
      "feat_name: (1350-1365,1425-1440), count_total: 26, num_trees: 26, samples: 3430\n",
      "feat_name: (1455-1470,1425-1440), count_total: 25, num_trees: 25, samples: 3785\n",
      "feat_name: (1350-1365,90-105), count_total: 25, num_trees: 25, samples: 2818\n",
      "feat_name: (1410-1425,1425-1440), count_total: 24, num_trees: 24, samples: 3621\n",
      "feat_name: (1485-1500,1440-1455), count_total: 24, num_trees: 24, samples: 3334\n",
      "feat_name: (0-15,345-360), count_total: 25, num_trees: 24, samples: 2490\n",
      "feat_name: (1485-1500,90-105), count_total: 24, num_trees: 24, samples: 1920\n",
      "feat_name: (1410-1425,105-120), count_total: 22, num_trees: 22, samples: 3417\n",
      "feat_name: (1470-1485,1425-1440), count_total: 22, num_trees: 22, samples: 3179\n",
      "feat_name: (0-15,1380-1395), count_total: 23, num_trees: 22, samples: 2605\n",
      "feat_name: (1470-1485,90-105), count_total: 22, num_trees: 22, samples: 2284\n",
      "feat_name: (1425-1440,1425-1440), count_total: 21, num_trees: 21, samples: 3170\n",
      "feat_name: (1365-1380,1410-1425), count_total: 20, num_trees: 20, samples: 5491\n",
      "feat_name: (1380-1395,1425-1440), count_total: 20, num_trees: 20, samples: 2761\n",
      "feat_name: (1335-1350,1425-1440), count_total: 19, num_trees: 19, samples: 2932\n",
      "feat_name: (1365-1380,1425-1440), count_total: 19, num_trees: 19, samples: 2864\n",
      "feat_name: (1425-1440,90-105), count_total: 19, num_trees: 19, samples: 1991\n",
      "feat_name: (1485-1500,915-930), count_total: 18, num_trees: 18, samples: 1831\n",
      "feat_name: (1455-1470,60-75), count_total: 18, num_trees: 18, samples: 1517\n",
      "feat_name: (1335-1350,1410-1425), count_total: 17, num_trees: 17, samples: 3955\n",
      "feat_name: (1365-1380,105-120), count_total: 17, num_trees: 17, samples: 1604\n",
      "feat_name: (90-105,1410-1425), count_total: 17, num_trees: 17, samples: 1477\n",
      "feat_name: (855-870,60-75), count_total: 16, num_trees: 16, samples: 2113\n",
      "feat_name: (0-15,210-225), count_total: 16, num_trees: 16, samples: 1749\n",
      "feat_name: (1110-1125,60-75), count_total: 16, num_trees: 16, samples: 1745\n",
      "feat_name: (1485-1500,945-960), count_total: 15, num_trees: 15, samples: 2886\n",
      "feat_name: (1290-1305,60-75), count_total: 15, num_trees: 15, samples: 1357\n",
      "feat_name: (0-15,1290-1305), count_total: 15, num_trees: 15, samples: 1279\n",
      "feat_name: (1440-1455,60-75), count_total: 15, num_trees: 15, samples: 1258\n",
      "feat_name: (15-30,75-90), count_total: 15, num_trees: 15, samples: 1115\n",
      "feat_name: (1485-1500,435-450), count_total: 14, num_trees: 14, samples: 1166\n",
      "feat_name: (1155-1170,1425-1440), count_total: 13, num_trees: 13, samples: 1759\n",
      "feat_name: (0-15,105-120), count_total: 13, num_trees: 13, samples: 1614\n",
      "feat_name: (1170-1185,60-75), count_total: 13, num_trees: 13, samples: 1405\n",
      "feat_name: (1110-1125,1410-1425), count_total: 13, num_trees: 13, samples: 1359\n",
      "feat_name: (105-120,1410-1425), count_total: 13, num_trees: 13, samples: 1322\n",
      "feat_name: (75-90,1410-1425), count_total: 13, num_trees: 13, samples: 1085\n",
      "feat_name: (1215-1230,60-75), count_total: 13, num_trees: 13, samples: 922\n",
      "feat_name: (1395-1410,105-120), count_total: 12, num_trees: 12, samples: 1364\n",
      "feat_name: (1080-1095,60-75), count_total: 12, num_trees: 12, samples: 1303\n",
      "feat_name: (1395-1410,135-150), count_total: 12, num_trees: 12, samples: 955\n",
      "feat_name: (120-135,105-120), count_total: 13, num_trees: 12, samples: 921\n",
      "feat_name: (1260-1275,90-105), count_total: 12, num_trees: 12, samples: 788\n",
      "feat_name: (1440-1455,1380-1395), count_total: 12, num_trees: 12, samples: 724\n",
      "feat_name: (1485-1500,1305-1320), count_total: 11, num_trees: 11, samples: 1370\n",
      "feat_name: (1470-1485,1290-1305), count_total: 11, num_trees: 11, samples: 1299\n",
      "feat_name: (1095-1110,60-75), count_total: 11, num_trees: 11, samples: 1193\n",
      "feat_name: (1185-1200,60-75), count_total: 11, num_trees: 11, samples: 1156\n",
      "feat_name: (1410-1425,120-135), count_total: 11, num_trees: 11, samples: 972\n",
      "feat_name: (1470-1485,60-75), count_total: 11, num_trees: 11, samples: 906\n",
      "feat_name: (360-375,75-90), count_total: 11, num_trees: 11, samples: 889\n",
      "feat_name: (1395-1410,1410-1425), count_total: 10, num_trees: 10, samples: 2239\n",
      "feat_name: (1050-1065,105-120), count_total: 10, num_trees: 10, samples: 1089\n",
      "feat_name: (0-15,720-735), count_total: 10, num_trees: 10, samples: 1016\n",
      "feat_name: (1365-1380,135-150), count_total: 10, num_trees: 10, samples: 935\n",
      "feat_name: (1050-1065,90-105), count_total: 10, num_trees: 10, samples: 786\n",
      "feat_name: (1485-1500,300-315), count_total: 10, num_trees: 10, samples: 784\n",
      "feat_name: (1230-1245,90-105), count_total: 10, num_trees: 10, samples: 685\n",
      "feat_name: (15-30,90-105), count_total: 10, num_trees: 10, samples: 231\n",
      "feat_name: (1305-1320,1425-1440), count_total: 9, num_trees: 9, samples: 1167\n",
      "feat_name: (1140-1155,1425-1440), count_total: 9, num_trees: 9, samples: 1067\n",
      "feat_name: (1290-1305,1425-1440), count_total: 9, num_trees: 9, samples: 1021\n",
      "feat_name: (990-1005,1410-1425), count_total: 9, num_trees: 9, samples: 1019\n",
      "feat_name: (90-105,900-915), count_total: 9, num_trees: 9, samples: 983\n",
      "feat_name: (1410-1425,1380-1395), count_total: 9, num_trees: 9, samples: 975\n",
      "feat_name: (1110-1125,1425-1440), count_total: 9, num_trees: 9, samples: 853\n",
      "feat_name: (1320-1335,60-75), count_total: 10, num_trees: 9, samples: 833\n",
      "feat_name: (60-75,1410-1425), count_total: 9, num_trees: 9, samples: 830\n",
      "feat_name: (1230-1245,105-120), count_total: 9, num_trees: 9, samples: 712\n",
      "feat_name: (135-150,1290-1305), count_total: 8, num_trees: 8, samples: 1018\n",
      "feat_name: (1095-1110,1410-1425), count_total: 8, num_trees: 8, samples: 936\n",
      "feat_name: (1125-1140,1380-1395), count_total: 8, num_trees: 8, samples: 905\n",
      "feat_name: (1110-1125,105-120), count_total: 8, num_trees: 8, samples: 742\n",
      "feat_name: (675-690,90-105), count_total: 8, num_trees: 8, samples: 714\n",
      "feat_name: (45-60,1410-1425), count_total: 8, num_trees: 8, samples: 641\n",
      "feat_name: (1080-1095,1425-1440), count_total: 8, num_trees: 8, samples: 637\n",
      "feat_name: (1245-1260,90-105), count_total: 8, num_trees: 8, samples: 604\n",
      "feat_name: (375-390,90-105), count_total: 9, num_trees: 8, samples: 600\n",
      "feat_name: (1020-1035,60-75), count_total: 8, num_trees: 8, samples: 594\n",
      "feat_name: (1305-1320,1380-1395), count_total: 8, num_trees: 8, samples: 569\n",
      "feat_name: (1350-1365,1380-1395), count_total: 8, num_trees: 8, samples: 521\n",
      "feat_name: (1185-1200,1380-1395), count_total: 8, num_trees: 8, samples: 330\n",
      "feat_name: (1050-1065,1380-1395), count_total: 8, num_trees: 8, samples: 313\n",
      "feat_name: (1320-1335,75-90), count_total: 8, num_trees: 8, samples: 86\n",
      "feat_name: (1485-1500,120-135), count_total: 8, num_trees: 8, samples: 57\n",
      "feat_name: (1170-1185,1425-1440), count_total: 7, num_trees: 7, samples: 973\n",
      "feat_name: (30-45,210-225), count_total: 7, num_trees: 7, samples: 925\n",
      "feat_name: (225-240,1290-1305), count_total: 7, num_trees: 7, samples: 912\n",
      "feat_name: (1440-1455,105-120), count_total: 7, num_trees: 7, samples: 848\n",
      "feat_name: (1305-1320,60-75), count_total: 7, num_trees: 7, samples: 831\n",
      "feat_name: (840-855,60-75), count_total: 7, num_trees: 7, samples: 810\n",
      "feat_name: (1200-1215,1425-1440), count_total: 7, num_trees: 7, samples: 757\n",
      "feat_name: (90-105,1380-1395), count_total: 7, num_trees: 7, samples: 733\n",
      "feat_name: (180-195,1290-1305), count_total: 7, num_trees: 7, samples: 700\n",
      "feat_name: (1110-1125,1380-1395), count_total: 7, num_trees: 7, samples: 700\n",
      "feat_name: (1455-1470,1290-1305), count_total: 7, num_trees: 7, samples: 661\n",
      "feat_name: (1230-1245,60-75), count_total: 7, num_trees: 7, samples: 636\n",
      "feat_name: (975-990,90-105), count_total: 7, num_trees: 7, samples: 635\n",
      "feat_name: (45-60,120-135), count_total: 7, num_trees: 7, samples: 635\n",
      "feat_name: (1440-1455,435-450), count_total: 7, num_trees: 7, samples: 627\n",
      "feat_name: (630-645,255-270), count_total: 7, num_trees: 7, samples: 550\n",
      "feat_name: (1425-1440,105-120), count_total: 7, num_trees: 7, samples: 522\n",
      "feat_name: (585-600,1410-1425), count_total: 7, num_trees: 7, samples: 453\n",
      "feat_name: (0-15,270-285), count_total: 7, num_trees: 7, samples: 422\n",
      "feat_name: (1275-1290,60-75), count_total: 7, num_trees: 7, samples: 384\n",
      "feat_name: (600-615,75-90), count_total: 7, num_trees: 7, samples: 359\n",
      "feat_name: (1425-1440,75-90), count_total: 7, num_trees: 7, samples: 248\n",
      "feat_name: (1380-1395,75-90), count_total: 7, num_trees: 7, samples: 59\n",
      "feat_name: (1410-1425,90-105), count_total: 7, num_trees: 7, samples: 53\n",
      "feat_name: (975-990,60-75), count_total: 6, num_trees: 6, samples: 969\n",
      "feat_name: (1125-1140,1410-1425), count_total: 6, num_trees: 6, samples: 888\n",
      "feat_name: (1005-1020,1410-1425), count_total: 6, num_trees: 6, samples: 772\n",
      "feat_name: (1335-1350,60-75), count_total: 6, num_trees: 6, samples: 768\n",
      "feat_name: (225-240,60-75), count_total: 6, num_trees: 6, samples: 727\n",
      "feat_name: (1395-1410,60-75), count_total: 6, num_trees: 6, samples: 700\n",
      "feat_name: (1380-1395,1410-1425), count_total: 6, num_trees: 6, samples: 699\n",
      "feat_name: (210-225,1290-1305), count_total: 6, num_trees: 6, samples: 633\n",
      "feat_name: (30-45,105-120), count_total: 6, num_trees: 6, samples: 611\n",
      "feat_name: (1470-1485,525-540), count_total: 6, num_trees: 6, samples: 609\n",
      "feat_name: (1035-1050,60-75), count_total: 6, num_trees: 6, samples: 601\n",
      "feat_name: (1080-1095,1380-1395), count_total: 6, num_trees: 6, samples: 582\n",
      "feat_name: (1470-1485,270-285), count_total: 6, num_trees: 6, samples: 569\n",
      "feat_name: (1410-1425,60-75), count_total: 6, num_trees: 6, samples: 555\n",
      "feat_name: (105-120,930-945), count_total: 6, num_trees: 6, samples: 547\n",
      "feat_name: (360-375,1125-1140), count_total: 6, num_trees: 6, samples: 542\n",
      "feat_name: (405-420,435-450), count_total: 6, num_trees: 6, samples: 538\n",
      "feat_name: (1455-1470,1380-1395), count_total: 6, num_trees: 6, samples: 517\n",
      "feat_name: (405-420,240-255), count_total: 6, num_trees: 6, samples: 491\n",
      "feat_name: (1200-1215,390-405), count_total: 6, num_trees: 6, samples: 475\n",
      "feat_name: (1350-1365,105-120), count_total: 6, num_trees: 6, samples: 472\n",
      "feat_name: (1170-1185,1380-1395), count_total: 6, num_trees: 6, samples: 457\n",
      "feat_name: (1335-1350,90-105), count_total: 6, num_trees: 6, samples: 446\n",
      "feat_name: (120-135,60-75), count_total: 6, num_trees: 6, samples: 407\n",
      "feat_name: (1260-1275,60-75), count_total: 6, num_trees: 6, samples: 336\n",
      "feat_name: (1350-1365,120-135), count_total: 6, num_trees: 6, samples: 311\n",
      "feat_name: (1080-1095,105-120), count_total: 6, num_trees: 6, samples: 286\n",
      "feat_name: (360-375,135-150), count_total: 6, num_trees: 6, samples: 267\n",
      "feat_name: (390-405,90-105), count_total: 6, num_trees: 6, samples: 202\n",
      "feat_name: (1215-1230,75-90), count_total: 6, num_trees: 6, samples: 136\n",
      "feat_name: (1065-1080,75-90), count_total: 6, num_trees: 6, samples: 51\n",
      "feat_name: (1050-1065,1425-1440), count_total: 5, num_trees: 5, samples: 683\n",
      "feat_name: (1095-1110,1380-1395), count_total: 5, num_trees: 5, samples: 676\n",
      "feat_name: (195-210,1290-1305), count_total: 5, num_trees: 5, samples: 661\n",
      "feat_name: (1140-1155,1410-1425), count_total: 5, num_trees: 5, samples: 637\n",
      "feat_name: (105-120,900-915), count_total: 5, num_trees: 5, samples: 594\n",
      "feat_name: (1440-1455,270-285), count_total: 5, num_trees: 5, samples: 524\n",
      "feat_name: (1035-1050,90-105), count_total: 5, num_trees: 5, samples: 518\n",
      "feat_name: (90-105,120-135), count_total: 5, num_trees: 5, samples: 500\n",
      "feat_name: (1320-1335,90-105), count_total: 5, num_trees: 5, samples: 491\n",
      "feat_name: (1485-1500,165-180), count_total: 5, num_trees: 5, samples: 488\n",
      "feat_name: (75-90,900-915), count_total: 5, num_trees: 5, samples: 478\n",
      "feat_name: (585-600,960-975), count_total: 5, num_trees: 5, samples: 471\n",
      "feat_name: (705-720,90-105), count_total: 5, num_trees: 5, samples: 471\n",
      "feat_name: (1425-1440,120-135), count_total: 5, num_trees: 5, samples: 467\n",
      "feat_name: (615-630,120-135), count_total: 5, num_trees: 5, samples: 458\n",
      "feat_name: (1410-1425,135-150), count_total: 5, num_trees: 5, samples: 452\n",
      "feat_name: (1290-1305,1380-1395), count_total: 5, num_trees: 5, samples: 452\n",
      "feat_name: (1035-1050,150-165), count_total: 5, num_trees: 5, samples: 440\n",
      "feat_name: (405-420,135-150), count_total: 5, num_trees: 5, samples: 433\n",
      "feat_name: (1485-1500,480-495), count_total: 5, num_trees: 5, samples: 429\n",
      "feat_name: (165-180,135-150), count_total: 5, num_trees: 5, samples: 426\n",
      "feat_name: (105-120,1380-1395), count_total: 5, num_trees: 5, samples: 416\n",
      "feat_name: (555-570,60-75), count_total: 5, num_trees: 5, samples: 416\n",
      "feat_name: (270-285,1290-1305), count_total: 5, num_trees: 5, samples: 408\n",
      "feat_name: (630-645,435-450), count_total: 5, num_trees: 5, samples: 388\n",
      "feat_name: (90-105,105-120), count_total: 5, num_trees: 5, samples: 373\n",
      "feat_name: (1230-1245,270-285), count_total: 5, num_trees: 5, samples: 353\n",
      "feat_name: (1470-1485,900-915), count_total: 5, num_trees: 5, samples: 303\n",
      "feat_name: (1470-1485,105-120), count_total: 5, num_trees: 5, samples: 271\n",
      "feat_name: (525-540,1410-1425), count_total: 5, num_trees: 5, samples: 246\n",
      "feat_name: (1335-1350,75-90), count_total: 5, num_trees: 5, samples: 51\n",
      "feat_name: (1050-1065,75-90), count_total: 5, num_trees: 5, samples: 47\n",
      "feat_name: (1065-1080,90-105), count_total: 5, num_trees: 5, samples: 38\n",
      "feat_name: (45-60,90-105), count_total: 5, num_trees: 5, samples: 29\n",
      "feat_name: (105-120,90-105), count_total: 5, num_trees: 5, samples: 14\n",
      "feat_name: (1290-1305,1410-1425), count_total: 4, num_trees: 4, samples: 814\n",
      "feat_name: (1080-1095,1410-1425), count_total: 4, num_trees: 4, samples: 609\n",
      "feat_name: (1140-1155,1380-1395), count_total: 4, num_trees: 4, samples: 543\n",
      "feat_name: (90-105,915-930), count_total: 4, num_trees: 4, samples: 516\n",
      "feat_name: (135-150,60-75), count_total: 4, num_trees: 4, samples: 513\n",
      "feat_name: (1185-1200,1260-1275), count_total: 4, num_trees: 4, samples: 503\n",
      "feat_name: (600-615,1410-1425), count_total: 4, num_trees: 4, samples: 496\n",
      "feat_name: (1395-1410,585-600), count_total: 4, num_trees: 4, samples: 484\n",
      "feat_name: (105-120,945-960), count_total: 4, num_trees: 4, samples: 483\n",
      "feat_name: (1020-1035,1410-1425), count_total: 4, num_trees: 4, samples: 466\n",
      "feat_name: (30-45,60-75), count_total: 4, num_trees: 4, samples: 465\n",
      "feat_name: (75-90,1380-1395), count_total: 4, num_trees: 4, samples: 431\n",
      "feat_name: (1485-1500,630-645), count_total: 4, num_trees: 4, samples: 431\n",
      "feat_name: (1140-1155,60-75), count_total: 4, num_trees: 4, samples: 425\n",
      "feat_name: (1470-1485,435-450), count_total: 4, num_trees: 4, samples: 419\n",
      "feat_name: (45-60,900-915), count_total: 4, num_trees: 4, samples: 417\n",
      "feat_name: (1485-1500,735-750), count_total: 4, num_trees: 4, samples: 417\n",
      "feat_name: (1050-1065,270-285), count_total: 4, num_trees: 4, samples: 408\n",
      "feat_name: (420-435,75-90), count_total: 4, num_trees: 4, samples: 408\n",
      "feat_name: (1395-1410,240-255), count_total: 4, num_trees: 4, samples: 400\n",
      "feat_name: (1485-1500,930-945), count_total: 4, num_trees: 4, samples: 399\n",
      "feat_name: (960-975,1410-1425), count_total: 4, num_trees: 4, samples: 398\n",
      "feat_name: (165-180,1290-1305), count_total: 4, num_trees: 4, samples: 391\n",
      "feat_name: (1200-1215,105-120), count_total: 4, num_trees: 4, samples: 388\n",
      "feat_name: (60-75,1380-1395), count_total: 4, num_trees: 4, samples: 376\n",
      "feat_name: (1485-1500,1185-1200), count_total: 4, num_trees: 4, samples: 373\n",
      "feat_name: (375-390,1410-1425), count_total: 4, num_trees: 4, samples: 373\n",
      "feat_name: (90-105,930-945), count_total: 4, num_trees: 4, samples: 366\n",
      "feat_name: (45-60,105-120), count_total: 4, num_trees: 4, samples: 365\n",
      "feat_name: (675-690,135-150), count_total: 4, num_trees: 4, samples: 365\n",
      "feat_name: (885-900,1410-1425), count_total: 4, num_trees: 4, samples: 347\n",
      "feat_name: (150-165,1410-1425), count_total: 4, num_trees: 4, samples: 336\n",
      "feat_name: (1035-1050,1410-1425), count_total: 4, num_trees: 4, samples: 333\n",
      "feat_name: (1470-1485,510-525), count_total: 4, num_trees: 4, samples: 327\n",
      "feat_name: (120-135,1290-1305), count_total: 4, num_trees: 4, samples: 289\n",
      "feat_name: (1290-1305,105-120), count_total: 4, num_trees: 4, samples: 285\n",
      "feat_name: (375-390,75-90), count_total: 4, num_trees: 4, samples: 277\n",
      "feat_name: (1380-1395,60-75), count_total: 4, num_trees: 4, samples: 270\n",
      "feat_name: (1440-1455,120-135), count_total: 4, num_trees: 4, samples: 232\n",
      "feat_name: (30-45,1380-1395), count_total: 4, num_trees: 4, samples: 221\n",
      "feat_name: (30-45,1410-1425), count_total: 4, num_trees: 4, samples: 220\n",
      "feat_name: (1365-1380,60-75), count_total: 4, num_trees: 4, samples: 219\n",
      "feat_name: (15-30,225-240), count_total: 4, num_trees: 4, samples: 202\n",
      "feat_name: (555-570,1410-1425), count_total: 4, num_trees: 4, samples: 201\n",
      "feat_name: (555-570,120-135), count_total: 4, num_trees: 4, samples: 195\n",
      "feat_name: (510-525,105-120), count_total: 4, num_trees: 4, samples: 194\n",
      "feat_name: (1020-1035,1425-1440), count_total: 4, num_trees: 4, samples: 168\n",
      "feat_name: (75-90,60-75), count_total: 4, num_trees: 4, samples: 162\n",
      "feat_name: (1425-1440,1380-1395), count_total: 4, num_trees: 4, samples: 152\n",
      "feat_name: (1305-1320,75-90), count_total: 4, num_trees: 4, samples: 132\n",
      "feat_name: (1275-1290,75-90), count_total: 4, num_trees: 4, samples: 129\n",
      "feat_name: (1395-1410,75-90), count_total: 4, num_trees: 4, samples: 125\n",
      "feat_name: (1455-1470,75-90), count_total: 4, num_trees: 4, samples: 123\n",
      "feat_name: (1155-1170,1380-1395), count_total: 4, num_trees: 4, samples: 117\n",
      "feat_name: (1485-1500,270-285), count_total: 4, num_trees: 4, samples: 117\n",
      "feat_name: (1200-1215,90-105), count_total: 4, num_trees: 4, samples: 114\n",
      "feat_name: (1200-1215,75-90), count_total: 4, num_trees: 4, samples: 111\n",
      "feat_name: (1290-1305,90-105), count_total: 4, num_trees: 4, samples: 102\n",
      "feat_name: (1230-1245,1380-1395), count_total: 4, num_trees: 4, samples: 46\n",
      "feat_name: (45-60,60-75), count_total: 4, num_trees: 4, samples: 44\n",
      "feat_name: (1470-1485,75-90), count_total: 4, num_trees: 4, samples: 39\n",
      "feat_name: (1200-1215,1380-1395), count_total: 4, num_trees: 4, samples: 33\n",
      "feat_name: (1095-1110,1425-1440), count_total: 3, num_trees: 3, samples: 487\n",
      "feat_name: (1275-1290,105-120), count_total: 3, num_trees: 3, samples: 467\n",
      "feat_name: (1185-1200,240-255), count_total: 3, num_trees: 3, samples: 405\n",
      "feat_name: (30-45,480-495), count_total: 3, num_trees: 3, samples: 398\n",
      "feat_name: (1020-1035,420-435), count_total: 3, num_trees: 3, samples: 395\n",
      "feat_name: (195-210,900-915), count_total: 3, num_trees: 3, samples: 388\n",
      "feat_name: (1470-1485,1065-1080), count_total: 3, num_trees: 3, samples: 385\n",
      "feat_name: (0-15,960-975), count_total: 3, num_trees: 3, samples: 376\n",
      "feat_name: (90-105,1290-1305), count_total: 3, num_trees: 3, samples: 373\n",
      "feat_name: (795-810,150-165), count_total: 3, num_trees: 3, samples: 368\n",
      "feat_name: (1380-1395,1380-1395), count_total: 3, num_trees: 3, samples: 366\n",
      "feat_name: (975-990,1410-1425), count_total: 3, num_trees: 3, samples: 356\n",
      "feat_name: (375-390,105-120), count_total: 3, num_trees: 3, samples: 345\n",
      "feat_name: (585-600,1380-1395), count_total: 3, num_trees: 3, samples: 342\n",
      "feat_name: (1455-1470,105-120), count_total: 3, num_trees: 3, samples: 341\n",
      "feat_name: (225-240,1050-1065), count_total: 3, num_trees: 3, samples: 331\n",
      "feat_name: (1020-1035,585-600), count_total: 3, num_trees: 3, samples: 330\n",
      "feat_name: (150-165,900-915), count_total: 3, num_trees: 3, samples: 322\n",
      "feat_name: (285-300,1020-1035), count_total: 3, num_trees: 3, samples: 321\n",
      "feat_name: (75-90,120-135), count_total: 3, num_trees: 3, samples: 321\n",
      "feat_name: (135-150,120-135), count_total: 3, num_trees: 3, samples: 318\n",
      "feat_name: (540-555,105-120), count_total: 3, num_trees: 3, samples: 309\n",
      "feat_name: (495-510,105-120), count_total: 3, num_trees: 3, samples: 306\n",
      "feat_name: (1365-1380,270-285), count_total: 3, num_trees: 3, samples: 306\n",
      "feat_name: (180-195,1410-1425), count_total: 3, num_trees: 3, samples: 303\n",
      "feat_name: (1305-1320,360-375), count_total: 3, num_trees: 3, samples: 294\n",
      "feat_name: (1035-1050,1425-1440), count_total: 3, num_trees: 3, samples: 293\n",
      "feat_name: (75-90,1290-1305), count_total: 3, num_trees: 3, samples: 292\n",
      "feat_name: (1485-1500,1350-1365), count_total: 3, num_trees: 3, samples: 290\n",
      "feat_name: (1470-1485,225-240), count_total: 3, num_trees: 3, samples: 289\n",
      "feat_name: (1305-1320,90-105), count_total: 3, num_trees: 3, samples: 288\n",
      "feat_name: (240-255,135-150), count_total: 3, num_trees: 3, samples: 286\n",
      "feat_name: (1425-1440,135-150), count_total: 3, num_trees: 3, samples: 285\n",
      "feat_name: (1125-1140,60-75), count_total: 3, num_trees: 3, samples: 283\n",
      "feat_name: (1350-1365,60-75), count_total: 3, num_trees: 3, samples: 279\n",
      "feat_name: (1335-1350,1380-1395), count_total: 3, num_trees: 3, samples: 278\n",
      "feat_name: (1485-1500,225-240), count_total: 3, num_trees: 3, samples: 278\n",
      "feat_name: (1320-1335,105-120), count_total: 3, num_trees: 3, samples: 278\n",
      "feat_name: (1455-1470,225-240), count_total: 3, num_trees: 3, samples: 272\n",
      "feat_name: (1260-1275,270-285), count_total: 3, num_trees: 3, samples: 272\n",
      "feat_name: (630-645,135-150), count_total: 3, num_trees: 3, samples: 269\n",
      "feat_name: (975-990,150-165), count_total: 3, num_trees: 3, samples: 266\n",
      "feat_name: (975-990,135-150), count_total: 3, num_trees: 3, samples: 264\n",
      "feat_name: (1125-1140,90-105), count_total: 3, num_trees: 3, samples: 257\n",
      "feat_name: (165-180,1380-1395), count_total: 3, num_trees: 3, samples: 256\n",
      "feat_name: (765-780,1410-1425), count_total: 3, num_trees: 3, samples: 254\n",
      "feat_name: (1320-1335,1380-1395), count_total: 3, num_trees: 3, samples: 254\n",
      "feat_name: (1440-1455,945-960), count_total: 3, num_trees: 3, samples: 254\n",
      "feat_name: (1365-1380,1380-1395), count_total: 3, num_trees: 3, samples: 254\n",
      "feat_name: (360-375,165-180), count_total: 3, num_trees: 3, samples: 252\n",
      "feat_name: (1380-1395,255-270), count_total: 3, num_trees: 3, samples: 248\n",
      "feat_name: (135-150,915-930), count_total: 3, num_trees: 3, samples: 240\n",
      "feat_name: (1485-1500,180-195), count_total: 3, num_trees: 3, samples: 238\n",
      "feat_name: (405-420,150-165), count_total: 3, num_trees: 3, samples: 236\n",
      "feat_name: (795-810,300-315), count_total: 3, num_trees: 3, samples: 230\n",
      "feat_name: (420-435,60-75), count_total: 3, num_trees: 3, samples: 227\n",
      "feat_name: (1215-1230,1425-1440), count_total: 3, num_trees: 3, samples: 227\n",
      "feat_name: (135-150,105-120), count_total: 3, num_trees: 3, samples: 223\n",
      "feat_name: (1275-1290,1410-1425), count_total: 3, num_trees: 3, samples: 219\n",
      "feat_name: (1485-1500,375-390), count_total: 3, num_trees: 3, samples: 218\n",
      "feat_name: (960-975,60-75), count_total: 3, num_trees: 3, samples: 214\n",
      "feat_name: (120-135,135-150), count_total: 3, num_trees: 3, samples: 213\n",
      "feat_name: (165-180,120-135), count_total: 3, num_trees: 3, samples: 209\n",
      "feat_name: (915-930,75-90), count_total: 3, num_trees: 3, samples: 205\n",
      "feat_name: (1005-1020,1425-1440), count_total: 3, num_trees: 3, samples: 205\n",
      "feat_name: (1485-1500,285-300), count_total: 3, num_trees: 3, samples: 204\n",
      "feat_name: (960-975,120-135), count_total: 3, num_trees: 3, samples: 201\n",
      "feat_name: (420-435,105-120), count_total: 3, num_trees: 3, samples: 199\n",
      "feat_name: (75-90,105-120), count_total: 3, num_trees: 3, samples: 194\n",
      "feat_name: (690-705,90-105), count_total: 3, num_trees: 3, samples: 189\n",
      "feat_name: (1485-1500,405-420), count_total: 3, num_trees: 3, samples: 188\n",
      "feat_name: (750-765,60-75), count_total: 3, num_trees: 3, samples: 178\n",
      "feat_name: (1485-1500,585-600), count_total: 3, num_trees: 3, samples: 177\n",
      "feat_name: (345-360,75-90), count_total: 3, num_trees: 3, samples: 174\n",
      "feat_name: (390-405,75-90), count_total: 3, num_trees: 3, samples: 173\n",
      "feat_name: (1245-1260,300-315), count_total: 3, num_trees: 3, samples: 173\n",
      "feat_name: (285-300,90-105), count_total: 3, num_trees: 3, samples: 164\n",
      "feat_name: (90-105,885-900), count_total: 3, num_trees: 3, samples: 162\n",
      "feat_name: (435-450,60-75), count_total: 3, num_trees: 3, samples: 162\n",
      "feat_name: (1245-1260,1380-1395), count_total: 3, num_trees: 3, samples: 158\n",
      "feat_name: (360-375,180-195), count_total: 3, num_trees: 3, samples: 155\n",
      "feat_name: (1065-1080,1380-1395), count_total: 3, num_trees: 3, samples: 154\n",
      "feat_name: (1245-1260,60-75), count_total: 3, num_trees: 3, samples: 153\n",
      "feat_name: (1200-1215,60-75), count_total: 3, num_trees: 3, samples: 146\n",
      "feat_name: (390-405,1290-1305), count_total: 3, num_trees: 3, samples: 144\n",
      "feat_name: (1215-1230,270-285), count_total: 3, num_trees: 3, samples: 141\n",
      "feat_name: (915-930,1410-1425), count_total: 3, num_trees: 3, samples: 137\n",
      "feat_name: (615-630,1410-1425), count_total: 3, num_trees: 3, samples: 135\n",
      "feat_name: (225-240,90-105), count_total: 3, num_trees: 3, samples: 131\n",
      "feat_name: (1455-1470,90-105), count_total: 3, num_trees: 3, samples: 131\n",
      "feat_name: (1425-1440,60-75), count_total: 3, num_trees: 3, samples: 130\n",
      "feat_name: (1095-1110,90-105), count_total: 3, num_trees: 3, samples: 123\n",
      "feat_name: (585-600,75-90), count_total: 3, num_trees: 3, samples: 122\n",
      "feat_name: (1440-1455,75-90), count_total: 3, num_trees: 3, samples: 119\n",
      "feat_name: (150-165,90-105), count_total: 3, num_trees: 3, samples: 111\n",
      "feat_name: (75-90,90-105), count_total: 3, num_trees: 3, samples: 110\n",
      "feat_name: (960-975,90-105), count_total: 3, num_trees: 3, samples: 110\n",
      "feat_name: (1020-1035,75-90), count_total: 3, num_trees: 3, samples: 110\n",
      "feat_name: (1275-1290,90-105), count_total: 3, num_trees: 3, samples: 109\n",
      "feat_name: (1215-1230,90-105), count_total: 3, num_trees: 3, samples: 109\n",
      "feat_name: (0-15,135-150), count_total: 3, num_trees: 3, samples: 107\n",
      "feat_name: (1095-1110,270-285), count_total: 3, num_trees: 3, samples: 96\n",
      "feat_name: (585-600,90-105), count_total: 3, num_trees: 3, samples: 95\n",
      "feat_name: (930-945,90-105), count_total: 3, num_trees: 3, samples: 91\n",
      "feat_name: (1185-1200,105-120), count_total: 3, num_trees: 3, samples: 87\n",
      "feat_name: (1365-1380,75-90), count_total: 3, num_trees: 3, samples: 39\n",
      "feat_name: (1380-1395,90-105), count_total: 3, num_trees: 3, samples: 38\n",
      "feat_name: (1260-1275,75-90), count_total: 3, num_trees: 3, samples: 38\n",
      "feat_name: (1260-1275,1410-1425), count_total: 3, num_trees: 3, samples: 34\n",
      "feat_name: (1245-1260,75-90), count_total: 3, num_trees: 3, samples: 29\n",
      "feat_name: (1410-1425,75-90), count_total: 3, num_trees: 3, samples: 24\n",
      "feat_name: (1155-1170,75-90), count_total: 3, num_trees: 3, samples: 21\n",
      "feat_name: (1230-1245,75-90), count_total: 3, num_trees: 3, samples: 21\n",
      "feat_name: (1170-1185,75-90), count_total: 3, num_trees: 3, samples: 20\n",
      "feat_name: (150-165,60-75), count_total: 3, num_trees: 3, samples: 19\n",
      "feat_name: (1185-1200,1410-1425), count_total: 3, num_trees: 3, samples: 19\n",
      "feat_name: (1080-1095,75-90), count_total: 3, num_trees: 3, samples: 16\n",
      "feat_name: (870-885,75-90), count_total: 3, num_trees: 3, samples: 16\n",
      "feat_name: (1035-1050,75-90), count_total: 3, num_trees: 3, samples: 14\n",
      "feat_name: (825-840,105-120), count_total: 3, num_trees: 3, samples: 12\n",
      "feat_name: (90-105,1125-1140), count_total: 3, num_trees: 3, samples: 10\n",
      "feat_name: (1065-1080,1425-1440), count_total: 2, num_trees: 2, samples: 337\n",
      "feat_name: (1245-1260,1425-1440), count_total: 2, num_trees: 2, samples: 317\n",
      "feat_name: (855-870,1410-1425), count_total: 2, num_trees: 2, samples: 283\n",
      "feat_name: (120-135,480-495), count_total: 2, num_trees: 2, samples: 274\n",
      "feat_name: (15-30,405-420), count_total: 2, num_trees: 2, samples: 274\n",
      "feat_name: (1035-1050,135-150), count_total: 2, num_trees: 2, samples: 272\n",
      "feat_name: (825-840,180-195), count_total: 2, num_trees: 2, samples: 270\n",
      "feat_name: (1395-1410,1305-1320), count_total: 2, num_trees: 2, samples: 269\n",
      "feat_name: (0-15,510-525), count_total: 2, num_trees: 2, samples: 267\n",
      "feat_name: (285-300,1290-1305), count_total: 2, num_trees: 2, samples: 266\n",
      "feat_name: (300-315,1065-1080), count_total: 2, num_trees: 2, samples: 262\n",
      "feat_name: (795-810,465-480), count_total: 2, num_trees: 2, samples: 262\n",
      "feat_name: (15-30,420-435), count_total: 2, num_trees: 2, samples: 259\n",
      "feat_name: (1485-1500,1080-1095), count_total: 2, num_trees: 2, samples: 257\n",
      "feat_name: (15-30,840-855), count_total: 2, num_trees: 2, samples: 254\n",
      "feat_name: (810-825,1410-1425), count_total: 2, num_trees: 2, samples: 253\n",
      "feat_name: (300-315,1410-1425), count_total: 2, num_trees: 2, samples: 248\n",
      "feat_name: (165-180,60-75), count_total: 2, num_trees: 2, samples: 245\n",
      "feat_name: (105-120,120-135), count_total: 2, num_trees: 2, samples: 243\n",
      "feat_name: (1290-1305,240-255), count_total: 2, num_trees: 2, samples: 243\n",
      "feat_name: (525-540,855-870), count_total: 2, num_trees: 2, samples: 242\n",
      "feat_name: (930-945,1410-1425), count_total: 2, num_trees: 2, samples: 242\n",
      "feat_name: (0-15,285-300), count_total: 2, num_trees: 2, samples: 239\n",
      "feat_name: (645-660,1410-1425), count_total: 2, num_trees: 2, samples: 238\n",
      "feat_name: (1110-1125,540-555), count_total: 2, num_trees: 2, samples: 238\n",
      "feat_name: (825-840,345-360), count_total: 2, num_trees: 2, samples: 236\n",
      "feat_name: (165-180,900-915), count_total: 2, num_trees: 2, samples: 236\n",
      "feat_name: (570-585,750-765), count_total: 2, num_trees: 2, samples: 234\n",
      "feat_name: (510-525,540-555), count_total: 2, num_trees: 2, samples: 233\n",
      "feat_name: (285-300,105-120), count_total: 2, num_trees: 2, samples: 233\n",
      "feat_name: (1380-1395,1365-1380), count_total: 2, num_trees: 2, samples: 232\n",
      "feat_name: (570-585,1410-1425), count_total: 2, num_trees: 2, samples: 231\n",
      "feat_name: (1470-1485,120-135), count_total: 2, num_trees: 2, samples: 231\n",
      "feat_name: (285-300,435-450), count_total: 2, num_trees: 2, samples: 231\n",
      "feat_name: (1470-1485,930-945), count_total: 2, num_trees: 2, samples: 230\n",
      "feat_name: (1485-1500,960-975), count_total: 2, num_trees: 2, samples: 228\n",
      "feat_name: (360-375,1290-1305), count_total: 2, num_trees: 2, samples: 227\n",
      "feat_name: (0-15,480-495), count_total: 2, num_trees: 2, samples: 227\n",
      "feat_name: (105-120,660-675), count_total: 2, num_trees: 2, samples: 225\n",
      "feat_name: (630-645,90-105), count_total: 2, num_trees: 2, samples: 225\n",
      "feat_name: (735-750,1410-1425), count_total: 2, num_trees: 2, samples: 225\n",
      "feat_name: (1365-1380,90-105), count_total: 2, num_trees: 2, samples: 224\n",
      "feat_name: (105-120,885-900), count_total: 2, num_trees: 2, samples: 224\n",
      "feat_name: (45-60,1290-1305), count_total: 2, num_trees: 2, samples: 223\n",
      "feat_name: (300-315,930-945), count_total: 2, num_trees: 2, samples: 223\n",
      "feat_name: (420-435,165-180), count_total: 2, num_trees: 2, samples: 222\n",
      "feat_name: (390-405,930-945), count_total: 2, num_trees: 2, samples: 222\n",
      "feat_name: (315-330,75-90), count_total: 2, num_trees: 2, samples: 220\n",
      "feat_name: (195-210,105-120), count_total: 2, num_trees: 2, samples: 220\n",
      "feat_name: (585-600,705-720), count_total: 2, num_trees: 2, samples: 217\n",
      "feat_name: (420-435,930-945), count_total: 2, num_trees: 2, samples: 217\n",
      "feat_name: (90-105,375-390), count_total: 2, num_trees: 2, samples: 216\n",
      "feat_name: (600-615,930-945), count_total: 2, num_trees: 2, samples: 213\n",
      "feat_name: (1260-1275,1425-1440), count_total: 2, num_trees: 2, samples: 209\n",
      "feat_name: (1335-1350,120-135), count_total: 2, num_trees: 2, samples: 209\n",
      "feat_name: (1395-1410,1380-1395), count_total: 2, num_trees: 2, samples: 208\n",
      "feat_name: (1185-1200,1425-1440), count_total: 2, num_trees: 2, samples: 207\n",
      "feat_name: (1080-1095,465-480), count_total: 2, num_trees: 2, samples: 207\n",
      "feat_name: (1440-1455,495-510), count_total: 2, num_trees: 2, samples: 204\n",
      "feat_name: (450-465,135-150), count_total: 2, num_trees: 2, samples: 204\n",
      "feat_name: (1380-1395,105-120), count_total: 2, num_trees: 2, samples: 204\n",
      "feat_name: (120-135,75-90), count_total: 2, num_trees: 2, samples: 203\n",
      "feat_name: (90-105,75-90), count_total: 2, num_trees: 2, samples: 203\n",
      "feat_name: (1335-1350,270-285), count_total: 2, num_trees: 2, samples: 203\n",
      "feat_name: (1275-1290,1425-1440), count_total: 2, num_trees: 2, samples: 199\n",
      "feat_name: (360-375,1380-1395), count_total: 2, num_trees: 2, samples: 199\n",
      "feat_name: (345-360,1275-1290), count_total: 2, num_trees: 2, samples: 198\n",
      "feat_name: (60-75,420-435), count_total: 2, num_trees: 2, samples: 198\n",
      "feat_name: (1455-1470,900-915), count_total: 2, num_trees: 2, samples: 197\n",
      "feat_name: (360-375,90-105), count_total: 2, num_trees: 2, samples: 195\n",
      "feat_name: (540-555,120-135), count_total: 2, num_trees: 2, samples: 193\n",
      "feat_name: (375-390,840-855), count_total: 2, num_trees: 2, samples: 193\n",
      "feat_name: (600-615,225-240), count_total: 2, num_trees: 2, samples: 192\n",
      "feat_name: (225-240,120-135), count_total: 2, num_trees: 2, samples: 191\n",
      "feat_name: (195-210,1410-1425), count_total: 2, num_trees: 2, samples: 190\n",
      "feat_name: (975-990,120-135), count_total: 2, num_trees: 2, samples: 190\n",
      "feat_name: (600-615,300-315), count_total: 2, num_trees: 2, samples: 188\n",
      "feat_name: (1365-1380,900-915), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (1305-1320,270-285), count_total: 2, num_trees: 2, samples: 187\n",
      "feat_name: (0-15,540-555), count_total: 2, num_trees: 2, samples: 186\n",
      "feat_name: (15-30,1410-1425), count_total: 2, num_trees: 2, samples: 186\n",
      "feat_name: (1155-1170,60-75), count_total: 2, num_trees: 2, samples: 184\n",
      "feat_name: (420-435,90-105), count_total: 2, num_trees: 2, samples: 183\n",
      "feat_name: (1380-1395,1275-1290), count_total: 2, num_trees: 2, samples: 183\n",
      "feat_name: (1350-1365,135-150), count_total: 2, num_trees: 2, samples: 181\n",
      "feat_name: (120-135,1410-1425), count_total: 2, num_trees: 2, samples: 181\n",
      "feat_name: (45-60,720-735), count_total: 2, num_trees: 2, samples: 178\n",
      "feat_name: (990-1005,645-660), count_total: 2, num_trees: 2, samples: 177\n",
      "feat_name: (405-420,90-105), count_total: 2, num_trees: 2, samples: 176\n",
      "feat_name: (120-135,210-225), count_total: 2, num_trees: 2, samples: 175\n",
      "feat_name: (1425-1440,930-945), count_total: 2, num_trees: 2, samples: 174\n",
      "feat_name: (345-360,240-255), count_total: 2, num_trees: 2, samples: 174\n",
      "feat_name: (1485-1500,255-270), count_total: 2, num_trees: 2, samples: 174\n",
      "feat_name: (135-150,1380-1395), count_total: 2, num_trees: 2, samples: 173\n",
      "feat_name: (1440-1455,135-150), count_total: 2, num_trees: 2, samples: 170\n",
      "feat_name: (1215-1230,1035-1050), count_total: 2, num_trees: 2, samples: 169\n",
      "feat_name: (1485-1500,900-915), count_total: 2, num_trees: 2, samples: 168\n",
      "feat_name: (390-405,240-255), count_total: 2, num_trees: 2, samples: 167\n",
      "feat_name: (165-180,1410-1425), count_total: 2, num_trees: 2, samples: 156\n",
      "feat_name: (240-255,540-555), count_total: 2, num_trees: 2, samples: 154\n",
      "feat_name: (510-525,60-75), count_total: 2, num_trees: 2, samples: 145\n",
      "feat_name: (105-120,1350-1365), count_total: 2, num_trees: 2, samples: 144\n",
      "feat_name: (465-480,120-135), count_total: 2, num_trees: 2, samples: 143\n",
      "feat_name: (30-45,930-945), count_total: 2, num_trees: 2, samples: 141\n",
      "feat_name: (0-15,420-435), count_total: 2, num_trees: 2, samples: 141\n",
      "feat_name: (1260-1275,1380-1395), count_total: 2, num_trees: 2, samples: 141\n",
      "feat_name: (1320-1335,1410-1425), count_total: 2, num_trees: 2, samples: 139\n",
      "feat_name: (1455-1470,570-585), count_total: 2, num_trees: 2, samples: 138\n",
      "feat_name: (255-270,120-135), count_total: 2, num_trees: 2, samples: 135\n",
      "feat_name: (855-870,1050-1065), count_total: 2, num_trees: 2, samples: 135\n",
      "feat_name: (195-210,1380-1395), count_total: 2, num_trees: 2, samples: 134\n",
      "feat_name: (735-750,195-210), count_total: 2, num_trees: 2, samples: 132\n",
      "feat_name: (585-600,105-120), count_total: 2, num_trees: 2, samples: 132\n",
      "feat_name: (150-165,1290-1305), count_total: 2, num_trees: 2, samples: 131\n",
      "feat_name: (450-465,255-270), count_total: 2, num_trees: 2, samples: 131\n",
      "feat_name: (1050-1065,1410-1425), count_total: 2, num_trees: 2, samples: 130\n",
      "feat_name: (450-465,120-135), count_total: 2, num_trees: 2, samples: 129\n",
      "feat_name: (195-210,60-75), count_total: 2, num_trees: 2, samples: 129\n",
      "feat_name: (930-945,435-450), count_total: 2, num_trees: 2, samples: 127\n",
      "feat_name: (435-450,90-105), count_total: 2, num_trees: 2, samples: 126\n",
      "feat_name: (60-75,105-120), count_total: 2, num_trees: 2, samples: 125\n",
      "feat_name: (690-705,1410-1425), count_total: 2, num_trees: 2, samples: 124\n",
      "feat_name: (330-345,75-90), count_total: 2, num_trees: 2, samples: 123\n",
      "feat_name: (1020-1035,1380-1395), count_total: 2, num_trees: 2, samples: 122\n",
      "feat_name: (1275-1290,1380-1395), count_total: 2, num_trees: 2, samples: 122\n",
      "feat_name: (1110-1125,75-90), count_total: 2, num_trees: 2, samples: 122\n",
      "feat_name: (30-45,300-315), count_total: 2, num_trees: 2, samples: 121\n",
      "feat_name: (285-300,900-915), count_total: 2, num_trees: 2, samples: 119\n",
      "feat_name: (585-600,480-495), count_total: 2, num_trees: 2, samples: 118\n",
      "feat_name: (60-75,1290-1305), count_total: 2, num_trees: 2, samples: 116\n",
      "feat_name: (375-390,60-75), count_total: 2, num_trees: 2, samples: 116\n",
      "feat_name: (180-195,105-120), count_total: 2, num_trees: 2, samples: 115\n",
      "feat_name: (1455-1470,795-810), count_total: 2, num_trees: 2, samples: 115\n",
      "feat_name: (1140-1155,90-105), count_total: 2, num_trees: 2, samples: 111\n",
      "feat_name: (645-660,285-300), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (915-930,90-105), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (1395-1410,945-960), count_total: 2, num_trees: 2, samples: 110\n",
      "feat_name: (1065-1080,1410-1425), count_total: 2, num_trees: 2, samples: 109\n",
      "feat_name: (1185-1200,330-345), count_total: 2, num_trees: 2, samples: 109\n",
      "feat_name: (990-1005,150-165), count_total: 2, num_trees: 2, samples: 108\n",
      "feat_name: (330-345,90-105), count_total: 2, num_trees: 2, samples: 108\n",
      "feat_name: (1410-1425,390-405), count_total: 2, num_trees: 2, samples: 108\n",
      "feat_name: (375-390,735-750), count_total: 2, num_trees: 2, samples: 108\n",
      "feat_name: (90-105,270-285), count_total: 2, num_trees: 2, samples: 107\n",
      "feat_name: (1005-1020,360-375), count_total: 2, num_trees: 2, samples: 107\n",
      "feat_name: (165-180,90-105), count_total: 3, num_trees: 2, samples: 106\n",
      "feat_name: (135-150,1410-1425), count_total: 2, num_trees: 2, samples: 105\n",
      "feat_name: (1395-1410,360-375), count_total: 2, num_trees: 2, samples: 105\n",
      "feat_name: (600-615,135-150), count_total: 2, num_trees: 2, samples: 105\n",
      "feat_name: (240-255,105-120), count_total: 2, num_trees: 2, samples: 105\n",
      "feat_name: (1425-1440,1170-1185), count_total: 2, num_trees: 2, samples: 105\n",
      "feat_name: (675-690,60-75), count_total: 2, num_trees: 2, samples: 104\n",
      "feat_name: (45-60,705-720), count_total: 2, num_trees: 2, samples: 104\n",
      "feat_name: (240-255,90-105), count_total: 2, num_trees: 2, samples: 103\n",
      "feat_name: (705-720,60-75), count_total: 2, num_trees: 2, samples: 103\n",
      "feat_name: (1470-1485,135-150), count_total: 2, num_trees: 2, samples: 102\n",
      "feat_name: (1440-1455,1365-1380), count_total: 2, num_trees: 2, samples: 102\n",
      "feat_name: (465-480,75-90), count_total: 2, num_trees: 2, samples: 102\n",
      "feat_name: (1350-1365,465-480), count_total: 2, num_trees: 2, samples: 101\n",
      "feat_name: (885-900,60-75), count_total: 2, num_trees: 2, samples: 101\n",
      "feat_name: (1335-1350,225-240), count_total: 2, num_trees: 2, samples: 101\n",
      "feat_name: (60-75,1020-1035), count_total: 2, num_trees: 2, samples: 101\n",
      "feat_name: (150-165,105-120), count_total: 2, num_trees: 2, samples: 100\n",
      "feat_name: (540-555,60-75), count_total: 2, num_trees: 2, samples: 98\n",
      "feat_name: (330-345,165-180), count_total: 2, num_trees: 2, samples: 97\n",
      "feat_name: (1110-1125,90-105), count_total: 2, num_trees: 2, samples: 97\n",
      "feat_name: (675-690,75-90), count_total: 2, num_trees: 2, samples: 96\n",
      "feat_name: (90-105,90-105), count_total: 2, num_trees: 2, samples: 95\n",
      "feat_name: (1485-1500,360-375), count_total: 2, num_trees: 2, samples: 95\n",
      "feat_name: (1335-1350,105-120), count_total: 2, num_trees: 2, samples: 94\n",
      "feat_name: (1080-1095,90-105), count_total: 2, num_trees: 2, samples: 94\n",
      "feat_name: (1440-1455,240-255), count_total: 2, num_trees: 2, samples: 94\n",
      "feat_name: (660-675,120-135), count_total: 2, num_trees: 2, samples: 94\n",
      "feat_name: (765-780,1380-1395), count_total: 2, num_trees: 2, samples: 94\n",
      "feat_name: (855-870,75-90), count_total: 2, num_trees: 2, samples: 92\n",
      "feat_name: (975-990,105-120), count_total: 2, num_trees: 2, samples: 91\n",
      "feat_name: (990-1005,135-150), count_total: 2, num_trees: 2, samples: 91\n",
      "feat_name: (465-480,1410-1425), count_total: 2, num_trees: 2, samples: 89\n",
      "feat_name: (1245-1260,345-360), count_total: 2, num_trees: 2, samples: 89\n",
      "feat_name: (1470-1485,1350-1365), count_total: 2, num_trees: 2, samples: 85\n",
      "feat_name: (840-855,120-135), count_total: 2, num_trees: 2, samples: 83\n",
      "feat_name: (1470-1485,165-180), count_total: 2, num_trees: 2, samples: 81\n",
      "feat_name: (30-45,270-285), count_total: 2, num_trees: 2, samples: 81\n",
      "feat_name: (390-405,675-690), count_total: 2, num_trees: 2, samples: 78\n",
      "feat_name: (1485-1500,240-255), count_total: 2, num_trees: 2, samples: 73\n",
      "feat_name: (1305-1320,225-240), count_total: 2, num_trees: 2, samples: 64\n",
      "feat_name: (795-810,60-75), count_total: 2, num_trees: 2, samples: 59\n",
      "feat_name: (1110-1125,120-135), count_total: 2, num_trees: 2, samples: 59\n",
      "feat_name: (285-300,60-75), count_total: 2, num_trees: 2, samples: 45\n",
      "feat_name: (870-885,60-75), count_total: 2, num_trees: 2, samples: 44\n",
      "feat_name: (90-105,1335-1350), count_total: 2, num_trees: 2, samples: 42\n",
      "feat_name: (810-825,60-75), count_total: 2, num_trees: 2, samples: 35\n",
      "feat_name: (1155-1170,270-285), count_total: 2, num_trees: 2, samples: 34\n",
      "feat_name: (135-150,1065-1080), count_total: 2, num_trees: 2, samples: 32\n",
      "feat_name: (1440-1455,1350-1365), count_total: 2, num_trees: 2, samples: 32\n",
      "feat_name: (30-45,75-90), count_total: 2, num_trees: 2, samples: 30\n",
      "feat_name: (780-795,1290-1305), count_total: 2, num_trees: 2, samples: 29\n",
      "feat_name: (750-765,1425-1440), count_total: 2, num_trees: 2, samples: 28\n",
      "feat_name: (1395-1410,90-105), count_total: 2, num_trees: 2, samples: 27\n",
      "feat_name: (105-120,1290-1305), count_total: 2, num_trees: 2, samples: 26\n",
      "feat_name: (1050-1065,210-225), count_total: 2, num_trees: 2, samples: 25\n",
      "feat_name: (1290-1305,75-90), count_total: 2, num_trees: 2, samples: 25\n",
      "feat_name: (165-180,75-90), count_total: 2, num_trees: 2, samples: 23\n",
      "feat_name: (0-15,465-480), count_total: 2, num_trees: 2, samples: 22\n",
      "feat_name: (1095-1110,75-90), count_total: 2, num_trees: 2, samples: 21\n",
      "feat_name: (1185-1200,75-90), count_total: 2, num_trees: 2, samples: 20\n",
      "feat_name: (1350-1365,360-375), count_total: 2, num_trees: 2, samples: 20\n",
      "feat_name: (900-915,75-90), count_total: 2, num_trees: 2, samples: 20\n",
      "feat_name: (1395-1410,195-210), count_total: 2, num_trees: 2, samples: 20\n",
      "feat_name: (585-600,300-315), count_total: 2, num_trees: 2, samples: 19\n",
      "feat_name: (1065-1080,345-360), count_total: 2, num_trees: 2, samples: 18\n",
      "feat_name: (990-1005,90-105), count_total: 2, num_trees: 2, samples: 18\n",
      "feat_name: (15-30,105-120), count_total: 2, num_trees: 2, samples: 17\n",
      "feat_name: (945-960,630-645), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (945-960,60-75), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (645-660,90-105), count_total: 2, num_trees: 2, samples: 16\n",
      "feat_name: (1155-1170,90-105), count_total: 2, num_trees: 2, samples: 15\n",
      "feat_name: (195-210,90-105), count_total: 2, num_trees: 2, samples: 15\n",
      "feat_name: (675-690,105-120), count_total: 2, num_trees: 2, samples: 15\n",
      "feat_name: (435-450,75-90), count_total: 2, num_trees: 2, samples: 15\n",
      "feat_name: (975-990,75-90), count_total: 2, num_trees: 2, samples: 14\n",
      "feat_name: (1215-1230,1380-1395), count_total: 2, num_trees: 2, samples: 14\n",
      "feat_name: (690-705,330-345), count_total: 2, num_trees: 2, samples: 13\n",
      "feat_name: (1230-1245,1410-1425), count_total: 2, num_trees: 2, samples: 13\n",
      "feat_name: (1485-1500,675-690), count_total: 2, num_trees: 2, samples: 13\n",
      "feat_name: (690-705,120-135), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (1020-1035,90-105), count_total: 2, num_trees: 2, samples: 12\n",
      "feat_name: (255-270,1410-1425), count_total: 2, num_trees: 2, samples: 10\n",
      "feat_name: (1095-1110,105-120), count_total: 2, num_trees: 2, samples: 10\n",
      "feat_name: (1455-1470,135-150), count_total: 2, num_trees: 2, samples: 10\n",
      "feat_name: (645-660,930-945), count_total: 2, num_trees: 2, samples: 9\n",
      "feat_name: (795-810,105-120), count_total: 2, num_trees: 2, samples: 9\n",
      "feat_name: (75-90,135-150), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (795-810,1380-1395), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (405-420,900-915), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (45-60,165-180), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (810-825,825-840), count_total: 2, num_trees: 2, samples: 7\n",
      "feat_name: (1140-1155,75-90), count_total: 2, num_trees: 2, samples: 6\n",
      "feat_name: (1020-1035,105-120), count_total: 2, num_trees: 2, samples: 6\n",
      "feat_name: (255-270,105-120), count_total: 2, num_trees: 2, samples: 5\n",
      "feat_name: (1275-1290,165-180), count_total: 2, num_trees: 2, samples: 5\n",
      "feat_name: (615-630,60-75), count_total: 2, num_trees: 2, samples: 4\n",
      "feat_name: (990-1005,60-75), count_total: 1, num_trees: 1, samples: 170\n",
      "feat_name: (945-960,1410-1425), count_total: 1, num_trees: 1, samples: 147\n",
      "feat_name: (525-540,135-150), count_total: 1, num_trees: 1, samples: 145\n",
      "feat_name: (1230-1245,1425-1440), count_total: 1, num_trees: 1, samples: 144\n",
      "feat_name: (75-90,1320-1335), count_total: 1, num_trees: 1, samples: 144\n",
      "feat_name: (45-60,1050-1065), count_total: 1, num_trees: 1, samples: 144\n",
      "feat_name: (435-450,510-525), count_total: 1, num_trees: 1, samples: 143\n",
      "feat_name: (105-120,735-750), count_total: 1, num_trees: 1, samples: 143\n",
      "feat_name: (870-885,345-360), count_total: 1, num_trees: 1, samples: 142\n",
      "feat_name: (135-150,930-945), count_total: 1, num_trees: 1, samples: 140\n",
      "feat_name: (300-315,525-540), count_total: 1, num_trees: 1, samples: 140\n",
      "feat_name: (105-120,1020-1035), count_total: 1, num_trees: 1, samples: 139\n",
      "feat_name: (1080-1095,1020-1035), count_total: 1, num_trees: 1, samples: 139\n",
      "feat_name: (885-900,330-345), count_total: 1, num_trees: 1, samples: 139\n",
      "feat_name: (810-825,585-600), count_total: 1, num_trees: 1, samples: 138\n",
      "feat_name: (240-255,285-300), count_total: 1, num_trees: 1, samples: 138\n",
      "feat_name: (795-810,75-90), count_total: 1, num_trees: 1, samples: 137\n",
      "feat_name: (780-795,705-720), count_total: 1, num_trees: 1, samples: 137\n",
      "feat_name: (1455-1470,150-165), count_total: 1, num_trees: 1, samples: 136\n",
      "feat_name: (1200-1215,840-855), count_total: 1, num_trees: 1, samples: 136\n",
      "feat_name: (225-240,525-540), count_total: 1, num_trees: 1, samples: 136\n",
      "feat_name: (840-855,90-105), count_total: 1, num_trees: 1, samples: 136\n",
      "feat_name: (690-705,1020-1035), count_total: 1, num_trees: 1, samples: 136\n",
      "feat_name: (180-195,60-75), count_total: 1, num_trees: 1, samples: 135\n",
      "feat_name: (75-90,930-945), count_total: 1, num_trees: 1, samples: 135\n",
      "feat_name: (345-360,570-585), count_total: 1, num_trees: 1, samples: 134\n",
      "feat_name: (75-90,705-720), count_total: 1, num_trees: 1, samples: 134\n",
      "feat_name: (240-255,60-75), count_total: 1, num_trees: 1, samples: 134\n",
      "feat_name: (15-30,495-510), count_total: 1, num_trees: 1, samples: 133\n",
      "feat_name: (510-525,1410-1425), count_total: 1, num_trees: 1, samples: 133\n",
      "feat_name: (855-870,120-135), count_total: 1, num_trees: 1, samples: 133\n",
      "feat_name: (1035-1050,1215-1230), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (660-675,945-960), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (1410-1425,1170-1185), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (30-45,1185-1200), count_total: 1, num_trees: 1, samples: 132\n",
      "feat_name: (30-45,1350-1365), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (1290-1305,360-375), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (90-105,1245-1260), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (375-390,120-135), count_total: 1, num_trees: 1, samples: 131\n",
      "feat_name: (945-960,1020-1035), count_total: 1, num_trees: 1, samples: 130\n",
      "feat_name: (840-855,450-465), count_total: 1, num_trees: 1, samples: 130\n",
      "feat_name: (720-735,1410-1425), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (840-855,1410-1425), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (765-780,480-495), count_total: 1, num_trees: 1, samples: 129\n",
      "feat_name: (960-975,1170-1185), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (1110-1125,435-450), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (105-120,720-735), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (510-525,1290-1305), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (60-75,135-150), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (570-585,375-390), count_total: 1, num_trees: 1, samples: 128\n",
      "feat_name: (1440-1455,810-825), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (45-60,495-510), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (1050-1065,405-420), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (1155-1170,1410-1425), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (840-855,1380-1395), count_total: 1, num_trees: 1, samples: 127\n",
      "feat_name: (495-510,1410-1425), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (945-960,1380-1395), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (1380-1395,1170-1185), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (120-135,720-735), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (345-360,150-165), count_total: 1, num_trees: 1, samples: 126\n",
      "feat_name: (405-420,495-510), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (1410-1425,1290-1305), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (90-105,1050-1065), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (1080-1095,1005-1020), count_total: 1, num_trees: 1, samples: 125\n",
      "feat_name: (1080-1095,1065-1080), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (1290-1305,225-240), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (300-315,1020-1035), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (120-135,900-915), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (855-870,90-105), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (1260-1275,300-315), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (510-525,120-135), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (435-450,1425-1440), count_total: 1, num_trees: 1, samples: 124\n",
      "feat_name: (870-885,1020-1035), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (1455-1470,1065-1080), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (480-495,150-165), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (300-315,900-915), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (450-465,330-345), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (465-480,720-735), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (1440-1455,555-570), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (1485-1500,825-840), count_total: 1, num_trees: 1, samples: 123\n",
      "feat_name: (330-345,1200-1215), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (690-705,1005-1020), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (270-285,840-855), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (405-420,60-75), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (450-465,480-495), count_total: 1, num_trees: 1, samples: 122\n",
      "feat_name: (780-795,150-165), count_total: 1, num_trees: 1, samples: 121\n",
      "feat_name: (765-780,390-405), count_total: 1, num_trees: 1, samples: 121\n",
      "feat_name: (300-315,510-525), count_total: 1, num_trees: 1, samples: 121\n",
      "feat_name: (225-240,105-120), count_total: 1, num_trees: 1, samples: 121\n",
      "feat_name: (60-75,915-930), count_total: 1, num_trees: 1, samples: 121\n",
      "feat_name: (855-870,105-120), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (390-405,120-135), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (780-795,1380-1395), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (810-825,90-105), count_total: 1, num_trees: 1, samples: 120\n",
      "feat_name: (330-345,210-225), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (1290-1305,1020-1035), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (1080-1095,225-240), count_total: 1, num_trees: 1, samples: 119\n",
      "feat_name: (255-270,405-420), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (75-90,1065-1080), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (1080-1095,165-180), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (225-240,1380-1395), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (135-150,1275-1290), count_total: 1, num_trees: 1, samples: 118\n",
      "feat_name: (855-870,705-720), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1455-1470,930-945), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1125-1140,225-240), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (285-300,1245-1260), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (345-360,300-315), count_total: 1, num_trees: 1, samples: 117\n",
      "feat_name: (1080-1095,1335-1350), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (270-285,1080-1095), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (45-60,840-855), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (0-15,660-675), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (1080-1095,1290-1305), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (30-45,510-525), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (330-345,60-75), count_total: 1, num_trees: 1, samples: 116\n",
      "feat_name: (390-405,945-960), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (210-225,1380-1395), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (165-180,105-120), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (1065-1080,825-840), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (150-165,930-945), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (255-270,150-165), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (900-915,660-675), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (390-405,540-555), count_total: 1, num_trees: 1, samples: 115\n",
      "feat_name: (120-135,1380-1395), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (270-285,1410-1425), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (945-960,1425-1440), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (900-915,120-135), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (1080-1095,390-405), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (45-60,1170-1185), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (945-960,465-480), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (135-150,465-480), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (1005-1020,75-90), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (240-255,1380-1395), count_total: 1, num_trees: 1, samples: 114\n",
      "feat_name: (1215-1230,225-240), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (285-300,1065-1080), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (1335-1350,510-525), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (600-615,60-75), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (180-195,900-915), count_total: 1, num_trees: 1, samples: 113\n",
      "feat_name: (615-630,75-90), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (480-495,120-135), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (210-225,930-945), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (195-210,675-690), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (30-45,1230-1245), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (180-195,705-720), count_total: 1, num_trees: 1, samples: 112\n",
      "feat_name: (1095-1110,1035-1050), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (975-990,615-630), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (285-300,915-930), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (510-525,600-615), count_total: 1, num_trees: 1, samples: 111\n",
      "feat_name: (780-795,495-510), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (270-285,735-750), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (45-60,75-90), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (255-270,1125-1140), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (45-60,420-435), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (1440-1455,255-270), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (780-795,1065-1080), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (240-255,675-690), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (1065-1080,465-480), count_total: 1, num_trees: 1, samples: 110\n",
      "feat_name: (510-525,945-960), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (1005-1020,420-435), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (585-600,930-945), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (540-555,1410-1425), count_total: 1, num_trees: 1, samples: 109\n",
      "feat_name: (285-300,720-735), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (585-600,900-915), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (1440-1455,1290-1305), count_total: 1, num_trees: 1, samples: 108\n",
      "feat_name: (15-30,60-75), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (1470-1485,480-495), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (525-540,315-330), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (240-255,1290-1305), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (1335-1350,930-945), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (690-705,435-450), count_total: 1, num_trees: 1, samples: 107\n",
      "feat_name: (885-900,1305-1320), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1485-1500,780-795), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (120-135,1350-1365), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (1425-1440,1290-1305), count_total: 1, num_trees: 1, samples: 106\n",
      "feat_name: (135-150,900-915), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (525-540,945-960), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (165-180,840-855), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (945-960,435-450), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (30-45,390-405), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (45-60,1125-1140), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (435-450,315-330), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (285-300,420-435), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (60-75,630-645), count_total: 1, num_trees: 1, samples: 105\n",
      "feat_name: (825-840,1305-1320), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1320-1335,450-465), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1425-1440,885-900), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (105-120,390-405), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (345-360,285-300), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (990-1005,570-585), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1095-1110,225-240), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (330-345,780-795), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (1425-1440,270-285), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (705-720,225-240), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (30-45,660-675), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (225-240,1065-1080), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (270-285,225-240), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (795-810,945-960), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (0-15,735-750), count_total: 1, num_trees: 1, samples: 104\n",
      "feat_name: (270-285,60-75), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (555-570,450-465), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (555-570,1425-1440), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1185-1200,195-210), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (885-900,1350-1365), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (90-105,870-885), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1365-1380,975-990), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (315-330,900-915), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (1335-1350,750-765), count_total: 1, num_trees: 1, samples: 103\n",
      "feat_name: (15-30,1185-1200), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (120-135,330-345), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (315-330,915-930), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (360-375,60-75), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (75-90,735-750), count_total: 1, num_trees: 1, samples: 102\n",
      "feat_name: (1260-1275,1365-1380), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (900-915,885-900), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (690-705,390-405), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (675-690,330-345), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (450-465,270-285), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (690-705,75-90), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (585-600,450-465), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (330-345,900-915), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (1050-1065,675-690), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (315-330,270-285), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (1410-1425,765-780), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (1215-1230,165-180), count_total: 1, num_trees: 1, samples: 101\n",
      "feat_name: (930-945,75-90), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (915-930,840-855), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (360-375,1410-1425), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (0-15,900-915), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (30-45,915-930), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (1110-1125,330-345), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (15-30,930-945), count_total: 1, num_trees: 1, samples: 100\n",
      "feat_name: (150-165,765-780), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (885-900,915-930), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (60-75,525-540), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (1200-1215,1080-1095), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (360-375,915-930), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (1290-1305,120-135), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (1350-1365,945-960), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (1410-1425,1125-1140), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (885-900,1380-1395), count_total: 1, num_trees: 1, samples: 99\n",
      "feat_name: (1395-1410,285-300), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (1395-1410,915-930), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (1410-1425,420-435), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (675-690,285-300), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (1455-1470,360-375), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (420-435,1110-1125), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (705-720,135-150), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (990-1005,615-630), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (300-315,90-105), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (1200-1215,1305-1320), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (720-735,330-345), count_total: 1, num_trees: 1, samples: 98\n",
      "feat_name: (435-450,1140-1155), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1395-1410,735-750), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1260-1275,360-375), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (435-450,900-915), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (300-315,330-345), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (420-435,1410-1425), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (165-180,285-300), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (645-660,1005-1020), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (570-585,120-135), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (120-135,510-525), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (1275-1290,240-255), count_total: 1, num_trees: 1, samples: 97\n",
      "feat_name: (285-300,930-945), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (1095-1110,825-840), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (180-195,165-180), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (105-120,105-120), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (570-585,735-750), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (180-195,75-90), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (1245-1260,270-285), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (1080-1095,300-315), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (1440-1455,300-315), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (630-645,1305-1320), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (735-750,795-810), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (615-630,765-780), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (15-30,1380-1395), count_total: 1, num_trees: 1, samples: 96\n",
      "feat_name: (1380-1395,480-495), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1470-1485,960-975), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (135-150,1095-1110), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (390-405,315-330), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (555-570,1380-1395), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (795-810,405-420), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1365-1380,480-495), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1035-1050,1395-1410), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1350-1365,270-285), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (1470-1485,360-375), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (75-90,75-90), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (105-120,465-480), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (150-165,120-135), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (180-195,480-495), count_total: 1, num_trees: 1, samples: 95\n",
      "feat_name: (315-330,90-105), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (360-375,120-135), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1470-1485,240-255), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (915-930,60-75), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (15-30,120-135), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (990-1005,480-495), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (1350-1365,495-510), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (300-315,60-75), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (885-900,300-315), count_total: 1, num_trees: 1, samples: 94\n",
      "feat_name: (375-390,375-390), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (330-345,990-1005), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (360-375,645-660), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (405-420,1275-1290), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1290-1305,480-495), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1395-1410,480-495), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (630-645,1410-1425), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1470-1485,630-645), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1350-1365,390-405), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1395-1410,825-840), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1410-1425,735-750), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (780-795,300-315), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (270-285,75-90), count_total: 1, num_trees: 1, samples: 93\n",
      "feat_name: (1485-1500,855-870), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1335-1350,945-960), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1380-1395,960-975), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1035-1050,225-240), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1260-1275,1035-1050), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1125-1140,120-135), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (30-45,1290-1305), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (90-105,1170-1185), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (120-135,375-390), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (720-735,60-75), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (1065-1080,810-825), count_total: 1, num_trees: 1, samples: 92\n",
      "feat_name: (135-150,705-720), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (570-585,135-150), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1245-1260,660-675), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1170-1185,270-285), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (75-90,180-195), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (975-990,525-540), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (750-765,930-945), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1245-1260,315-330), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1110-1125,825-840), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (60-75,930-945), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1365-1380,120-135), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1365-1380,1365-1380), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (90-105,135-150), count_total: 1, num_trees: 1, samples: 91\n",
      "feat_name: (1350-1365,420-435), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (600-615,480-495), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (705-720,645-660), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (720-735,150-165), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1380-1395,435-450), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (105-120,1065-1080), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (1410-1425,435-450), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (330-345,930-945), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (135-150,405-420), count_total: 1, num_trees: 1, samples: 90\n",
      "feat_name: (45-60,180-195), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (720-735,630-645), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (1380-1395,135-150), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (150-165,75-90), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (1425-1440,945-960), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (60-75,900-915), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (990-1005,435-450), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (1380-1395,330-345), count_total: 1, num_trees: 1, samples: 89\n",
      "feat_name: (315-330,780-795), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (195-210,660-675), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (1365-1380,1050-1065), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (705-720,210-225), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (1365-1380,465-480), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (1185-1200,390-405), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (1425-1440,960-975), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (330-345,1245-1260), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (480-495,720-735), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (315-330,1380-1395), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (180-195,420-435), count_total: 1, num_trees: 1, samples: 88\n",
      "feat_name: (1185-1200,570-585), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (1380-1395,495-510), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (945-960,180-195), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (930-945,540-555), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (1335-1350,1275-1290), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (1395-1410,1320-1335), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (225-240,285-300), count_total: 1, num_trees: 1, samples: 87\n",
      "feat_name: (480-495,60-75), count_total: 1, num_trees: 1, samples: 86\n",
      "feat_name: (315-330,825-840), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (1455-1470,1080-1095), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (915-930,345-360), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (690-705,765-780), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (1215-1230,150-165), count_total: 1, num_trees: 1, samples: 85\n",
      "feat_name: (1050-1065,825-840), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1470-1485,1305-1320), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (255-270,720-735), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1365-1380,150-165), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1440-1455,150-165), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (435-450,465-480), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (1275-1290,135-150), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (375-390,165-180), count_total: 1, num_trees: 1, samples: 84\n",
      "feat_name: (660-675,135-150), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (585-600,840-855), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (360-375,945-960), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (315-330,945-960), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1485-1500,495-510), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1440-1455,1275-1290), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1365-1380,945-960), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1170-1185,90-105), count_total: 1, num_trees: 1, samples: 83\n",
      "feat_name: (1320-1335,285-300), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (1335-1350,1320-1335), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (285-300,1410-1425), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (1440-1455,735-750), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (1365-1380,960-975), count_total: 1, num_trees: 1, samples: 82\n",
      "feat_name: (1440-1455,960-975), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (1245-1260,135-150), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (1440-1455,225-240), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (45-60,1005-1020), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (135-150,1140-1155), count_total: 1, num_trees: 1, samples: 81\n",
      "feat_name: (1425-1440,1305-1320), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (660-675,255-270), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (1365-1380,300-315), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (300-315,270-285), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (1260-1275,915-930), count_total: 1, num_trees: 1, samples: 80\n",
      "feat_name: (1395-1410,315-330), count_total: 1, num_trees: 1, samples: 79\n",
      "feat_name: (615-630,105-120), count_total: 1, num_trees: 1, samples: 79\n",
      "feat_name: (255-270,135-150), count_total: 1, num_trees: 1, samples: 79\n",
      "feat_name: (1200-1215,480-495), count_total: 1, num_trees: 1, samples: 78\n",
      "feat_name: (1200-1215,435-450), count_total: 1, num_trees: 1, samples: 77\n",
      "feat_name: (420-435,135-150), count_total: 1, num_trees: 1, samples: 77\n",
      "feat_name: (405-420,180-195), count_total: 1, num_trees: 1, samples: 77\n",
      "feat_name: (360-375,240-255), count_total: 1, num_trees: 1, samples: 77\n",
      "feat_name: (600-615,90-105), count_total: 1, num_trees: 1, samples: 75\n",
      "feat_name: (585-600,180-195), count_total: 1, num_trees: 1, samples: 74\n",
      "feat_name: (1485-1500,750-765), count_total: 1, num_trees: 1, samples: 74\n",
      "feat_name: (165-180,645-660), count_total: 1, num_trees: 1, samples: 74\n",
      "feat_name: (570-585,705-720), count_total: 1, num_trees: 1, samples: 74\n",
      "feat_name: (225-240,300-315), count_total: 1, num_trees: 1, samples: 72\n",
      "feat_name: (30-45,765-780), count_total: 1, num_trees: 1, samples: 40\n",
      "feat_name: (1245-1260,225-240), count_total: 1, num_trees: 1, samples: 37\n",
      "feat_name: (930-945,1425-1440), count_total: 1, num_trees: 1, samples: 35\n",
      "feat_name: (255-270,1380-1395), count_total: 1, num_trees: 1, samples: 33\n",
      "feat_name: (1065-1080,60-75), count_total: 1, num_trees: 1, samples: 33\n",
      "feat_name: (210-225,1320-1335), count_total: 1, num_trees: 1, samples: 32\n",
      "feat_name: (435-450,420-435), count_total: 1, num_trees: 1, samples: 32\n",
      "feat_name: (1440-1455,420-435), count_total: 1, num_trees: 1, samples: 32\n",
      "feat_name: (1230-1245,165-180), count_total: 1, num_trees: 1, samples: 31\n",
      "feat_name: (30-45,165-180), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (120-135,420-435), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (75-90,1215-1230), count_total: 1, num_trees: 1, samples: 29\n",
      "feat_name: (225-240,1170-1185), count_total: 1, num_trees: 1, samples: 28\n",
      "feat_name: (840-855,1290-1305), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (45-60,1350-1365), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (225-240,1185-1200), count_total: 1, num_trees: 1, samples: 27\n",
      "feat_name: (1140-1155,810-825), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (345-360,165-180), count_total: 1, num_trees: 1, samples: 26\n",
      "feat_name: (435-450,285-300), count_total: 1, num_trees: 1, samples: 25\n",
      "feat_name: (1485-1500,1275-1290), count_total: 1, num_trees: 1, samples: 25\n",
      "feat_name: (1335-1350,180-195), count_total: 1, num_trees: 1, samples: 25\n",
      "feat_name: (1005-1020,270-285), count_total: 1, num_trees: 1, samples: 25\n",
      "feat_name: (135-150,345-360), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (855-870,1290-1305), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (930-945,195-210), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (1110-1125,1290-1305), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (135-150,510-525), count_total: 1, num_trees: 1, samples: 24\n",
      "feat_name: (45-60,300-315), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (450-465,1245-1260), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (975-990,1335-1350), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (60-75,1350-1365), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (1305-1320,1350-1365), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (1155-1170,390-405), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (810-825,75-90), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (1440-1455,360-375), count_total: 1, num_trees: 1, samples: 23\n",
      "feat_name: (1155-1170,375-390), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (1425-1440,420-435), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (750-765,1230-1245), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (600-615,1200-1215), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (1140-1155,1125-1140), count_total: 1, num_trees: 1, samples: 22\n",
      "feat_name: (0-15,525-540), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (630-645,300-315), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (90-105,1140-1155), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (1200-1215,1410-1425), count_total: 1, num_trees: 1, samples: 21\n",
      "feat_name: (0-15,1350-1365), count_total: 1, num_trees: 1, samples: 20\n",
      "feat_name: (1350-1365,75-90), count_total: 1, num_trees: 1, samples: 20\n",
      "feat_name: (1170-1185,510-525), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (390-405,450-465), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (1260-1275,240-255), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (1080-1095,930-945), count_total: 1, num_trees: 1, samples: 18\n",
      "feat_name: (645-660,465-480), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (765-780,540-555), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (105-120,1305-1320), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (60-75,120-135), count_total: 1, num_trees: 1, samples: 17\n",
      "feat_name: (1230-1245,345-360), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (150-165,840-855), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (1050-1065,315-330), count_total: 1, num_trees: 1, samples: 16\n",
      "feat_name: (15-30,945-960), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (795-810,90-105), count_total: 1, num_trees: 1, samples: 15\n",
      "feat_name: (345-360,105-120), count_total: 1, num_trees: 1, samples: 14\n",
      "feat_name: (600-615,540-555), count_total: 1, num_trees: 1, samples: 14\n",
      "feat_name: (840-855,75-90), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (645-660,75-90), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (945-960,105-120), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (870-885,1410-1425), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (1425-1440,300-315), count_total: 1, num_trees: 1, samples: 13\n",
      "feat_name: (1455-1470,270-285), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (1290-1305,195-210), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (45-60,135-150), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (1215-1230,870-885), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (810-825,540-555), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (1125-1140,915-930), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (945-960,810-825), count_total: 1, num_trees: 1, samples: 12\n",
      "feat_name: (45-60,765-780), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (600-615,435-450), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (120-135,150-165), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (210-225,120-135), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (90-105,195-210), count_total: 1, num_trees: 1, samples: 11\n",
      "feat_name: (90-105,855-870), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (660-675,1410-1425), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1125-1140,900-915), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1305-1320,105-120), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (480-495,390-405), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (75-90,1275-1290), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (915-930,1380-1395), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (1080-1095,285-300), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (45-60,150-165), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (945-960,75-90), count_total: 1, num_trees: 1, samples: 10\n",
      "feat_name: (975-990,1425-1440), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (870-885,1425-1440), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (360-375,1155-1170), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (180-195,90-105), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (555-570,390-405), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (870-885,390-405), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (1305-1320,1365-1380), count_total: 1, num_trees: 1, samples: 9\n",
      "feat_name: (480-495,900-915), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1215-1230,1410-1425), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (630-645,750-765), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1095-1110,555-570), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (0-15,405-420), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (975-990,1095-1110), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1275-1290,735-750), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (360-375,150-165), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (750-765,105-120), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (630-645,120-135), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1170-1185,1410-1425), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (45-60,690-705), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1215-1230,105-120), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (15-30,180-195), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1305-1320,120-135), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (645-660,1275-1290), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (450-465,780-795), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1395-1410,120-135), count_total: 1, num_trees: 1, samples: 8\n",
      "feat_name: (1410-1425,900-915), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (720-735,75-90), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (660-675,960-975), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (660-675,1380-1395), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (105-120,330-345), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1125-1140,75-90), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (75-90,1245-1260), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (840-855,510-525), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1140-1155,210-225), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1110-1125,1185-1200), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1170-1185,420-435), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (975-990,975-990), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (645-660,720-735), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (465-480,885-900), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1230-1245,225-240), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (435-450,750-765), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (165-180,465-480), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1320-1335,960-975), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (660-675,90-105), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (15-30,720-735), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (1140-1155,105-120), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (180-195,270-285), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (990-1005,285-300), count_total: 1, num_trees: 1, samples: 7\n",
      "feat_name: (795-810,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (300-315,885-900), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1020-1035,120-135), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (780-795,105-120), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (345-360,270-285), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (900-915,180-195), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (195-210,630-645), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (195-210,225-240), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1425-1440,330-345), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1455-1470,735-750), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1185-1200,270-285), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (915-930,375-390), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (360-375,435-450), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1200-1215,450-465), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1320-1335,1170-1185), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (645-660,105-120), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1470-1485,945-960), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (240-255,1410-1425), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (705-720,105-120), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (750-765,90-105), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (810-825,120-135), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (780-795,120-135), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (330-345,105-120), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (660-675,270-285), count_total: 1, num_trees: 1, samples: 6\n",
      "feat_name: (1170-1185,105-120), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (540-555,1335-1350), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (870-885,90-105), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (195-210,915-930), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1425-1440,390-405), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (915-930,120-135), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (540-555,90-105), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (810-825,105-120), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1305-1320,660-675), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1395-1410,255-270), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1245-1260,120-135), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1035-1050,105-120), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (795-810,1215-1230), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (180-195,150-165), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (30-45,1035-1050), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1125-1140,1425-1440), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (105-120,75-90), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (60-75,285-300), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (525-540,90-105), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1080-1095,585-600), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (825-840,1380-1395), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (330-345,660-675), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1245-1260,390-405), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1245-1260,1410-1425), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (1320-1335,225-240), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (405-420,255-270), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (990-1005,1425-1440), count_total: 1, num_trees: 1, samples: 5\n",
      "feat_name: (795-810,135-150), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (255-270,675-690), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (30-45,225-240), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (270-285,180-195), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (30-45,900-915), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (30-45,315-330), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (735-750,1215-1230), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1230-1245,375-390), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1185-1200,285-300), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (675-690,1305-1320), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (420-435,420-435), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (600-615,690-705), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1110-1125,390-405), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (495-510,945-960), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (150-165,360-375), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (135-150,240-255), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (870-885,1380-1395), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (90-105,1350-1365), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1095-1110,120-135), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (480-495,510-525), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (675-690,990-1005), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1305-1320,825-840), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (435-450,660-675), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (315-330,660-675), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (870-885,435-450), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (465-480,180-195), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (660-675,75-90), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (885-900,900-915), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (750-765,1410-1425), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (390-405,105-120), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (30-45,975-990), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (75-90,495-510), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (15-30,210-225), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (645-660,825-840), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (1155-1170,105-120), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (705-720,120-135), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (735-750,1005-1020), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (75-90,345-360), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (30-45,450-465), count_total: 1, num_trees: 1, samples: 4\n",
      "feat_name: (495-510,480-495), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (975-990,165-180), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (390-405,180-195), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (360-375,1215-1230), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (945-960,915-930), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (240-255,75-90), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (90-105,765-780), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (480-495,135-150), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (180-195,1380-1395), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (885-900,90-105), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (435-450,135-150), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (945-960,450-465), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (420-435,1320-1335), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (300-315,195-210), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (765-780,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1215-1230,675-690), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1170-1185,225-240), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (390-405,1410-1425), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (120-135,660-675), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1350-1365,720-735), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (105-120,495-510), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1290-1305,165-180), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (600-615,960-975), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (660-675,1335-1350), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (840-855,285-300), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (285-300,465-480), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (15-30,1230-1245), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (210-225,375-390), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (990-1005,105-120), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (645-660,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1125-1140,330-345), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1185-1200,585-600), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (870-885,555-570), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1110-1125,690-705), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1380-1395,270-285), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (60-75,945-960), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (765-780,600-615), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (795-810,810-825), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (225-240,615-630), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (660-675,240-255), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (45-60,945-960), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (495-510,90-105), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (330-345,1410-1425), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (945-960,1365-1380), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (375-390,1245-1260), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1185-1200,990-1005), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (480-495,1380-1395), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (300-315,990-1005), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (390-405,405-420), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1320-1335,390-405), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (645-660,840-855), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (825-840,840-855), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (270-285,270-285), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1440-1455,480-495), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (465-480,270-285), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (105-120,135-150), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1320-1335,270-285), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (1275-1290,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (420-435,900-915), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (0-15,1140-1155), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (645-660,810-825), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (195-210,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (30-45,120-135), count_total: 1, num_trees: 1, samples: 3\n",
      "feat_name: (375-390,495-510), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (465-480,495-510), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (915-930,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1065-1080,135-150), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (120-135,945-960), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (735-750,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1080-1095,270-285), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (300-315,1005-1020), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (585-600,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (930-945,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1410-1425,285-300), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (930-945,345-360), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (345-360,180-195), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1005-1020,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1245-1260,255-270), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1140-1155,825-840), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1065-1080,390-405), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1005-1020,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1185-1200,525-540), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1290-1305,1215-1230), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (885-900,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (270-285,990-1005), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (375-390,390-405), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (75-90,1035-1050), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (435-450,270-285), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (645-660,900-915), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (315-330,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1410-1425,1035-1050), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (660-675,150-165), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (45-60,870-885), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (885-900,270-285), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (405-420,1245-1260), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1350-1365,435-450), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1140-1155,285-300), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (90-105,300-315), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (885-900,105-120), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (330-345,300-315), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (45-60,225-240), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (855-870,855-870), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1290-1305,135-150), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (945-960,345-360), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1365-1380,930-945), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1410-1425,1320-1335), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (90-105,210-225), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (60-75,90-105), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (240-255,195-210), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (375-390,1305-1320), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1035-1050,270-285), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (45-60,750-765), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (780-795,90-105), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (675-690,975-990), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (945-960,120-135), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (345-360,990-1005), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (240-255,975-990), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (15-30,150-165), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (705-720,75-90), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (165-180,1125-1140), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (645-660,60-75), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (555-570,1065-1080), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1440-1455,645-660), count_total: 1, num_trees: 1, samples: 2\n",
      "feat_name: (1245-1260,330-345), count_total: 1, num_trees: 1, samples: 2\n"
     ]
    }
   ],
   "source": [
    "all_features = {}\n",
    "i=0\n",
    "for j in range(num_stability_iter):\n",
    "    for dt, rev in all_trees[j]:\n",
    "        dot_data = tree.export_graphviz(\n",
    "            dt,\n",
    "            class_names=classes,\n",
    "            feature_names=features,\n",
    "            filled=True,\n",
    "            rounded=True,\n",
    "            special_characters=True,)\n",
    "        graph = graphviz.Source(dot_data)\n",
    "        graph.render(f'rf_pool tree x,y {i}')    \n",
    "\n",
    "        features_used, splits, branches = get_dt_info(dt)\n",
    "\n",
    "        for feat in features_used:\n",
    "            if feat not in all_features:\n",
    "                all_features[feat] = {\"feat_name\": MyFeature(feat+1), \"count_total\": 0, \"num_trees\": 0, \"samples\": 0}\n",
    "\n",
    "            all_features[feat][\"count_total\"] += features_used[feat][\"count\"]\n",
    "            all_features[feat][\"num_trees\"] += 1\n",
    "            all_features[feat][\"samples\"] += features_used[feat][\"samples\"]\n",
    "\n",
    "        \"\"\"\n",
    "        print(f'tree {i}:')\n",
    "        for feat in features_used:   \n",
    "            print(f'feat: {feat+1}, count: {features_used[feat][\"count\"]}, samples: {features_used[feat][\"samples\"]}')\n",
    "        \"\"\"\n",
    "        i+=1\n",
    "\n",
    "print()\n",
    "print(\"all tree:\")    \n",
    "for feat in all_features:   \n",
    "     print(f'feat_name: ({all_features[feat][\"feat_name\"]}), count_total: {all_features[feat][\"count_total\"]}, num_trees: {all_features[feat][\"num_trees\"]}, samples: {all_features[feat][\"samples\"]}')\n",
    "\n",
    "\n",
    "print()\n",
    "sorted_features = sorted(all_features.items(), key=lambda x: (x[1][\"num_trees\"], x[1][\"samples\"]), reverse=True)\n",
    "print(\"sorted features:\")\n",
    "for feat, data in sorted_features:\n",
    "    print(f'feat_name: ({all_features[feat][\"feat_name\"]}), count_total: {data[\"count_total\"]}, num_trees: {data[\"num_trees\"]}, samples: {data[\"samples\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed31f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
